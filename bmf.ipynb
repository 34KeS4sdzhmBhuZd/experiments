{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11399db6",
   "metadata": {},
   "source": [
    "# Binary Matrix Factorization\n",
    "\n",
    "Requires the following packages to be installed in the environment: \n",
    "\n",
    "```\n",
    "- numpy\n",
    "- scikit-learn\n",
    "- matplotlib\n",
    "- opencv-python\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c4d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import perf_counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ee3a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def nearest_neighbor(points, data, n_neighbors = 1, p=2):\n",
    "    \"\"\"Function for finding the nearest neighbor of points in a dataset.\n",
    "    \n",
    "    Used to replace the k-means Steiner points with the nearest neighbor\n",
    "    in the dataset.\n",
    "    \n",
    "    Wraps the scipy nearest neighbor class.\"\"\"\n",
    "    \n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto', p=p, n_jobs=-1).fit(data)\n",
    "    _, indices = nbrs.kneighbors(points)\n",
    "    #print(np.bincount(indices.flatten()))\n",
    "    \n",
    "    return data[indices.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ede9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import minkowski\n",
    "\n",
    "def l_p_norm(v, p=2):\n",
    "    return np.power(np.linalg.norm(v, ord=p), p)    \n",
    "\n",
    "def l_p_dist(u, v, p=2):\n",
    "    return np.power(np.linalg.norm(u-v, ord=p), p)\n",
    "\n",
    "# vector valued functions\n",
    "def l_1_dist(u, v):\n",
    "    return l_p_dist(u,v,1)\n",
    "\n",
    "def l_2_dist(u, v):\n",
    "    return l_p_dist(u,v,2)\n",
    "\n",
    "def l_5_dist(u, v):\n",
    "    return l_p_dist(u,v,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e62fb",
   "metadata": {},
   "source": [
    "# Kumar et al.'s algorithm for Binary Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "5315334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, k_means\n",
    "\n",
    "class BMFKMeans:\n",
    "    '''The proposed algorithm of Kumar et al. (2019) to obtain a low-rank binary matrix\n",
    "    that approximates a given matrix.'''\n",
    "    \n",
    "    def __init__(self, k, max_iter=300):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def __fit(self, data):\n",
    "        #t0 = time()\n",
    "        kmeans = KMeans(init=\"k-means++\", n_clusters=self.k, max_iter=self.max_iter, n_init='auto')\n",
    "        kmeans.fit(data) # get clusters\n",
    "        #print(\"Elapsed time for k-means: %f\" % (time() - t0))\n",
    "        #cluster_centers_, labels_, inertia_ = k_means(data, self.k, n_init='auto', max_iter=self.max_iter)\n",
    "        \n",
    "        #t1 = time()\n",
    "        self.centers_ = nearest_neighbor(kmeans.cluster_centers_, data, p=1)\n",
    "        self.low_rank_ = nearest_neighbor(data, self.centers_) # self.centers_[kmeans.labels_]\n",
    "        #print(\"Elapsed time for nearest-neighbors: %f\" % (time() - t1))\n",
    "        \n",
    "    def fit(self, data, labels = []):\n",
    "        if (data.ndim == 2):\n",
    "            self.__fit(data)\n",
    "            return self\n",
    "        else: \n",
    "            raise ValueError(\"Can not factorize a dataset of shape % s.\" % str(data.shape))\n",
    "            \n",
    "    def results(self):\n",
    "        return self.low_rank_\n",
    "    \n",
    "    def score(self, data, label):\n",
    "        return np.square(np.linalg.norm(data - self.low_rank_, ord='fro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8438e0",
   "metadata": {},
   "source": [
    "# Our algorithm for Binary Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, k_means\n",
    "\n",
    "class BMFKMeans_plus:\n",
    "    '''The proposed algorithm of Kumar et al. (2019) to obtain a low-rank binary matrix\n",
    "    that approximates a given matrix - with post processing.'''\n",
    "    \n",
    "    def __init__(self, k, max_iter=300):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def __fit(self, data):\n",
    "        #t0 = time()\n",
    "        kmeans = KMeans(init=\"k-means++\", n_clusters=self.k, max_iter=self.max_iter, n_init='auto')\n",
    "        kmeans.fit(data) # get clusters\n",
    "        #print(\"Elapsed time for k-means: %f\" % (time() - t0))\n",
    "        #cluster_centers_, labels_, inertia_ = k_means(data, self.k, n_init='auto', max_iter=self.max_iter)\n",
    "        \n",
    "        #t1 = time()\n",
    "        self.centers_ = nearest_neighbor(kmeans.cluster_centers_, data, p=1)\n",
    "        self.low_rank_ = self.optimize(data)\n",
    "        #print(\"Elapsed time for nearest-neighbors: %f\" % (time() - t1))\n",
    "        \n",
    "    def fit(self, data, labels = []):\n",
    "        if (data.ndim == 2):\n",
    "            self.__fit(data)\n",
    "            return self\n",
    "        else: \n",
    "            raise ValueError(\"Can not factorize a dataset of shape % s.\" % str(data.shape))\n",
    "            \n",
    "    def results(self):\n",
    "        return self.low_rank_\n",
    "    \n",
    "    def score(self, data, label):\n",
    "        return np.linalg.norm(data - self.low_rank_, ord='fro')\n",
    "    \n",
    "    def optimize(self, data):\n",
    "        combinations = []\n",
    "        # enumerate all possible linear combinations\n",
    "        for i in range(2**self.k):\n",
    "            #if i % 10000 == 0 and i > 0:\n",
    "            #    print(i)\n",
    "            bits = []\n",
    "            for j, c in enumerate(bin(i)[:1:-1], 1):\n",
    "                if c == '1':\n",
    "                    bits.append(j-1)\n",
    "            combinations.append(np.sum(self.centers_[bits], axis=0))\n",
    "        combinations = np.mod(np.array(combinations), 2)\n",
    "        combinations = np.unique(combinations, axis=0)\n",
    "        # print(\"Obtained %d unique combinations.\" % combinations.shape[0])\n",
    "        return nearest_neighbor(data, np.array(combinations), p=1)\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0df64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, k_means\n",
    "\n",
    "class BMFKMeans_plus_int_1:\n",
    "    '''The proposed algorithm of Kumar et al. (2019) to obtain a low-rank binary matrix\n",
    "    that approximates a given matrix, with post-processing.'''\n",
    "    \n",
    "    def __init__(self, k, max_iter=300):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def __fit(self, data):\n",
    "        #t0 = time()\n",
    "        kmeans = KMeans(init=\"k-means++\", n_clusters=self.k, max_iter=self.max_iter, n_init='auto')\n",
    "        kmeans.fit(data) # get clusters\n",
    "        #print(\"Elapsed time for k-means: %f\" % (time() - t0))\n",
    "        #cluster_centers_, labels_, inertia_ = k_means(data, self.k, n_init='auto', max_iter=self.max_iter)\n",
    "        \n",
    "        #t1 = time()\n",
    "        self.centers_ = nearest_neighbor(kmeans.cluster_centers_, data, p=1)\n",
    "        self.low_rank_ = self.optimize(data)\n",
    "        #print(\"Elapsed time for nearest-neighbors: %f\" % (time() - t1))\n",
    "        \n",
    "    def fit(self, data, labels = []):\n",
    "        if (data.ndim == 2):\n",
    "            self.__fit(data)\n",
    "            return self\n",
    "        else: \n",
    "            raise ValueError(\"Can not factorize a dataset of shape % s.\" % str(data.shape))\n",
    "            \n",
    "    def results(self):\n",
    "        return self.low_rank_\n",
    "    \n",
    "    def score(self, data, label):\n",
    "        return l_p_norm((data - self.low_rank_).flatten(), p=1)\n",
    "    \n",
    "    def optimize(self, data):\n",
    "        combinations = []\n",
    "        # enumerate all possible linear combinations\n",
    "        for i in range(2**self.k):\n",
    "            #if i % 10000 == 0 and i > 0:\n",
    "            #    print(i)\n",
    "            bits = []\n",
    "            for j, c in enumerate(bin(i)[:1:-1], 1):\n",
    "                if c == '1':\n",
    "                    bits.append(j-1)\n",
    "            combinations.append(np.sum(self.centers_[bits], axis=0))\n",
    "        # combinations = np.mod(np.array(combinations), 2)\n",
    "        combinations = np.unique(combinations, axis=0)\n",
    "        # print(\"Obtained %d unique combinations.\" % combinations.shape[0])\n",
    "        return nearest_neighbor(data, np.array(combinations), p=1)\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ae229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, k_means\n",
    "\n",
    "class BMFKMeans_plus_int_2:\n",
    "    '''The proposed algorithm of Kumar et al. (2019) to obtain a low-rank binary matrix\n",
    "    that approximates a given matrix, with post-processing.'''\n",
    "    \n",
    "    def __init__(self, k, max_iter=300):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def __fit(self, data):\n",
    "        #t0 = time()\n",
    "        kmeans = KMeans(init=\"k-means++\", n_clusters=self.k, max_iter=self.max_iter, n_init='auto')\n",
    "        kmeans.fit(data) # get clusters\n",
    "        #print(\"Elapsed time for k-means: %f\" % (time() - t0))\n",
    "        #cluster_centers_, labels_, inertia_ = k_means(data, self.k, n_init='auto', max_iter=self.max_iter)\n",
    "        \n",
    "        #t1 = time()\n",
    "        self.centers_ = nearest_neighbor(kmeans.cluster_centers_, data, p=1)\n",
    "        self.low_rank_ = self.optimize(data)\n",
    "        #print(\"Elapsed time for nearest-neighbors: %f\" % (time() - t1))\n",
    "        \n",
    "    def fit(self, data, labels = []):\n",
    "        if (data.ndim == 2):\n",
    "            self.__fit(data)\n",
    "            return self\n",
    "        else: \n",
    "            raise ValueError(\"Can not factorize a dataset of shape % s.\" % str(data.shape))\n",
    "            \n",
    "    def results(self):\n",
    "        return self.low_rank_\n",
    "    \n",
    "    def score(self, data, label):\n",
    "        return l_p_norm((data - self.low_rank_).flatten(), p=2)\n",
    "    \n",
    "    def optimize(self, data):\n",
    "        combinations = []\n",
    "        # enumerate all possible linear combinations\n",
    "        for i in range(2**self.k):\n",
    "            #if i % 10000 == 0 and i > 0:\n",
    "            #    print(i)\n",
    "            bits = []\n",
    "            for j, c in enumerate(bin(i)[:1:-1], 1):\n",
    "                if c == '1':\n",
    "                    bits.append(j-1)\n",
    "            combinations.append(np.sum(self.centers_[bits], axis=0))\n",
    "        # combinations = np.mod(np.array(combinations), 2)\n",
    "        combinations = np.unique(combinations, axis=0)\n",
    "        # print(\"Obtained %d unique combinations.\" % combinations.shape[0])\n",
    "        return nearest_neighbor(data, np.array(combinations), p=2)\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e62de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, k_means\n",
    "\n",
    "class BMFKMeans_plus_int_5:\n",
    "    '''The proposed algorithm of Kumar et al. (2019) to obtain a low-rank binary matrix\n",
    "    that approximates a given matrix, with post-processing.'''\n",
    "    \n",
    "    def __init__(self, k, max_iter=300):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def __fit(self, data):\n",
    "        #t0 = time()\n",
    "        kmeans = KMeans(init=\"k-means++\", n_clusters=self.k, max_iter=self.max_iter, n_init='auto')\n",
    "        kmeans.fit(data) # get clusters\n",
    "        #print(\"Elapsed time for k-means: %f\" % (time() - t0))\n",
    "        #cluster_centers_, labels_, inertia_ = k_means(data, self.k, n_init='auto', max_iter=self.max_iter)\n",
    "        \n",
    "        #t1 = time()\n",
    "        self.centers_ = nearest_neighbor(kmeans.cluster_centers_, data, p=1)\n",
    "        self.low_rank_ = self.optimize(data)\n",
    "        #print(\"Elapsed time for nearest-neighbors: %f\" % (time() - t1))\n",
    "        \n",
    "    def fit(self, data, labels = []):\n",
    "        if (data.ndim == 2):\n",
    "            self.__fit(data)\n",
    "            return self\n",
    "        else: \n",
    "            raise ValueError(\"Can not factorize a dataset of shape % s.\" % str(data.shape))\n",
    "            \n",
    "    def results(self):\n",
    "        return self.low_rank_\n",
    "    \n",
    "    def score(self, data, label):\n",
    "        return l_p_norm((data - self.low_rank_).flatten(), p=5)\n",
    "    \n",
    "    def optimize(self, data):\n",
    "        combinations = []\n",
    "        # enumerate all possible linear combinations\n",
    "        for i in range(2**self.k):\n",
    "            #if i % 10000 == 0 and i > 0:\n",
    "            #    print(i)\n",
    "            bits = []\n",
    "            for j, c in enumerate(bin(i)[:1:-1], 1):\n",
    "                if c == '1':\n",
    "                    bits.append(j-1)\n",
    "            combinations.append(np.sum(self.centers_[bits], axis=0))\n",
    "        # combinations = np.mod(np.array(combinations), 2)\n",
    "        combinations = np.unique(combinations, axis=0)\n",
    "        # print(\"Obtained %d unique combinations.\" % combinations.shape[0])\n",
    "        return nearest_neighbor(data, np.array(combinations), p=5)\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "0f2a0b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.099833886584822"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmf = BMFKMeans(15)\n",
    "bmf.fit(congress)\n",
    "np.sqrt(bmf.score(congress, congress))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5d53a",
   "metadata": {},
   "source": [
    "# Coreset Constructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420203a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LWCoreset:\n",
    "    '''An algorithm for computing light-weight coresets, based on the paper\n",
    "    Scalable k-means clustering via lightweight coresets by Bachem, Lucic and Krause\n",
    "    \n",
    "    This gives an additive-multiplicative guarantee on the costs of k-means\n",
    "    clustering.'''\n",
    "    def __init__(self, m):\n",
    "        self.m = m\n",
    "    \n",
    "    def fit(self, data):\n",
    "        if data.ndim != 2:\n",
    "            raise ValueError(\"Dataset needs to be of dimension 2, is of dimension % s\" % data.ndims)\n",
    "        \n",
    "        n, d = data.shape\n",
    "        \n",
    "        #t0 = perf_counter()\n",
    "        mean = np.mean(data, axis=0)\n",
    "        dists = np.square(np.linalg.norm(data - mean, axis=1))\n",
    "        \n",
    "        self.p = (1.0 / n + dists / np.sum(dists))/2.0\n",
    "        #print(\"Calculated Distribution in %f s\" % (perf_counter() - t0))\n",
    "\n",
    "        #t0 = perf_counter()\n",
    "        self.indices = np.random.choice(n, size=self.m, replace=True, p=self.p)\n",
    "        #print(\"Sampled Indices in %f s\" % (perf_counter() - t0))\n",
    "\n",
    "        #t0 = perf_counter()\n",
    "        self.coreset = data[self.indices]\n",
    "        self.weights = 1.0 / (self.m * self.p[self.indices])\n",
    "        #print(\"Selected Coreset and Weights in %f s\" % (perf_counter() - t0))\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def result(self):\n",
    "        return (self.coreset, self.weights)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import kmeans_plusplus\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils.extmath import row_norms\n",
    "\n",
    "class KMeansCoreset:\n",
    "    def __init__(self, delta, k):\n",
    "        self.delta = delta\n",
    "        self.k = k\n",
    "        #self.d = d\n",
    "        \n",
    "    def fit(self, X, size):\n",
    "        n, d = X.shape\n",
    "        \n",
    "        # calculate squared norms of points\n",
    "        #t0 = perf_counter()\n",
    "        model = KMeans(self.k)\n",
    "        norms = row_norms(X, squared=True)\n",
    "        cs = model._init_centroids(X, init='k-means++',\n",
    "                                  x_squared_norms=norms, random_state=np.random.RandomState(seed=0))\n",
    "        #print(\"D2 sampling took %f\" % (perf_counter() - t0))\n",
    "        \n",
    "        \n",
    "        dist = row_norms(X - nearest_neighbor(X, cs), squared=True)\n",
    "        cs_cost = np.sum(dist)\n",
    "        c_total = cs_cost / n      \n",
    "        \n",
    "        nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(cs)\n",
    "        _, indices = nbrs.kneighbors(X) # euclidean distance and labels\n",
    "        indices = indices.flatten()\n",
    "        \n",
    "        keys, counts = np.unique(indices, return_counts=True)\n",
    "        cluster_sizes = np.array(counts)\n",
    "        \n",
    "        \n",
    "        if c_total < 0.00001:\n",
    "            #print(\"Coreset centers cover whole space.\")\n",
    "            self.coreset = cs\n",
    "            self.weights = np.ones(cs.shape)/ self.k\n",
    "            return self\n",
    "        \n",
    "        # calculate sensitivity\n",
    "        cluster_cost = np.bincount(indices, dist)\n",
    "        cluster_sizes_ = cluster_sizes[indices]\n",
    "        \n",
    "        alpha = 16 * np.log2(self.k) + 32\n",
    "        s = alpha / c_total * dist + (2 * alpha * cluster_cost[indices] / c_total + 4 * n) / cluster_sizes_\n",
    "        \n",
    "        \n",
    "        p = s / np.sum(s)\n",
    "        \n",
    "        self.indices = np.random.choice(n, size = size, p = p)\n",
    "        self.coreset = X[self.indices]\n",
    "        self.weights = 1.0 / (size * p[self.indices])\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def result(self):\n",
    "        return (self.coreset, self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, k_means\n",
    "\n",
    "class BMFCoreset:\n",
    "    '''Using a Coreset for BMF'''\n",
    "    \n",
    "    def __init__(self, k, size, max_iter=300):\n",
    "        self.k = k\n",
    "        self.size = size\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def __fit(self, data):\n",
    "        n, d = data.shape\n",
    "        \n",
    "        #kmcs = LWCoreset(self.size).fit(data)\n",
    "        #t0 = perf_counter()\n",
    "        kmcs = KMeansCoreset(0.99, self.k).fit(data, self.size)\n",
    "        cs, ws = kmcs.result()\n",
    "        #print(\"Calculated Coreset in %f s\" % (perf_counter() - t0))\n",
    "        if cs.shape[0] > k:\n",
    "            kmeans = KMeans(init=\"k-means++\", n_clusters=self.k, max_iter=self.max_iter, n_init='auto')\n",
    "            kmeans.fit(cs, sample_weight=ws) # get clusters\n",
    "            self.centers_ = nearest_neighbor(kmeans.cluster_centers_, data)\n",
    "        else:\n",
    "            self.centers_ = cs\n",
    "        #print(\"Elapsed time for k-means: %f\" % (time() - t0))\n",
    "        #cluster_centers_, labels_, inertia_ = k_means(data, self.k, n_init='auto', max_iter=self.max_iter)\n",
    "        \n",
    "        #t1 = time()\n",
    "        #self.low_rank_ = nearest_neighbor(data, self.centers_)\n",
    "        self.low_rank_ = self.optimize(data)\n",
    "\n",
    "        #self.low_rank_ = centers_[labels_]\n",
    "        #print(\"Elapsed time for nearest-neighbors: %f\" % (time() - t1))\n",
    "        \n",
    "    def fit(self, data, labels = []):\n",
    "        if (data.ndim == 2):\n",
    "            self.__fit(data)\n",
    "            return self\n",
    "        else: \n",
    "            raise ValueError(\"Can not factorize a dataset of shape % s.\" % str(data.shape))\n",
    "            \n",
    "    def results(self):\n",
    "        return self.low_rank_\n",
    "    \n",
    "    def score(self, data, label):\n",
    "        return np.linalg.norm(data - self.low_rank_, ord='fro')\n",
    "    \n",
    "    def optimize(self, data):\n",
    "        combinations = []\n",
    "        # enumerate all possible linear combinations\n",
    "        for i in range(2**self.k):\n",
    "            if i % 10000 == 0 and i > 0:\n",
    "                print(i)\n",
    "            bits = []\n",
    "            for j, c in enumerate(bin(i)[:1:-1], 1):\n",
    "                if c == '1':\n",
    "                    bits.append(j-1)\n",
    "            combinations.append(np.sum(self.centers_[bits], axis=0))\n",
    "        combinations = np.mod(np.array(combinations), 2)\n",
    "        combinations = np.unique(combinations, axis=0)\n",
    "        # print(\"Obtained %d unique combinations.\" % combinations.shape[0])\n",
    "        return nearest_neighbor(data, np.array(combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d40c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, k_means\n",
    "\n",
    "class BMFLWCoreset:\n",
    "    '''Using a Lightweight Coreset for BMF'''\n",
    "    \n",
    "    def __init__(self, k, size, max_iter=300):\n",
    "        self.k = k\n",
    "        self.size = size\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def __fit(self, data):\n",
    "        n, d = data.shape\n",
    "        \n",
    "        #t0 = perf_counter()\n",
    "        kmcs = LWCoreset(self.size).fit(data)\n",
    "        cs, ws = kmcs.result()\n",
    "        #print(\"Calculated Coreset in %f s\" % (perf_counter() - t0))\n",
    "        \n",
    "        kmeans = KMeans(init=\"k-means++\", n_clusters=self.k, max_iter=self.max_iter, n_init='auto')\n",
    "        kmeans.fit(cs, sample_weight=ws) # get clusters\n",
    "        #print(\"Elapsed time for k-means: %f\" % (time() - t0))\n",
    "        #cluster_centers_, labels_, inertia_ = k_means(data, self.k, n_init='auto', max_iter=self.max_iter)\n",
    "        \n",
    "        #t1 = time()\n",
    "        self.centers_ = nearest_neighbor(kmeans.cluster_centers_, data)\n",
    "        #self.low_rank_ = nearest_neighbor(data, self.centers_)\n",
    "        self.low_rank_ = self.optimize(data)\n",
    "        \n",
    "    def fit(self, data, labels = []):\n",
    "        if (data.ndim == 2):\n",
    "            self.__fit(data)\n",
    "            return self\n",
    "        else: \n",
    "            raise ValueError(\"Can not factorize a dataset of shape % s.\" % str(data.shape))\n",
    "            \n",
    "    def results(self):\n",
    "        return self.low_rank_\n",
    "    \n",
    "    def score(self, data, label):\n",
    "        return np.linalg.norm(data - self.low_rank_, ord='fro')\n",
    "\n",
    "    def optimize(self, data):\n",
    "        combinations = []\n",
    "        # enumerate all possible linear combinations\n",
    "        for i in range(2**self.k):\n",
    "            if i % 10000 == 0 and i > 0:\n",
    "                print(i)\n",
    "            bits = []\n",
    "            for j, c in enumerate(bin(i)[:1:-1], 1):\n",
    "                if c == '1':\n",
    "                    bits.append(j-1)\n",
    "            combinations.append(np.sum(self.centers_[bits], axis=0))\n",
    "        combinations = np.mod(np.array(combinations), 2)\n",
    "        combinations = np.unique(combinations, axis=0)\n",
    "        # print(\"Obtained %d unique combinations.\" % combinations.shape[0])\n",
    "        return nearest_neighbor(data, np.array(combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, Binarizer\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "def bench_bmf(bmf, name, k, data):\n",
    "    \"\"\"Benchmark to evaluate binary matrix factorization algorithms.\n",
    "    \n",
    "    Parameters\n",
    "    -----------------\n",
    "    bmf: BMF instance\n",
    "        a BMF instance with k already set\n",
    "    name: str\n",
    "        Name of the algorithm.\n",
    "    data: ndarray of shape (n_matrices, n_d1, n_d2)\n",
    "        A dataset of matrices to find low rank binary approximations to.\n",
    "    \"\"\"\n",
    "    results = [name, k]\n",
    "    warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "    \n",
    "    # normalize the data\n",
    "    shape_ = data.shape\n",
    "    if data.ndim == 3:\n",
    "        data = data.reshape(shape_[0] * shape_[1], shape_[2])  \n",
    "    data = Binarizer(threshold=0.33).transform(MinMaxScaler().fit_transform(data)).reshape(shape_)\n",
    "\n",
    "    \n",
    "    \n",
    "    if data.ndim == 2:\n",
    "        # data is a single matrix\n",
    "        t0 = perf_counter()\n",
    "        bmf.fit(data)\n",
    "        fit_time = perf_counter() - t0\n",
    "        results.append(fit_time * 1000)\n",
    "        results.append(bmf.score(data,data))\n",
    "        results.append(bmf.score(data,data))\n",
    "\n",
    "    if data.ndim == 3:\n",
    "        # dataset is a number of matrices\n",
    "        times = []\n",
    "        error = []\n",
    "        i = 0\n",
    "\n",
    "        for d in data:\n",
    "            #sleep(1)\n",
    "            t0 = perf_counter()\n",
    "            bmf.fit(d)\n",
    "            fit_time = perf_counter() - t0\n",
    "            err = bmf.score(d,d)\n",
    "            #t1 = perf_counter()\n",
    "            #bmf.fit(d.T)\n",
    "            #fit_time = fit_time + (perf_counter() - t1)\n",
    "            #err = min(err_1, bmf.score(d.T, d.T))\n",
    "            times.append(fit_time * 1000)\n",
    "            error.append(err)\n",
    "            i+=1\n",
    "            if i % 25 == 0:\n",
    "                print(\"\\r\" + name + \"-\" + str(k) + \": Processed %d elements\" % i, end=\"\")\n",
    "            # Show the results\n",
    "        \n",
    "        #m = 10\n",
    "        #largest = sorted(range(len(error)), key = lambda sub: error[sub])[-m:]\n",
    "        #print((\"Worst %d instances are \" % m) + str(largest))\n",
    "        \n",
    "        results.append(np.average(times))\n",
    "        results.append(np.average(error))\n",
    "        results.append(np.median(error))\n",
    "    \n",
    "    formatter_result = (\n",
    "        \"{:8s}\\t{:d}\\t{:2.3f}ms\\t{:.3f}\\t{:.3f}          \"\n",
    "    )\n",
    "    print(\"\\r\" + formatter_result.format(*results))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa891496",
   "metadata": {},
   "source": [
    "# Synthetic Data Generation\n",
    "\n",
    "The following functions are used for sampling full rank synthetic data, low rank synthetic data and noisy low rank synthetic data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fa1c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_random(n, d, q):\n",
    "    \"\"\"Generate a random n by d matrix where each entry is 1 with probability q\"\"\"\n",
    "    return np.random.choice(2, size=(n,d), p=[1-q, q])\n",
    "    \n",
    "def generate_synthetic_rank_k(n, d, q, k):\n",
    "    \"\"\"Generate a random n by d matrix via two uniformly sampled low rank matrices\"\"\"\n",
    "    A_ = np.random.choice(2, size=(n,k), p=[1-q, q])\n",
    "    B_ = np.random.choice(2, size=(k,d), p=[1-q, q])\n",
    "    return np.mod(A_ @ B_, 2)\n",
    "\n",
    "def generate_noisy_rank_k(n,d,q,k,p):\n",
    "    \"\"\"Generate a random n by d matrix via two uniformly sampled low rank matrices, where with probability p we flip a bit\"\"\"\n",
    "    A_ = np.random.choice(2, size=(n,k), p=[1-q, q])\n",
    "    B_ = np.random.choice(2, size=(k,d), p=[1-q, q])\n",
    "    C = np.mod(A_ @ B_, 2)\n",
    "    \n",
    "    flip = np.random.rand(n,d) < p\n",
    "    C[flip] = 1 - C[flip]\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464607c7",
   "metadata": {},
   "source": [
    "# Loading the Datasets\n",
    "\n",
    "We load the MNIST, ORL, ThyroidRL and Congress Vote Datasets and process them into binary matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6058543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the mnist dataset\n",
    "\n",
    "import gzip\n",
    "\n",
    "f = gzip.open('./datasets/mnist/train-images-idx3-ubyte.gz')\n",
    "image_size = 28\n",
    "num_images = 60000\n",
    "\n",
    "f.read(16)\n",
    "buf = f.read(image_size**2 * num_images)\n",
    "mnist = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "mnist = mnist.reshape(num_images, image_size, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4350d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "\n",
    "# we assume that all pgm files live in the same directory \n",
    "orl = np.array([cv2.imread(file,0) for file in glob.glob(\"./datasets/orl/*.pgm*\")])\n",
    "orl_shape = orl.shape\n",
    "orl = orl.reshape((orl_shape[0] * orl_shape[1] * orl_shape[2], 1))\n",
    "orl = Binarizer(threshold=0.33).fit_transform(MinMaxScaler().fit_transform(np.array(orl)))\n",
    "orl = orl.reshape(orl_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4c1de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read congressional votes dataset\n",
    "\n",
    "def convert_voting(s):\n",
    "    if s == b'y':\n",
    "        return 1.0\n",
    "    if s == b'n':\n",
    "        return 0.0\n",
    "    if s == b'?':\n",
    "        return 0.0\n",
    "    if s == b'republican':\n",
    "        return 1.0\n",
    "    if s == b'democrat':\n",
    "        return 0.0\n",
    "\n",
    "from numpy import loadtxt\n",
    "file = open('./datasets/house-votes-84.csv')\n",
    "congress = loadtxt(file, delimiter=',', skiprows=1, converters=convert_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aea3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "thyroid =pd.read_csv('./datasets/thyroidDF.csv')\n",
    "display(thyroid)\n",
    "thyroid.drop(['age', 'TT4', 'T4U', 'TSH', 'T3', 'FTI', 'TBG', 'referral_source', 'target', 'patient_id'], axis=1, inplace=True)\n",
    "\n",
    "thyroid_map = {'F' : 1.0, 'M': 0.0, 'f': 0.0, 't': 1.0, 'NaN': 0.0}\n",
    "thyroid = thyroid.replace(thyroid_map).to_numpy()\n",
    "\n",
    "thyroid[np.argwhere(np.isnan(thyroid))] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac686fa",
   "metadata": {},
   "source": [
    "# Coreset Size Experiments\n",
    "\n",
    "Here we evaluate the effect of coreset size on the Frobenius norm error. We generate 100 full rank binary matrices and compare the effect of coreset size on the average error of 10 runs of each algorithm. We run the experiment for values of $k \\in \\{2,3,5,10,15\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0de792",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_low_rank_test = generate_noisy_rank_k(5000,50,0.5,5,0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e15227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "ks = [2, 3, 5, 10]\n",
    "n_runs = 20\n",
    "\n",
    "datasets = [cs_low_rank_test, congress, thyroid]\n",
    "dataset_names = [\"low_rank\", \"congress\", \"thyroid\"]\n",
    "\n",
    "coreset_dataframe = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Size': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "            \n",
    "for k in ks:\n",
    "    for (name, data) in zip(dataset_names, datasets):\n",
    "        for i in range(n_runs):\n",
    "            print(i)\n",
    "            bmf = BMFKMeans_plus(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"k-means bmf\", k=k, data=data)\n",
    "            \n",
    "            for size in sizes: \n",
    "                row = pd.Series({'Dataset': name, 'Algorithm': 'bmf+', 'k': k, 'Size': size, 'Error': res[3], 'Time': res[2]})\n",
    "                coreset_dataframe = pd.concat([coreset_dataframe, row.to_frame().T], ignore_index=True)\n",
    "\n",
    "            for size in sizes:\n",
    "                coreset_size = max(k, np.ceil(data.shape[1] * size).astype(int))\n",
    "                \n",
    "                bmf = BMFCoreset(k, coreset_size)\n",
    "                res = bench_bmf(bmf=bmf, name=\"coreset bmf\", k=k, data=data)\n",
    "                \n",
    "                row = pd.Series(\n",
    "                    {'Dataset': name, 'Algorithm': 'coreset-bmf+', 'k': k, 'Size': size, 'Error': res[3], 'Time': res[2]})\n",
    "                coreset_dataframe = pd.concat([coreset_dataframe, row.to_frame().T], ignore_index=True)\n",
    "                \n",
    "                bmf = BMFLWCoreset(k, coreset_size)\n",
    "                res = bench_bmf(bmf=bmf, name=\"lw bmf\", k=k, data=data)\n",
    "                \n",
    "                row = pd.Series(\n",
    "                    {'Dataset': name, 'Algorithm': 'lw-coreset-bmf+', 'k': k, 'Size': size, 'Error': res[3], 'Time': res[2]})\n",
    "                coreset_dataframe = pd.concat([coreset_dataframe, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"colorblind\")\n",
    "\n",
    "cs_df = coreset_dataframe\n",
    "\n",
    "plot = sns.FacetGrid(data=cs_df[(cs_df['k'] == 5) | (cs_df['k'] == 10)], hue='Algorithm', col='Dataset', row='k', sharey=False, sharex=False)\n",
    "\n",
    "plot.map(sns.lineplot, 'Size', 'Error', errorbar=\"se\")\n",
    "\n",
    "plot.add_legend(title=\"Algorithm\")\n",
    "\n",
    "fig = plot.fig\n",
    "fig.savefig(\"coreset-plot.png\", transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bc40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coreset time \n",
    "sizes = [0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "ks = [2, 3, 5, 10]\n",
    "n_runs = 20\n",
    "\n",
    "datasets = [cs_low_rank_test, congress, thyroid]\n",
    "dataset_names = [\"low_rank\", \"congress\", \"thyroid\"]\n",
    "\n",
    "coreset_time = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Size': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for k in ks:\n",
    "    for (name, data) in zip(dataset_names, datasets):\n",
    "        print(name)\n",
    "        for i in range(n_runs):\n",
    "            print(i)\n",
    "            for size in sizes:\n",
    "                coreset_size = max(k, np.ceil(data.shape[1] * size).astype(int))\n",
    "                \n",
    "                t0 = perf_counter()\n",
    "                kmcs = KMeansCoreset(0.99, k).fit(data, coreset_size)\n",
    "                res = perf_counter() - t0\n",
    "                \n",
    "                row = pd.Series(\n",
    "                    {'Dataset': name, 'Algorithm': 'coreset', 'k': k, 'Size': size, 'Time': res})\n",
    "                coreset_time = pd.concat([coreset_time, row.to_frame().T], ignore_index=True)\n",
    "                \n",
    "                t0 = perf_counter()\n",
    "                kmcs = LWCoreset(coreset_size).fit(data)\n",
    "                res = perf_counter() - t0\n",
    "                \n",
    "                row = pd.Series(\n",
    "                    {'Dataset': name, 'Algorithm': 'lw-coreset', 'k': k, 'Size': size, 'Time': res})\n",
    "                coreset_time = pd.concat([coreset_time, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6a433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cst_df = coreset_time\n",
    "\n",
    "cst_df.groupby(['k', 'Algorithm'])['Time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8a7cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_df.groupby(['k', 'Algorithm', 'Dataset']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eec214",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_df.to_pickle('./cs_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c02448",
   "metadata": {},
   "source": [
    "# Comparative Experiments on Real and Synthetic Data\n",
    "\n",
    "In the experimental setup of these experiments, we compare only the quality (and runtime) of the approximation produced, using only the final matrix produced by the heuristics, without taking into account the low-rank factors produced by the algorithm and whether these are binary. Furthermore, the algorithms are used in a black box manner, which means that they may use the Boolean semiring, or GF(2) to perform matrix operations internally or may use non Boolean factors. \n",
    "\n",
    "We compare the frobenius norm error of the algorithms.\n",
    "\n",
    "Even under ideal conditions, our post-processing step produces the best quality approximation with only a small runtime overhead for small k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708551bf",
   "metadata": {},
   "source": [
    "## Benchmarking on Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e04c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_full = np.array([generate_synthetic_random(250, 50, 0.5) for i in range(25)])\n",
    "synthetic_low_rank_5 = np.array([generate_synthetic_rank_k(250, 50, 0.5, 5) for i in range(25)])\n",
    "synthetic_low_rank_10 = np.array([generate_synthetic_rank_k(250, 50, 0.5, 10) for i in range(25)])\n",
    "synthetic_low_rank_15 = np.array([generate_synthetic_rank_k(250, 50, 0.5, 15) for i in range(25)])\n",
    "synthetic_noisy_10_001 = np.array([generate_noisy_rank_k(250, 50, 0.5, 10, 0.01) for i in range(25)])\n",
    "synthetic_noisy_10_0001 = np.array([generate_noisy_rank_k(250, 50, 0.5, 10, 0.001) for i in range(25)])\n",
    "synthetic_full_ = np.array([generate_synthetic_random(250, 50, 0.1) for i in range(25)])\n",
    "synthetic_low_rank_5_ = np.array([generate_synthetic_rank_k(250, 50, 0.1, 5) for i in range(25)])\n",
    "synthetic_low_rank_10_ = np.array([generate_synthetic_rank_k(250, 50, 0.1, 10) for i in range(25)])\n",
    "synthetic_low_rank_15_ = np.array([generate_synthetic_rank_k(250, 50, 0.1, 15) for i in range(25)])\n",
    "synthetic_noisy_10_001_ = np.array([generate_noisy_rank_k(250, 50, 0.1, 10, 0.01) for i in range(25)])\n",
    "synthetic_noisy_10_0001_ = np.array([generate_noisy_rank_k(250, 50, 0.1, 10, 0.001) for i in range(25)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419f53a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "datasets = [synthetic_full, synthetic_low_rank_5, synthetic_low_rank_10, synthetic_low_rank_15, \n",
    "           synthetic_noisy_10_001, synthetic_noisy_10_0001,\n",
    "            synthetic_full_, synthetic_low_rank_5_, synthetic_low_rank_10_, synthetic_low_rank_15_, \n",
    "           synthetic_noisy_10_001_, synthetic_noisy_10_0001_]\n",
    "dataset_names = [\"full\", \"lr5\", \"lr10\", \"lr15\", \"noisy10-001\", \"noisy10-0001\", \n",
    "                 \"full0.1\", \"lr5-0.1\", \"lr10-0.1\", \"lr15-0.1\", \"noisy10-001-0.1\", \"noisy10-0001-0.1\", \n",
    "                ]\n",
    "\n",
    "synth_df = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "            \n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        for i in range(n_runs):\n",
    "            bmf = BMFKMeans(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf', 'k': k, 'Error': res[3], 'Time': (res[2] / 1000)})\n",
    "            synth_df = pd.concat([synth_df, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            bmf = BMFKMeans_plus(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf+\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf+', 'k': k, 'Error': res[3], 'Time': (res[2]/1000)})\n",
    "            synth_df = pd.concat([synth_df, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25736020",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_df.to_pickle('./synth_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb664609",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nimfa\n",
    "\n",
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "synth_df_nimfa = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        for i in range(n_runs):\n",
    "            avg_error = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()\n",
    "                bmf = nimfa.Bmf(mat, seed=\"nndsvd\", rank=k, max_iter=10000, lambda_w=1.1, lambda_h=1.1)\n",
    "                bmf_fit = bmf()\n",
    "                bmf_fitted = bmf.fitted()\n",
    "                bmf_fitted = Binarizer(threshold=0.5).fit_transform(np.array(bmf_fitted))\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                avg_error.append(np.linalg.norm(bmf_fitted - mat))\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'nimfa', 'k': k, 'Error': np.average(avg_error), 'Time': np.average(avg_time)})\n",
    "            synth_df_nimfa = pd.concat([synth_df_nimfa, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20de25b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "synth_df_nimfa.to_pickle('./synth_df_nimfa.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72711f32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from binmf import fit_spfact\n",
    "\n",
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "synth_df_binmf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        for i in range(n_runs):\n",
    "            avg_error = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()\n",
    "                nrows, ncols = mat.shape\n",
    "\n",
    "                sp_mat = csr_matrix(mat)\n",
    "                row_fact = np.random.normal(size=(nrows, k))\n",
    "                col_fact = np.random.normal(size=(ncols, k))\n",
    "                fit_spfact(sp_mat, row_fact, col_fact, reg_param=1e-1, niter=200, nthreads=8) #adjust number of threads for your setup\n",
    "                approx = row_fact @ col_fact.T\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                \n",
    "                avg_error.append(np.linalg.norm(Binarizer(threshold=0.5).fit_transform(approx) - mat))\n",
    "            \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'binmf', 'k': k, 'Error': np.average(avg_error), 'Time': np.average(avg_time)})\n",
    "            \n",
    "            synth_df_binmf = pd.concat([synth_df_binmf, row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dafa4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_df_binmf.to_pickle('./synth_df_binmf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: Ravanbakhsh Siamak, Poczos Barnabas, Greiner Russell, Boolean Matrix Factorization and Noisy Completion via Message Passing, ICML 2016\n",
    "\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def log_ratio(x):\n",
    "    return np.log(x) - np.log(1. - x)\n",
    "\n",
    "def get_random_matrices(M, N, K, p_x_1 = .5, p_y_1 = .5, p_flip = 0, p_observe = .1):\n",
    "    X = (np.random.rand(M, K) < p_x_1).astype(int)\n",
    "    Y = (np.random.rand(N, K) < p_y_1).astype(int)\n",
    "    Z = (X.dot(Y.T) > 0).astype(int)\n",
    "    mask = np.random.rand(M,N) < p_observe\n",
    "    O = Z.copy()\n",
    "    \n",
    "    flip = np.random.rand(M,N) < p_flip\n",
    "    O[flip] = 1 - O[flip]\n",
    "    mats = {'X':X, 'Y':Y, 'Z':Z, 'O':O, 'mask':mask}\n",
    "    return mats\n",
    "\n",
    "def hamming(X,Y):\n",
    "    return np.sum(np.abs(X - Y) > 1e-5)\n",
    "\n",
    "def density(X):\n",
    "    return np.sum(X)/float(np.prod(X.shape))\n",
    "\n",
    "\n",
    "def rec_error(Z, Zh):\n",
    "    return np.sum(np.abs(Z - Zh))/float(np.prod(Z.shape))\n",
    "\n",
    "\n",
    "def read_csv(fname, delimiter = ','):\n",
    "    mat = np.genfromtxt(fname, delimiter=delimiter)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8193dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pdb\n",
    "\n",
    "\n",
    "class MatrixCompletion(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 O, #observed matrix (only the parts indicated by mask will be used)\n",
    "                 K, #hidden dim\n",
    "                 mask = None,#boolean matrix the same size as O\n",
    "                 min_sum = True,                 \n",
    "                 tol = 1e-4,#tolerance for message updates\n",
    "                 learning_rate = .2, #damping parameter\n",
    "                 max_iter = 500, #maximum number of message passing updates\n",
    "                 verbose = False,\n",
    "                 p_x_1 = .5, #the prior probability of x=1. For regularization use small or large values in [0,1]\n",
    "                 p_y_1 = .5, #the prior probability of y=1. For regularization use small or large values in [0,1]\n",
    "                 #note that when p_x and p_y are uniform the MAP assignment is not sensitive\n",
    "                 #to the following values, assuming they are the same and above .5\n",
    "                 p_1_given_1 = .99, #the model of the noisy channel: probability of observing 1 for the input of 1\n",
    "                 p_0_given_0 = .99, #similar to the above\n",
    "                ):\n",
    "        \n",
    "        assert(p_x_1 < 1 and p_x_1 > 0)\n",
    "        assert(p_y_1 < 1 and p_y_1 > 0)\n",
    "        assert(p_1_given_1 > .5 and p_1_given_1 < 1)\n",
    "        assert(p_0_given_0 > .5 and p_0_given_0 < 1)                \n",
    "        \n",
    "        self.O = O.astype(int)\n",
    "        self.M,self.N = O.shape\n",
    "        self.K = K\n",
    "        self.verbose = verbose\n",
    "\n",
    "        assert(self.K < min(self.M,self.N))\n",
    "        if mask is not None:\n",
    "            assert(mask.shape[0] == self.M and mask.shape[1] == self.N)\n",
    "            self.mask = mask.astype(bool)\n",
    "        else:\n",
    "            self.mask = np.ones(O.shape, dtype=bool)\n",
    "            \n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.min_sum = min_sum\n",
    "        self.num_edges = np.sum(self.mask)        \n",
    "\n",
    "        self.update_adj_list()\n",
    "        \n",
    "        # will be used frequently\n",
    "        self.pos_edges = np.nonzero(O[mask])[0]\n",
    "        self.neg_edges = np.nonzero(1 - O[mask])[0]\n",
    "        self.range_edges = np.arange(self.num_edges)\n",
    "        self.cx = np.log(p_x_1) - np.log(1 - p_x_1)\n",
    "        self.cy = np.log(p_y_1) - np.log(1 - p_y_1)\n",
    "        self.co1 = np.log(p_1_given_1) - np.log(1. - p_0_given_0) #log(p(1|1)/p(1|0))\n",
    "        self.co0 = np.log(1. - p_1_given_1) - np.log(p_0_given_0) ##log(p(0|1)/p(0|0))\n",
    "\n",
    "    \n",
    "    def init_msgs_n_marginals(self):\n",
    "        self.marg_x = np.zeros((self.M, self.K))\n",
    "        self.marg_y = np.zeros((self.N, self.K))\n",
    "        self.in_x = np.zeros((self.num_edges, self.K)) #message going towards variable X: phi in the papger\n",
    "        self.new_in_x = np.zeros((self.num_edges, self.K)) #the new one\n",
    "        \n",
    "        self.out_x = np.log((np.random.rand(self.num_edges, self.K)))#/self.M #message leaving variable x: phi_hat in the paper \n",
    "        self.in_y = np.zeros((self.num_edges, self.K)) #message leaving variable y: psi in the paper\n",
    "        self.new_in_y = np.zeros((self.num_edges, self.K))\n",
    "        self.out_y = np.log(np.random.rand(self.num_edges, self.K))#/self.N #psi_hat in the paper\n",
    "        self.in_z = np.zeros((self.num_edges, self.K)) #gamma in the paper\n",
    "        self.out_z = np.zeros((self.num_edges, self.K)) #gamma_hat in the paper\n",
    "        \n",
    "        \n",
    "    def update_adj_list(self):\n",
    "        ''' nbM: list of indices of nonzeros organized in rows\n",
    "        nbM: list of indices of nonzeros organized in columns\n",
    "        '''\n",
    "        \n",
    "        Mnz,Nnz = np.nonzero(self.mask)\n",
    "        M = self.M\n",
    "        N = self.N\n",
    "        nbM = [[] for i in range(M)] \n",
    "        nbN = [[] for i in range(N)]\n",
    "\n",
    "        for z in range(len(Mnz)):\n",
    "            nbN[Nnz[z]].append(z)\n",
    "            nbM[Mnz[z]].append(z)\n",
    "\n",
    "        for i in range(M):\n",
    "            nbM[i] = np.array(nbM[i], dtype=int)\n",
    "        for i in range(N):\n",
    "            nbN[i] = np.array(nbN[i], dtype=int)\n",
    "            \n",
    "        self.rows = nbM\n",
    "        self.cols = nbN\n",
    "\n",
    "        \n",
    "    \n",
    "    def run(self):\n",
    "        self.init_msgs_n_marginals()\n",
    "        iters = 1\n",
    "        diff_msg = np.inf\n",
    "\n",
    "        while (diff_msg > self.tol and iters <= self.max_iter) or iters < 5:\n",
    "            self.update_min_sum()#(outX, outY, inZ, outZ, newInX, newInY, posEdges, negEdges,  opt)\n",
    "            diff_msg = np.max(np.abs(self.new_in_x - self.in_x))\n",
    "            self.in_x *= (1. - self.learning_rate)\n",
    "            self.in_x += self.learning_rate * (self.new_in_x)\n",
    "            self.in_y *= (1. - self.learning_rate)\n",
    "            self.in_y += self.learning_rate * (self.new_in_y)\n",
    "            self.update_margs()\n",
    "            if self.verbose:\n",
    "                print(\"iter %d, diff:%f\" %(iters, diff_msg))\n",
    "            #else:\n",
    "                #print(iters)\n",
    "                #sys.stdout.flush()\n",
    "                \n",
    "            iters += 1\n",
    "\n",
    "        #recover X and Y from marginals and reconstruct Z\n",
    "        self.X = (self.marg_x > 0).astype(int)\n",
    "        self.Y = (self.marg_y > 0).astype(int)\n",
    "        self.Z = (self.X.dot(self.Y.T) > 0).astype(int)\n",
    "\n",
    "        \n",
    "        \n",
    "    def update_min_sum(self):\n",
    "        self.in_z = np.minimum(np.minimum(self.out_x + self.out_y, self.out_x), self.out_y) #gamma update in the paper\n",
    "        \n",
    "        inz_pos = np.maximum(0.,self.in_z) # calculate it now, because we're chaning inz\n",
    "        #find the second larges element along the 1st axis (there's also a 0nd! axis)\n",
    "        inz_max_ind = np.argmax(self.in_z, axis=1)\n",
    "        inz_max = np.maximum(-self.in_z[self.range_edges, inz_max_ind],0)\n",
    "        self.in_z[self.range_edges, inz_max_ind] = -np.inf\n",
    "        inz_max_sec = np.maximum(-np.max(self.in_z, axis=1),0) # update for gamma_hat in the paper\n",
    "        sum_val = np.sum(inz_pos, axis=1)\n",
    "        #penalties/rewards for confoming with observations\n",
    "        sum_val[self.pos_edges] += self.co1\n",
    "        sum_val[self.neg_edges] += self.co0\n",
    "        \n",
    "        tmp_inz_max = inz_max.copy()\n",
    "        inz_pos =  sum_val[:, np.newaxis] - inz_pos\n",
    "        \n",
    "        for k in range(self.K):\n",
    "            self_max_ind = np.nonzero(inz_max_ind == k)[0]#find the indices where the max incoming message is from k\n",
    "            tmp_inz_max[self_max_ind] = inz_max_sec.take(self_max_ind)#replace the value of the max with the second largest value\n",
    "            self.out_z[:, k] = np.minimum( tmp_inz_max, inz_pos[:,k])#see the update for gamma_hat\n",
    "            tmp_inz_max[self_max_ind] = inz_max.take(self_max_ind)#fix tmp_iz_max for the next iter\n",
    "\n",
    "        # update in_x and in_y: phi_hat and psi_hat in the paper\n",
    "        self.new_in_x = np.maximum(self.out_z + self.out_y, 0) - np.maximum(self.out_y,0)\n",
    "        self.new_in_y = np.maximum(self.out_z + self.out_x, 0) - np.maximum(self.out_x,0)\n",
    "\n",
    "    \n",
    "\n",
    "    def update_margs(self):\n",
    "        #updates for phi and psi\n",
    "        for m in range(self.M):\n",
    "            self.marg_x[m,:] = np.sum(self.in_x.take(self.rows[m],axis=0), axis=0) + self.cx\n",
    "            self.out_x[self.rows[m], :] = -self.in_x.take(self.rows[m],axis=0) + self.marg_x[m,:]\n",
    "\n",
    "        for n in range(self.N):\n",
    "            self.marg_y[n, :] = np.sum(self.in_y.take(self.cols[n], axis=0), axis=0) + self.cy\n",
    "            self.out_y[self.cols[n], :] = -self.in_y.take(self.cols[n], axis=0) + self.marg_y[n,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc590f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "synth_mpf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        for i in range(n_runs):\n",
    "            avg_error = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()             \n",
    "                \n",
    "                mask = np.random.rand(mat.shape[0], mat.shape[1]) < 0.99\n",
    "                comp = MatrixCompletion(mat, k, mask = mask, min_sum = True, verbose = False, max_iter = 100)\n",
    "                comp.run()\n",
    "                \n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                avg_error.append(np.linalg.norm(Binarizer(threshold=0.5).fit_transform(comp.Z) - mat))\n",
    "            \n",
    "            print(np.average(avg_error))\n",
    "            print(np.average(avg_time))\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'mpbmf', 'k': k, 'Error': np.average(avg_error), 'Time': np.average(avg_time)})\n",
    "            \n",
    "            synth_mpf = pd.concat([synth_mpf, row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad536e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_mpf.to_pickle(\"./synth_mpf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba37a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_df\n",
    "synth_df_bmf = synth_df[(synth_df['Algorithm'] == 'bmf') | (synth_df['Algorithm'] == 'bmf+')]\n",
    "\n",
    "display(synth_df_bmf)\n",
    "\n",
    "synth_df_bmf.to_pickle(\"./synth_df_bmf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a10d4d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "synth_df.groupby([\"Dataset\", \"k\", \"Algorithm\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7470ad",
   "metadata": {},
   "source": [
    "## Benchmarking on Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14af2b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "# datasets are generally three dimensional\n",
    "datasets = [ orl, np.array([congress]), np.array([thyroid]) ]\n",
    "dataset_names = [\"orl\", \"congress\", \"thyroid\",  \n",
    "                ]\n",
    "\n",
    "real_df_bmf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "            \n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        for i in range(n_runs):\n",
    "            bmf = BMFKMeans(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf', 'k': k, 'Error': res[3], 'Time': (res[2] / 1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            bmf = BMFKMeans_plus(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf+\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf+', 'k': k, 'Error': res[3], 'Time': (res[2]/1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebccd752",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_bmf.to_pickle('./real_df_bmf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nimfa\n",
    "\n",
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_nimfa = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        for i in range(n_runs):\n",
    "            avg_error = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()\n",
    "                bmf = nimfa.Bmf(mat, seed=\"nndsvd\", rank=k, max_iter=10000, lambda_w=1.1, lambda_h=1.1)\n",
    "                bmf_fit = bmf()\n",
    "                bmf_fitted = bmf.fitted()\n",
    "                bmf_fitted = Binarizer(threshold=0.5).fit_transform(np.array(bmf_fitted))\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                avg_error.append(np.linalg.norm(bmf_fitted - mat))\n",
    "                print(bmf_fitted)\n",
    "                print(mat)\n",
    "                print(avg_error[-1])\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'nimfa', 'k': k, 'Error': np.average(avg_error), 'Time': np.average(avg_time)})\n",
    "            real_df_nimfa = pd.concat([real_df_nimfa, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c062af",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_nimfa.to_pickle('./real_df_nimfa.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a8ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from binmf import fit_spfact\n",
    "\n",
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_binmf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        for i in range(n_runs):\n",
    "            avg_error = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()\n",
    "                nrows, ncols = mat.shape\n",
    "\n",
    "                sp_mat = csr_matrix(mat)\n",
    "                row_fact = np.random.normal(size=(nrows, k))\n",
    "                col_fact = np.random.normal(size=(ncols, k))\n",
    "                fit_spfact(sp_mat, row_fact, col_fact, reg_param=1e-1, niter=200, nthreads=8) #adjust number of threads for your setup\n",
    "                approx = row_fact @ col_fact.T\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                \n",
    "                avg_error.append(np.linalg.norm(Binarizer(threshold=0).fit_transform(approx) - mat))\n",
    "            \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'binmf', 'k': k, 'Error': np.average(avg_error), 'Time': np.average(avg_time)})\n",
    "            \n",
    "            real_df_binmf = pd.concat([real_df_binmf, row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ee532",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_binmf.to_pickle('./real_df_binmf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c4598",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_mpf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        for i in range(n_runs):\n",
    "            avg_error = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()             \n",
    "                \n",
    "                mask = np.random.rand(mat.shape[0], mat.shape[1]) < 0.99\n",
    "                comp = MatrixCompletion(mat, k, mask = mask, min_sum = True, verbose = False, max_iter = 100)\n",
    "                comp.run()\n",
    "                \n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                avg_error.append(np.linalg.norm(Binarizer(threshold=0.5).fit_transform(comp.Z) - mat))\n",
    "            \n",
    "            print(np.average(avg_error))\n",
    "            print(np.average(avg_time))\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'mpbmf', 'k': k, 'Error': np.average(avg_error), 'Time': np.average(avg_time)})\n",
    "            \n",
    "            real_df_mpf = pd.concat([real_df_mpf, row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b47e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_mpf.to_pickle('./real_df_mpf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6372a022",
   "metadata": {},
   "source": [
    "# Comparisons on Real Data for different lp-norms and regular matrix multiplication\n",
    "\n",
    "We now compare the approximations produced by the heuristics for Lp norms on the integers for $p \\in \\{1, 2, 5\\}$. Note that the case $p = 2$ is the setting of minimizing the Frobenius norm that we initially discuss in our paper. \n",
    "\n",
    "As some of the heuristics do not produce low rank factors that are boolean, we binarize them using a threshold chosen such that the error across experiments is minimized. This is the case for the NIMFA and binmf heuristics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33a41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "# datasets are generally three dimensional\n",
    "datasets = [ orl, np.array([congress]), np.array([thyroid]) ]\n",
    "dataset_names = [\"orl\", \"congress\", \"thyroid\",  \n",
    "                ]\n",
    "\n",
    "real_df_bmf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "            \n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        for i in range(n_runs):\n",
    "            bmf = BMFKMeans(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf', 'k': k, 'Error': res[3], 'Time': (res[2] / 1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            bmf = BMFKMeans_plus_int_1(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf+ (int, l1)\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf+ (int, l1)', 'k': k, 'Error': res[3], 'Time': (res[2]/1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            bmf = BMFKMeans_plus_int_2(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf+ (int, l2)\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf+ (int, l2)', 'k': k, 'Error': res[3], 'Time': (res[2]/1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            bmf = BMFKMeans_plus_int_5(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf+ (int, l5)\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf+ (int, l5)', 'k': k, 'Error': res[3], 'Time': (res[2]/1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13f536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_bmf.to_pickle('./real_df_bmf_int.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175b6977",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmf = nimfa.Bmf(congress, seed=\"nndsvd\", rank=15, max_iter=10000, lambda_w=1.1, lambda_h=1.1)\n",
    "bmf_fit = bmf()\n",
    "b = Binarizer(threshold=0.3)               \n",
    "l = b.fit_transform(np.asarray(bmf.basis()))\n",
    "r = b.fit_transform(np.asarray(bmf.coef()))\n",
    "#l = bmf.basis()\n",
    "#r = bmf.coef()\n",
    "bmf_fitted = l @ r\n",
    "\n",
    "print(np.square(np.linalg.norm(congress - bmf_fitted)))\n",
    "\n",
    "plt.imshow(bmf_fitted)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e9194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1594e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nimfa\n",
    "\n",
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_nimfa = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        for i in range(n_runs):\n",
    "            avg_error_l1 = []\n",
    "            avg_error_l2 = []\n",
    "            avg_error_l5 = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()\n",
    "                bmf = nimfa.Bmf(mat, seed=\"nndsvd\", rank=k, max_iter=10000, lambda_w=1.1, lambda_h=1.1)\n",
    "                bmf_fit = bmf()\n",
    "                b = Binarizer(threshold=0.3)               \n",
    "                l = b.fit_transform(np.asarray(bmf.basis()))\n",
    "                r = b.fit_transform(np.asarray(bmf.coef()))\n",
    "                bmf_fitted = l @ r\n",
    "\n",
    "                #bmf_fitted = bmf.fitted()\n",
    "                #bmf_fitted = Binarizer(threshold=0.5).fit_transform(np.array(bmf_fitted))\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                avg_error_l2.append(np.square(np.linalg.norm(bmf_fitted - mat)))\n",
    "                avg_error_l1.append(np.sum(np.abs(bmf_fitted - mat)))\n",
    "                avg_error_l5.append(np.power(np.linalg.norm((bmf_fitted-mat).flatten(), ord=5) , 5))\n",
    "                #print(bmf_fitted)\n",
    "                #print(mat)\n",
    "                #print(avg_error[-1])\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'nimfa l1', 'k': k, 'Error': np.average(avg_error_l1), 'Time': np.average(avg_time)})\n",
    "            real_df_nimfa = pd.concat([real_df_nimfa, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'nimfa l2', 'k': k, 'Error': np.average(avg_error_l2), 'Time': np.average(avg_time)})\n",
    "            real_df_nimfa = pd.concat([real_df_nimfa, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'nimfa l5', 'k': k, 'Error': np.average(avg_error_l5), 'Time': np.average(avg_time)})\n",
    "            real_df_nimfa = pd.concat([real_df_nimfa, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c0c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_nimfa.to_pickle('./real_df_nimfa_int.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f56713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from binmf import fit_spfact\n",
    "\n",
    "mat = orl[6]\n",
    "k = 15\n",
    "\n",
    "nrows, ncols = mat.shape\n",
    "\n",
    "sp_mat = csr_matrix(mat)\n",
    "row_fact = np.random.normal(size=(nrows, k))\n",
    "col_fact = np.random.normal(size=(ncols, k))\n",
    "fit_spfact(sp_mat, row_fact, col_fact, reg_param=1e-1, niter=200, nthreads=8) #adjust number of threads for your setup\n",
    "b = Binarizer(threshold=0.6)\n",
    "approx = b.fit_transform(row_fact) @ b.fit_transform(col_fact.T)\n",
    "\n",
    "print(np.square(np.linalg.norm(mat - approx)))\n",
    "\n",
    "plt.imshow(approx)\n",
    "print(approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e3643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from binmf import fit_spfact\n",
    "\n",
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_binmf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(\"k: %s\" % k)\n",
    "        for i in range(n_runs):\n",
    "            print(i)\n",
    "            j=0\n",
    "            avg_error_l1 = []\n",
    "            avg_error_l2 = []\n",
    "            avg_error_l5 = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                if j % 50 == 0:\n",
    "                    print(j) \n",
    "                j+=1\n",
    "                \n",
    "                t0 = perf_counter()\n",
    "                nrows, ncols = mat.shape\n",
    "\n",
    "                sp_mat = csr_matrix(mat)\n",
    "                b = Binarizer(threshold=0.6)\n",
    "                row_fact = np.random.normal(size=(nrows, k))\n",
    "                col_fact = np.random.normal(size=(ncols, k))\n",
    "                fit_spfact(sp_mat, row_fact, col_fact, reg_param=1e-1, niter=200, nthreads=8) #adjust number of threads for your setup\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "\n",
    "                bmf_fitted = b.fit_transform(row_fact) @ b.fit_transform(col_fact.T)\n",
    "                \n",
    "                avg_error_l2.append(np.square(np.linalg.norm(bmf_fitted - mat)))\n",
    "                avg_error_l1.append(np.sum(np.abs(bmf_fitted - mat)))\n",
    "                avg_error_l5.append(np.power(np.linalg.norm((bmf_fitted-mat).flatten(), ord=5) , 5))\n",
    "            \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'binmf l1', 'k': k, 'Error': np.average(avg_error_l1), 'Time': np.average(avg_time)})\n",
    "            real_df_binmf = pd.concat([real_df_binmf, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'binmf l2', 'k': k, 'Error': np.average(avg_error_l2), 'Time': np.average(avg_time)})\n",
    "            real_df_binmf = pd.concat([real_df_binmf, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'binmf l5', 'k': k, 'Error': np.average(avg_error_l5), 'Time': np.average(avg_time)})\n",
    "            real_df_binmf = pd.concat([real_df_binmf, row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be74bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_binmf.to_pickle('./real_df_binmf_int.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43572a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = orl[0]\n",
    "k = 15\n",
    "\n",
    "mask = np.random.rand(mat.shape[0], mat.shape[1]) < 0.99\n",
    "comp = MatrixCompletion(mat, k, mask = mask, min_sum = True, verbose = False, max_iter = 100)\n",
    "comp.run()\n",
    "\n",
    "print(comp.Y)\n",
    "print(comp.X)\n",
    "plt.imshow(comp.X @ comp.Y.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01254343",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_mpf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print('k: %s' % k)\n",
    "        for i in range(n_runs):\n",
    "            print(i)\n",
    "            avg_error_l1 = []\n",
    "            avg_error_l2 = []\n",
    "            avg_error_l5 = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()             \n",
    "                \n",
    "                mask = np.random.rand(mat.shape[0], mat.shape[1]) < 0.99\n",
    "                comp = MatrixCompletion(mat, k, mask = mask, min_sum = True, verbose = False, max_iter = 100)\n",
    "                comp.run()\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                bmf_fitted = comp.X @ comp.Y.T\n",
    "                \n",
    "                #avg_error.append(np.linalg.norm(Binarizer(threshold=0.5).fit_transform(comp.Z) - mat))\n",
    "                avg_error_l2.append(np.square(np.linalg.norm(bmf_fitted - mat)))\n",
    "                avg_error_l1.append(np.sum(np.abs(bmf_fitted - mat)))\n",
    "                avg_error_l5.append(np.power(np.linalg.norm((bmf_fitted-mat).flatten(), ord=5) , 5))\n",
    "\n",
    "           \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'mpbmf l1', 'k': k, 'Error': np.average(avg_error_l1), 'Time': np.average(avg_time)})\n",
    "            real_df_mpf = pd.concat([real_df_mpf, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'mpbmf l2', 'k': k, 'Error': np.average(avg_error_l2), 'Time': np.average(avg_time)})\n",
    "            real_df_mpf = pd.concat([real_df_mpf, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'mpbmf l5', 'k': k, 'Error': np.average(avg_error_l5), 'Time': np.average(avg_time)})\n",
    "            real_df_mpf = pd.concat([real_df_mpf, row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5568a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_mpf.to_pickle('./real_df_mpf_int.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5a6fe",
   "metadata": {},
   "source": [
    "# Int with Synthetic\n",
    "\n",
    "In this section we perform experiments where the matrix multiplication is performed in the standard way over the reals, rather than the boolean semiring or GF(2). This is especially bad for existing heuristics, as they internally are usually tuned to the Boolean semiring. The NIMFA and binmf heuristics do not have a guarantee on producing 0-1 valued low rank factors U and V, so we apply a best-effort thresholding, to produce these factors.\n",
    "\n",
    "*We note again here, that the existing heuristics are not tuned to this setting and therefore we do not expect them to perform well*. The heuristic of Kumar et. al and our extension that guesses a good U V pair based on centers obtained from the coreset does "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc04fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "# datasets are generally three dimensional\n",
    "datasets = [synthetic_full, synthetic_low_rank_5, synthetic_low_rank_10, synthetic_low_rank_15, \n",
    "           synthetic_noisy_10_001, synthetic_noisy_10_0001,\n",
    "            synthetic_full_, synthetic_low_rank_5_, synthetic_low_rank_10_, synthetic_low_rank_15_, \n",
    "           synthetic_noisy_10_001_, synthetic_noisy_10_0001_]\n",
    "dataset_names = [\"full\", \"lr5\", \"lr10\", \"lr15\", \"noisy10-001\", \"noisy10-0001\", \n",
    "                 \"full0.1\", \"lr5-0.1\", \"lr10-0.1\", \"lr15-0.1\", \"noisy10-001-0.1\", \"noisy10-0001-0.1\", \n",
    "                ]\n",
    "\n",
    "real_df_bmf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "            \n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        for i in range(n_runs):\n",
    "            bmf = BMFKMeans(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf', 'k': k, 'Error': res[3], 'Time': (res[2] / 1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            bmf = BMFKMeans_plus_int_1(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf+ (int, l1)\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf+ (int, l1)', 'k': k, 'Error': res[3], 'Time': (res[2]/1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            bmf = BMFKMeans_plus_int_2(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf+ (int, l2)\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf+ (int, l2)', 'k': k, 'Error': res[3], 'Time': (res[2]/1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            bmf = BMFKMeans_plus_int_5(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf+ (int, l5)\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf+ (int, l5)', 'k': k, 'Error': res[3], 'Time': (res[2]/1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a0b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_bmf.to_pickle('./synth_df_bmf_int.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417c3e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nimfa\n",
    "\n",
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_nimfa = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        for i in range(n_runs):\n",
    "            avg_error_l1 = []\n",
    "            avg_error_l2 = []\n",
    "            avg_error_l5 = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()\n",
    "                bmf = nimfa.Bmf(mat, seed=\"nndsvd\", rank=k, max_iter=10000, lambda_w=1.1, lambda_h=1.1)\n",
    "                bmf_fit = bmf()\n",
    "                b = Binarizer(threshold=0.3)               \n",
    "                l = b.fit_transform(np.asarray(bmf.basis()))\n",
    "                r = b.fit_transform(np.asarray(bmf.coef()))\n",
    "                bmf_fitted = l @ r\n",
    "\n",
    "                #bmf_fitted = bmf.fitted()\n",
    "                #bmf_fitted = Binarizer(threshold=0.5).fit_transform(np.array(bmf_fitted))\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                avg_error_l2.append(np.square(np.linalg.norm(bmf_fitted - mat)))\n",
    "                avg_error_l1.append(np.sum(np.abs(bmf_fitted - mat)))\n",
    "                avg_error_l5.append(np.power(np.linalg.norm((bmf_fitted-mat).flatten(), ord=5) , 5))\n",
    "                #print(bmf_fitted)\n",
    "                #print(mat)\n",
    "                #print(avg_error[-1])\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'nimfa l1', 'k': k, 'Error': np.average(avg_error_l1), 'Time': np.average(avg_time)})\n",
    "            real_df_nimfa = pd.concat([real_df_nimfa, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'nimfa l2', 'k': k, 'Error': np.average(avg_error_l2), 'Time': np.average(avg_time)})\n",
    "            real_df_nimfa = pd.concat([real_df_nimfa, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'nimfa l5', 'k': k, 'Error': np.average(avg_error_l5), 'Time': np.average(avg_time)})\n",
    "            real_df_nimfa = pd.concat([real_df_nimfa, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fefd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_nimfa.to_pickle('./synth_df_nimfa_int.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482038fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from binmf import fit_spfact\n",
    "\n",
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_binmf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(\"k: %s\" % k)\n",
    "        for i in range(n_runs):\n",
    "            print(i)\n",
    "            avg_error_l1 = []\n",
    "            avg_error_l2 = []\n",
    "            avg_error_l5 = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()\n",
    "                nrows, ncols = mat.shape\n",
    "\n",
    "                sp_mat = csr_matrix(mat)\n",
    "                b = Binarizer(threshold=0.6)\n",
    "                row_fact = np.random.normal(size=(nrows, k))\n",
    "                col_fact = np.random.normal(size=(ncols, k))\n",
    "                fit_spfact(sp_mat, row_fact, col_fact, reg_param=1e-1, niter=200, nthreads=8) #adjust number of threads for your setup\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "\n",
    "                bmf_fitted = b.fit_transform(row_fact) @ b.fit_transform(col_fact.T)\n",
    "                \n",
    "                avg_error_l2.append(np.square(np.linalg.norm(bmf_fitted - mat)))\n",
    "                avg_error_l1.append(np.sum(np.abs(bmf_fitted - mat)))\n",
    "                avg_error_l5.append(np.power(np.linalg.norm((bmf_fitted-mat).flatten(), ord=5) , 5))\n",
    "            \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'binmf l1', 'k': k, 'Error': np.average(avg_error_l1), 'Time': np.average(avg_time)})\n",
    "            real_df_binmf = pd.concat([real_df_binmf, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'binmf l2', 'k': k, 'Error': np.average(avg_error_l2), 'Time': np.average(avg_time)})\n",
    "            real_df_binmf = pd.concat([real_df_binmf, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'binmf l5', 'k': k, 'Error': np.average(avg_error_l5), 'Time': np.average(avg_time)})\n",
    "            real_df_binmf = pd.concat([real_df_binmf, row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb5f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_binmf.to_pickle('./synth_df_binmf_int.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_mpf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print('k: %s' % k)\n",
    "        for i in range(n_runs):\n",
    "            print(i)\n",
    "            avg_error_l1 = []\n",
    "            avg_error_l2 = []\n",
    "            avg_error_l5 = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()             \n",
    "                \n",
    "                mask = np.random.rand(mat.shape[0], mat.shape[1]) < 0.99\n",
    "                comp = MatrixCompletion(mat, k, mask = mask, min_sum = True, verbose = False, max_iter = 100)\n",
    "                comp.run()\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                bmf_fitted = comp.X @ comp.Y.T\n",
    "                \n",
    "                #avg_error.append(np.linalg.norm(Binarizer(threshold=0.5).fit_transform(comp.Z) - mat))\n",
    "                avg_error_l2.append(np.square(np.linalg.norm(bmf_fitted - mat)))\n",
    "                avg_error_l1.append(np.sum(np.abs(bmf_fitted - mat)))\n",
    "                avg_error_l5.append(np.power(np.linalg.norm((bmf_fitted-mat).flatten(), ord=5) , 5))\n",
    "\n",
    "           \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'mpbmf l1', 'k': k, 'Error': np.average(avg_error_l1), 'Time': np.average(avg_time)})\n",
    "            real_df_mpf = pd.concat([real_df_mpf, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'mpbmf l2', 'k': k, 'Error': np.average(avg_error_l2), 'Time': np.average(avg_time)})\n",
    "            real_df_mpf = pd.concat([real_df_mpf, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'mpbmf l5', 'k': k, 'Error': np.average(avg_error_l5), 'Time': np.average(avg_time)})\n",
    "            real_df_mpf = pd.concat([real_df_mpf, row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af5b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_mpf.to_pickle('./synth_df_mpf_int.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d49e3",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "We first analyze the outcomes of the \"steelmanned\" heuristic comparison, where each heuristic is used as detailed by the implementers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "1deba27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load real data\n",
    "real_df_bmf = pd.read_pickle('./real_df_bmf.pkl')\n",
    "real_df_binmf = pd.read_pickle('./real_df_binmf.pkl')\n",
    "real_df_mpf = pd.read_pickle('./real_df_mpf.pkl')\n",
    "real_df_nimfa = pd.read_pickle('./real_df_nimfa.pkl')\n",
    "\n",
    "real_df = pd.concat([real_df_bmf, real_df_mpf, real_df_nimfa, real_df_binmf], ignore_index=True)\n",
    "\n",
    "# load synthetic data\n",
    "synth_df_bmf = pd.read_pickle('./synth_df_bmf.pkl')\n",
    "synth_df_binmf = pd.read_pickle('./synth_df_binmf.pkl')\n",
    "synth_df_mpf = pd.read_pickle('./synth_mpf.pkl')\n",
    "synth_df_nimfa = pd.read_pickle('./synth_df_nimfa.pkl')\n",
    "\n",
    "synth_df = pd.concat([synth_df_bmf, synth_df_binmf, synth_df_mpf, synth_df_nimfa])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a48651c",
   "metadata": {},
   "source": [
    "## Results for Real Data\n",
    "\n",
    "Here we show the Frobenius norm error and Runtime (in seconds) for each algorithm on real datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "74b4f476",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Error</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>binmf</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+</th>\n",
       "      <th>mpbmf</th>\n",
       "      <th>nimfa</th>\n",
       "      <th>binmf</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+</th>\n",
       "      <th>mpbmf</th>\n",
       "      <th>nimfa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">congress</th>\n",
       "      <th>2</th>\n",
       "      <td>36.458482</td>\n",
       "      <td>40.037482</td>\n",
       "      <td>38.820098</td>\n",
       "      <td>38.809791</td>\n",
       "      <td>36.359318</td>\n",
       "      <td>0.090348</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.280718</td>\n",
       "      <td>0.006909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.512418</td>\n",
       "      <td>38.363051</td>\n",
       "      <td>36.624927</td>\n",
       "      <td>35.889981</td>\n",
       "      <td>32.710854</td>\n",
       "      <td>0.102086</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>0.311166</td>\n",
       "      <td>0.013638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24.286930</td>\n",
       "      <td>35.696393</td>\n",
       "      <td>32.712793</td>\n",
       "      <td>31.141360</td>\n",
       "      <td>27.748874</td>\n",
       "      <td>0.119905</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.332855</td>\n",
       "      <td>0.016217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.899723</td>\n",
       "      <td>32.730459</td>\n",
       "      <td>23.919929</td>\n",
       "      <td>22.471524</td>\n",
       "      <td>18.439089</td>\n",
       "      <td>0.102877</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.016910</td>\n",
       "      <td>0.407083</td>\n",
       "      <td>0.022573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.929173</td>\n",
       "      <td>14.807827</td>\n",
       "      <td>15.469016</td>\n",
       "      <td>9.591663</td>\n",
       "      <td>0.089422</td>\n",
       "      <td>0.007394</td>\n",
       "      <td>0.246655</td>\n",
       "      <td>0.480527</td>\n",
       "      <td>0.027471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">orl</th>\n",
       "      <th>2</th>\n",
       "      <td>33.713419</td>\n",
       "      <td>39.376678</td>\n",
       "      <td>37.785530</td>\n",
       "      <td>35.857652</td>\n",
       "      <td>33.521305</td>\n",
       "      <td>0.090572</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.203744</td>\n",
       "      <td>0.011625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.626366</td>\n",
       "      <td>35.716104</td>\n",
       "      <td>34.569188</td>\n",
       "      <td>32.237612</td>\n",
       "      <td>29.711777</td>\n",
       "      <td>0.088825</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.241613</td>\n",
       "      <td>0.013129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.105650</td>\n",
       "      <td>31.672486</td>\n",
       "      <td>30.712163</td>\n",
       "      <td>27.680846</td>\n",
       "      <td>25.577315</td>\n",
       "      <td>0.084834</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.005817</td>\n",
       "      <td>0.289372</td>\n",
       "      <td>0.015375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.099023</td>\n",
       "      <td>26.449686</td>\n",
       "      <td>25.714423</td>\n",
       "      <td>21.628539</td>\n",
       "      <td>21.382890</td>\n",
       "      <td>0.081724</td>\n",
       "      <td>0.004258</td>\n",
       "      <td>0.022310</td>\n",
       "      <td>0.415707</td>\n",
       "      <td>0.019140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.205162</td>\n",
       "      <td>23.414144</td>\n",
       "      <td>22.794089</td>\n",
       "      <td>17.845095</td>\n",
       "      <td>19.691523</td>\n",
       "      <td>0.081194</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>0.318042</td>\n",
       "      <td>0.575532</td>\n",
       "      <td>0.022177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">thyroid</th>\n",
       "      <th>2</th>\n",
       "      <td>95.822162</td>\n",
       "      <td>106.600675</td>\n",
       "      <td>98.622961</td>\n",
       "      <td>90.474314</td>\n",
       "      <td>91.580566</td>\n",
       "      <td>0.376068</td>\n",
       "      <td>0.012622</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>7.063550</td>\n",
       "      <td>0.044308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.365356</td>\n",
       "      <td>94.480695</td>\n",
       "      <td>90.472925</td>\n",
       "      <td>75.475512</td>\n",
       "      <td>73.925638</td>\n",
       "      <td>0.312943</td>\n",
       "      <td>0.014406</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>7.822042</td>\n",
       "      <td>0.092907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.023772</td>\n",
       "      <td>82.704286</td>\n",
       "      <td>80.395914</td>\n",
       "      <td>78.513723</td>\n",
       "      <td>61.846584</td>\n",
       "      <td>0.398811</td>\n",
       "      <td>0.031802</td>\n",
       "      <td>0.025212</td>\n",
       "      <td>8.860249</td>\n",
       "      <td>0.132118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23.591007</td>\n",
       "      <td>66.032060</td>\n",
       "      <td>55.419848</td>\n",
       "      <td>54.045930</td>\n",
       "      <td>52.933921</td>\n",
       "      <td>0.346888</td>\n",
       "      <td>0.028935</td>\n",
       "      <td>0.059646</td>\n",
       "      <td>12.686316</td>\n",
       "      <td>0.241407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.571106</td>\n",
       "      <td>57.552221</td>\n",
       "      <td>38.903848</td>\n",
       "      <td>39.232925</td>\n",
       "      <td>46.711883</td>\n",
       "      <td>0.348516</td>\n",
       "      <td>0.026658</td>\n",
       "      <td>0.313364</td>\n",
       "      <td>16.237675</td>\n",
       "      <td>0.432735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Error                                                   Time  \\\n",
       "Algorithm        binmf         bmf       bmf+      mpbmf      nimfa     binmf   \n",
       "Dataset  k                                                                      \n",
       "congress 2   36.458482   40.037482  38.820098  38.809791  36.359318  0.090348   \n",
       "         3   32.512418   38.363051  36.624927  35.889981  32.710854  0.102086   \n",
       "         5   24.286930   35.696393  32.712793  31.141360  27.748874  0.119905   \n",
       "         10   5.899723   32.730459  23.919929  22.471524  18.439089  0.102877   \n",
       "         15   0.000000   30.929173  14.807827  15.469016   9.591663  0.089422   \n",
       "orl      2   33.713419   39.376678  37.785530  35.857652  33.521305  0.090572   \n",
       "         3   28.626366   35.716104  34.569188  32.237612  29.711777  0.088825   \n",
       "         5   22.105650   31.672486  30.712163  27.680846  25.577315  0.084834   \n",
       "         10  12.099023   26.449686  25.714423  21.628539  21.382890  0.081724   \n",
       "         15   5.205162   23.414144  22.794089  17.845095  19.691523  0.081194   \n",
       "thyroid  2   95.822162  106.600675  98.622961  90.474314  91.580566  0.376068   \n",
       "         3   84.365356   94.480695  90.472925  75.475512  73.925638  0.312943   \n",
       "         5   50.023772   82.704286  80.395914  78.513723  61.846584  0.398811   \n",
       "         10  23.591007   66.032060  55.419848  54.045930  52.933921  0.346888   \n",
       "         15   3.571106   57.552221  38.903848  39.232925  46.711883  0.348516   \n",
       "\n",
       "                                                      \n",
       "Algorithm         bmf      bmf+      mpbmf     nimfa  \n",
       "Dataset  k                                            \n",
       "congress 2   0.001975  0.003310   0.280718  0.006909  \n",
       "         3   0.002328  0.004103   0.311166  0.013638  \n",
       "         5   0.004624  0.005205   0.332855  0.016217  \n",
       "         10  0.003197  0.016910   0.407083  0.022573  \n",
       "         15  0.007394  0.246655   0.480527  0.027471  \n",
       "orl      2   0.001990  0.002936   0.203744  0.011625  \n",
       "         3   0.002908  0.004662   0.241613  0.013129  \n",
       "         5   0.003809  0.005817   0.289372  0.015375  \n",
       "         10  0.004258  0.022310   0.415707  0.019140  \n",
       "         15  0.006068  0.318042   0.575532  0.022177  \n",
       "thyroid  2   0.012622  0.014159   7.063550  0.044308  \n",
       "         3   0.014406  0.018722   7.822042  0.092907  \n",
       "         5   0.031802  0.025212   8.860249  0.132118  \n",
       "         10  0.028935  0.059646  12.686316  0.241407  \n",
       "         15  0.026658  0.313364  16.237675  0.432735  "
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = real_df.groupby(['Dataset', 'k', 'Algorithm']).mean()\n",
    "grouped_df.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ffa5ec",
   "metadata": {},
   "source": [
    "## Results for Synthetic Data\n",
    "\n",
    "Here we show the Frobenius norm error and Runtime (in seconds) for each algorithm on synthetic datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "86675a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Error</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>binmf</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+</th>\n",
       "      <th>mpbmf</th>\n",
       "      <th>nimfa</th>\n",
       "      <th>binmf</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+</th>\n",
       "      <th>mpbmf</th>\n",
       "      <th>nimfa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">full</th>\n",
       "      <th>2</th>\n",
       "      <td>73.344298</td>\n",
       "      <td>75.750915</td>\n",
       "      <td>72.333028</td>\n",
       "      <td>71.256986</td>\n",
       "      <td>71.321495</td>\n",
       "      <td>0.177331</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>0.008610</td>\n",
       "      <td>0.280658</td>\n",
       "      <td>0.011552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.831318</td>\n",
       "      <td>74.280728</td>\n",
       "      <td>69.928525</td>\n",
       "      <td>69.385181</td>\n",
       "      <td>68.674021</td>\n",
       "      <td>0.140231</td>\n",
       "      <td>0.014863</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.309760</td>\n",
       "      <td>0.011651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69.252822</td>\n",
       "      <td>72.157767</td>\n",
       "      <td>65.764912</td>\n",
       "      <td>66.563674</td>\n",
       "      <td>64.856944</td>\n",
       "      <td>0.139583</td>\n",
       "      <td>0.010872</td>\n",
       "      <td>0.011492</td>\n",
       "      <td>0.347684</td>\n",
       "      <td>0.013350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62.785281</td>\n",
       "      <td>68.657704</td>\n",
       "      <td>57.353965</td>\n",
       "      <td>61.535130</td>\n",
       "      <td>58.478444</td>\n",
       "      <td>0.203146</td>\n",
       "      <td>0.015410</td>\n",
       "      <td>0.053407</td>\n",
       "      <td>0.486640</td>\n",
       "      <td>0.017212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>56.163514</td>\n",
       "      <td>66.404657</td>\n",
       "      <td>50.373358</td>\n",
       "      <td>57.918306</td>\n",
       "      <td>53.723584</td>\n",
       "      <td>0.232967</td>\n",
       "      <td>0.016217</td>\n",
       "      <td>0.272142</td>\n",
       "      <td>0.667299</td>\n",
       "      <td>0.021675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">full0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>43.009379</td>\n",
       "      <td>36.000430</td>\n",
       "      <td>35.010907</td>\n",
       "      <td>34.946703</td>\n",
       "      <td>35.164001</td>\n",
       "      <td>0.098257</td>\n",
       "      <td>0.010760</td>\n",
       "      <td>0.011347</td>\n",
       "      <td>0.277318</td>\n",
       "      <td>0.009876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.409356</td>\n",
       "      <td>35.899464</td>\n",
       "      <td>34.884510</td>\n",
       "      <td>34.948634</td>\n",
       "      <td>34.976351</td>\n",
       "      <td>0.094788</td>\n",
       "      <td>0.007534</td>\n",
       "      <td>0.013918</td>\n",
       "      <td>0.302109</td>\n",
       "      <td>0.010645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39.331131</td>\n",
       "      <td>35.637114</td>\n",
       "      <td>34.608827</td>\n",
       "      <td>35.530870</td>\n",
       "      <td>34.223749</td>\n",
       "      <td>0.088861</td>\n",
       "      <td>0.012673</td>\n",
       "      <td>0.018454</td>\n",
       "      <td>0.336946</td>\n",
       "      <td>0.012633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>34.073479</td>\n",
       "      <td>35.023489</td>\n",
       "      <td>33.868040</td>\n",
       "      <td>35.812739</td>\n",
       "      <td>31.749037</td>\n",
       "      <td>0.094921</td>\n",
       "      <td>0.017044</td>\n",
       "      <td>0.064458</td>\n",
       "      <td>0.459616</td>\n",
       "      <td>0.015913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29.300266</td>\n",
       "      <td>34.317619</td>\n",
       "      <td>33.025709</td>\n",
       "      <td>38.451906</td>\n",
       "      <td>28.995963</td>\n",
       "      <td>0.102995</td>\n",
       "      <td>0.020859</td>\n",
       "      <td>0.269500</td>\n",
       "      <td>0.628404</td>\n",
       "      <td>0.019576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr10</th>\n",
       "      <th>2</th>\n",
       "      <td>73.169735</td>\n",
       "      <td>75.817642</td>\n",
       "      <td>72.161664</td>\n",
       "      <td>71.090447</td>\n",
       "      <td>71.680565</td>\n",
       "      <td>0.171184</td>\n",
       "      <td>0.013379</td>\n",
       "      <td>0.015495</td>\n",
       "      <td>0.281237</td>\n",
       "      <td>0.011453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.561317</td>\n",
       "      <td>74.320028</td>\n",
       "      <td>69.554721</td>\n",
       "      <td>69.135761</td>\n",
       "      <td>68.961825</td>\n",
       "      <td>0.174765</td>\n",
       "      <td>0.015792</td>\n",
       "      <td>0.020046</td>\n",
       "      <td>0.308018</td>\n",
       "      <td>0.011711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68.815887</td>\n",
       "      <td>72.048301</td>\n",
       "      <td>64.746181</td>\n",
       "      <td>66.119482</td>\n",
       "      <td>64.841498</td>\n",
       "      <td>0.223248</td>\n",
       "      <td>0.020858</td>\n",
       "      <td>0.019687</td>\n",
       "      <td>0.345483</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>61.768702</td>\n",
       "      <td>68.193327</td>\n",
       "      <td>28.368406</td>\n",
       "      <td>60.222202</td>\n",
       "      <td>57.948659</td>\n",
       "      <td>0.289431</td>\n",
       "      <td>0.016190</td>\n",
       "      <td>0.051420</td>\n",
       "      <td>0.477845</td>\n",
       "      <td>0.017268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55.343812</td>\n",
       "      <td>65.645340</td>\n",
       "      <td>0.799573</td>\n",
       "      <td>56.017076</td>\n",
       "      <td>52.942195</td>\n",
       "      <td>0.264179</td>\n",
       "      <td>0.019311</td>\n",
       "      <td>0.245181</td>\n",
       "      <td>0.659640</td>\n",
       "      <td>0.021258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr10-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>32.765260</td>\n",
       "      <td>30.820627</td>\n",
       "      <td>30.521675</td>\n",
       "      <td>27.625313</td>\n",
       "      <td>28.510833</td>\n",
       "      <td>0.073599</td>\n",
       "      <td>0.010030</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>0.213402</td>\n",
       "      <td>0.005664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.609959</td>\n",
       "      <td>28.506134</td>\n",
       "      <td>28.131885</td>\n",
       "      <td>25.238997</td>\n",
       "      <td>25.479182</td>\n",
       "      <td>0.074419</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>0.013308</td>\n",
       "      <td>0.248525</td>\n",
       "      <td>0.011488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.199439</td>\n",
       "      <td>24.734379</td>\n",
       "      <td>23.198115</td>\n",
       "      <td>20.365842</td>\n",
       "      <td>19.927415</td>\n",
       "      <td>0.068856</td>\n",
       "      <td>0.013058</td>\n",
       "      <td>0.018687</td>\n",
       "      <td>0.291977</td>\n",
       "      <td>0.013395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.605244</td>\n",
       "      <td>18.313160</td>\n",
       "      <td>10.201085</td>\n",
       "      <td>7.566958</td>\n",
       "      <td>8.757867</td>\n",
       "      <td>0.072697</td>\n",
       "      <td>0.016362</td>\n",
       "      <td>0.076154</td>\n",
       "      <td>0.434597</td>\n",
       "      <td>0.016920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.196752</td>\n",
       "      <td>15.221658</td>\n",
       "      <td>2.504529</td>\n",
       "      <td>4.691869</td>\n",
       "      <td>5.410569</td>\n",
       "      <td>0.065885</td>\n",
       "      <td>0.014753</td>\n",
       "      <td>0.261326</td>\n",
       "      <td>0.638779</td>\n",
       "      <td>0.022075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr15</th>\n",
       "      <th>2</th>\n",
       "      <td>73.461105</td>\n",
       "      <td>75.708405</td>\n",
       "      <td>72.273592</td>\n",
       "      <td>71.187829</td>\n",
       "      <td>71.268859</td>\n",
       "      <td>0.279565</td>\n",
       "      <td>0.014452</td>\n",
       "      <td>0.018608</td>\n",
       "      <td>0.277588</td>\n",
       "      <td>0.011339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.885052</td>\n",
       "      <td>74.246647</td>\n",
       "      <td>69.898775</td>\n",
       "      <td>69.338224</td>\n",
       "      <td>68.712767</td>\n",
       "      <td>0.232276</td>\n",
       "      <td>0.012746</td>\n",
       "      <td>0.011133</td>\n",
       "      <td>0.306455</td>\n",
       "      <td>0.011698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69.421449</td>\n",
       "      <td>72.067391</td>\n",
       "      <td>65.710864</td>\n",
       "      <td>66.565762</td>\n",
       "      <td>64.809208</td>\n",
       "      <td>0.225033</td>\n",
       "      <td>0.014997</td>\n",
       "      <td>0.019006</td>\n",
       "      <td>0.339678</td>\n",
       "      <td>0.013028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62.643136</td>\n",
       "      <td>68.609598</td>\n",
       "      <td>56.540031</td>\n",
       "      <td>61.474079</td>\n",
       "      <td>58.391770</td>\n",
       "      <td>0.140653</td>\n",
       "      <td>0.018659</td>\n",
       "      <td>0.051422</td>\n",
       "      <td>0.478283</td>\n",
       "      <td>0.017195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>56.199033</td>\n",
       "      <td>66.368334</td>\n",
       "      <td>29.212435</td>\n",
       "      <td>57.732194</td>\n",
       "      <td>53.589677</td>\n",
       "      <td>0.144722</td>\n",
       "      <td>0.013021</td>\n",
       "      <td>0.239873</td>\n",
       "      <td>0.652809</td>\n",
       "      <td>0.021137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr15-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>39.467855</td>\n",
       "      <td>38.697035</td>\n",
       "      <td>38.229198</td>\n",
       "      <td>35.638083</td>\n",
       "      <td>36.530253</td>\n",
       "      <td>0.090266</td>\n",
       "      <td>0.012055</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>0.242158</td>\n",
       "      <td>0.009670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.376478</td>\n",
       "      <td>37.087185</td>\n",
       "      <td>36.190913</td>\n",
       "      <td>33.650332</td>\n",
       "      <td>34.211802</td>\n",
       "      <td>0.094768</td>\n",
       "      <td>0.009987</td>\n",
       "      <td>0.013022</td>\n",
       "      <td>0.274059</td>\n",
       "      <td>0.012790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.334947</td>\n",
       "      <td>33.716537</td>\n",
       "      <td>32.177006</td>\n",
       "      <td>29.832138</td>\n",
       "      <td>29.483310</td>\n",
       "      <td>0.090495</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>0.313237</td>\n",
       "      <td>0.014645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.518119</td>\n",
       "      <td>28.122054</td>\n",
       "      <td>22.340419</td>\n",
       "      <td>20.330422</td>\n",
       "      <td>19.781748</td>\n",
       "      <td>0.069222</td>\n",
       "      <td>0.020178</td>\n",
       "      <td>0.056258</td>\n",
       "      <td>0.457335</td>\n",
       "      <td>0.017878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.752210</td>\n",
       "      <td>25.274851</td>\n",
       "      <td>14.232960</td>\n",
       "      <td>11.597783</td>\n",
       "      <td>13.381887</td>\n",
       "      <td>0.085105</td>\n",
       "      <td>0.021152</td>\n",
       "      <td>0.247893</td>\n",
       "      <td>0.643755</td>\n",
       "      <td>0.021234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr5</th>\n",
       "      <th>2</th>\n",
       "      <td>66.111364</td>\n",
       "      <td>72.472089</td>\n",
       "      <td>67.098743</td>\n",
       "      <td>66.013343</td>\n",
       "      <td>67.823084</td>\n",
       "      <td>0.195308</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.007883</td>\n",
       "      <td>0.274857</td>\n",
       "      <td>0.011892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.581214</td>\n",
       "      <td>69.161153</td>\n",
       "      <td>60.017709</td>\n",
       "      <td>62.280223</td>\n",
       "      <td>64.038011</td>\n",
       "      <td>0.168244</td>\n",
       "      <td>0.012764</td>\n",
       "      <td>0.012004</td>\n",
       "      <td>0.301523</td>\n",
       "      <td>0.013537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53.020314</td>\n",
       "      <td>63.956862</td>\n",
       "      <td>26.933413</td>\n",
       "      <td>55.245308</td>\n",
       "      <td>56.724761</td>\n",
       "      <td>0.152431</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.339839</td>\n",
       "      <td>0.015420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>34.338310</td>\n",
       "      <td>52.869364</td>\n",
       "      <td>0.693289</td>\n",
       "      <td>41.015698</td>\n",
       "      <td>42.546584</td>\n",
       "      <td>0.136435</td>\n",
       "      <td>0.014717</td>\n",
       "      <td>0.072737</td>\n",
       "      <td>0.472532</td>\n",
       "      <td>0.019469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19.072401</td>\n",
       "      <td>43.320731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.752151</td>\n",
       "      <td>31.133041</td>\n",
       "      <td>0.127316</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>0.658014</td>\n",
       "      <td>0.023838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr5-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>20.671033</td>\n",
       "      <td>20.506771</td>\n",
       "      <td>20.369701</td>\n",
       "      <td>16.458187</td>\n",
       "      <td>15.809840</td>\n",
       "      <td>0.072242</td>\n",
       "      <td>0.009361</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>0.185606</td>\n",
       "      <td>0.004770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.877655</td>\n",
       "      <td>16.982355</td>\n",
       "      <td>16.581775</td>\n",
       "      <td>13.068700</td>\n",
       "      <td>11.961674</td>\n",
       "      <td>0.064584</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.209091</td>\n",
       "      <td>0.012251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.529595</td>\n",
       "      <td>11.121688</td>\n",
       "      <td>8.431304</td>\n",
       "      <td>4.618262</td>\n",
       "      <td>5.122947</td>\n",
       "      <td>0.075819</td>\n",
       "      <td>0.007038</td>\n",
       "      <td>0.008039</td>\n",
       "      <td>0.275875</td>\n",
       "      <td>0.014790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.149004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.723558</td>\n",
       "      <td>2.347018</td>\n",
       "      <td>0.076249</td>\n",
       "      <td>0.019299</td>\n",
       "      <td>0.074956</td>\n",
       "      <td>0.460467</td>\n",
       "      <td>0.018124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.519957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383233</td>\n",
       "      <td>1.447927</td>\n",
       "      <td>0.066698</td>\n",
       "      <td>0.020186</td>\n",
       "      <td>0.297033</td>\n",
       "      <td>0.630887</td>\n",
       "      <td>0.022105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-0001</th>\n",
       "      <th>2</th>\n",
       "      <td>73.371909</td>\n",
       "      <td>75.830112</td>\n",
       "      <td>72.314566</td>\n",
       "      <td>71.212894</td>\n",
       "      <td>71.573618</td>\n",
       "      <td>0.154078</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>0.012840</td>\n",
       "      <td>0.290358</td>\n",
       "      <td>0.011308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.633068</td>\n",
       "      <td>74.332280</td>\n",
       "      <td>69.618142</td>\n",
       "      <td>69.270222</td>\n",
       "      <td>69.007748</td>\n",
       "      <td>0.156375</td>\n",
       "      <td>0.013779</td>\n",
       "      <td>0.015563</td>\n",
       "      <td>0.309285</td>\n",
       "      <td>0.011601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68.985594</td>\n",
       "      <td>72.054578</td>\n",
       "      <td>64.695129</td>\n",
       "      <td>66.218066</td>\n",
       "      <td>64.964312</td>\n",
       "      <td>0.144317</td>\n",
       "      <td>0.017590</td>\n",
       "      <td>0.023805</td>\n",
       "      <td>0.345791</td>\n",
       "      <td>0.013636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62.120176</td>\n",
       "      <td>68.194114</td>\n",
       "      <td>33.776000</td>\n",
       "      <td>60.342012</td>\n",
       "      <td>58.077464</td>\n",
       "      <td>0.141350</td>\n",
       "      <td>0.016828</td>\n",
       "      <td>0.053969</td>\n",
       "      <td>0.481068</td>\n",
       "      <td>0.017556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55.412943</td>\n",
       "      <td>65.566467</td>\n",
       "      <td>4.821331</td>\n",
       "      <td>56.164721</td>\n",
       "      <td>53.212566</td>\n",
       "      <td>0.151302</td>\n",
       "      <td>0.018362</td>\n",
       "      <td>0.247057</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.021622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-0001-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>33.303616</td>\n",
       "      <td>32.482432</td>\n",
       "      <td>32.142283</td>\n",
       "      <td>29.307728</td>\n",
       "      <td>29.963531</td>\n",
       "      <td>0.081998</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.223646</td>\n",
       "      <td>0.007564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.460065</td>\n",
       "      <td>30.046449</td>\n",
       "      <td>29.523761</td>\n",
       "      <td>26.942610</td>\n",
       "      <td>27.099691</td>\n",
       "      <td>0.077983</td>\n",
       "      <td>0.006387</td>\n",
       "      <td>0.010063</td>\n",
       "      <td>0.255379</td>\n",
       "      <td>0.011568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.396051</td>\n",
       "      <td>26.152327</td>\n",
       "      <td>24.632310</td>\n",
       "      <td>21.993109</td>\n",
       "      <td>21.320073</td>\n",
       "      <td>0.072059</td>\n",
       "      <td>0.006637</td>\n",
       "      <td>0.009697</td>\n",
       "      <td>0.291923</td>\n",
       "      <td>0.013541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.687233</td>\n",
       "      <td>19.784124</td>\n",
       "      <td>12.015600</td>\n",
       "      <td>9.252733</td>\n",
       "      <td>10.449424</td>\n",
       "      <td>0.071803</td>\n",
       "      <td>0.016357</td>\n",
       "      <td>0.067387</td>\n",
       "      <td>0.441153</td>\n",
       "      <td>0.018231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.168419</td>\n",
       "      <td>16.698047</td>\n",
       "      <td>4.913025</td>\n",
       "      <td>6.835038</td>\n",
       "      <td>7.201189</td>\n",
       "      <td>0.073849</td>\n",
       "      <td>0.013914</td>\n",
       "      <td>0.254960</td>\n",
       "      <td>0.641788</td>\n",
       "      <td>0.022376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-001</th>\n",
       "      <th>2</th>\n",
       "      <td>73.081826</td>\n",
       "      <td>75.795304</td>\n",
       "      <td>72.079907</td>\n",
       "      <td>70.980806</td>\n",
       "      <td>71.675296</td>\n",
       "      <td>0.139399</td>\n",
       "      <td>0.009654</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>0.276129</td>\n",
       "      <td>0.011360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.388300</td>\n",
       "      <td>74.325448</td>\n",
       "      <td>69.534284</td>\n",
       "      <td>69.028929</td>\n",
       "      <td>69.070412</td>\n",
       "      <td>0.139142</td>\n",
       "      <td>0.012133</td>\n",
       "      <td>0.013341</td>\n",
       "      <td>0.302450</td>\n",
       "      <td>0.011976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68.799062</td>\n",
       "      <td>72.038974</td>\n",
       "      <td>64.659731</td>\n",
       "      <td>66.010443</td>\n",
       "      <td>64.777670</td>\n",
       "      <td>0.146974</td>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.012517</td>\n",
       "      <td>0.338912</td>\n",
       "      <td>0.013408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>61.690641</td>\n",
       "      <td>68.305561</td>\n",
       "      <td>38.203974</td>\n",
       "      <td>60.187646</td>\n",
       "      <td>57.926486</td>\n",
       "      <td>0.149543</td>\n",
       "      <td>0.015029</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>0.474954</td>\n",
       "      <td>0.017228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55.107302</td>\n",
       "      <td>65.704424</td>\n",
       "      <td>16.733824</td>\n",
       "      <td>56.072349</td>\n",
       "      <td>52.782413</td>\n",
       "      <td>0.149078</td>\n",
       "      <td>0.018006</td>\n",
       "      <td>0.254025</td>\n",
       "      <td>0.672944</td>\n",
       "      <td>0.021290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-001-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>39.271263</td>\n",
       "      <td>33.260074</td>\n",
       "      <td>33.025713</td>\n",
       "      <td>30.274989</td>\n",
       "      <td>30.929522</td>\n",
       "      <td>0.071764</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.011524</td>\n",
       "      <td>0.225325</td>\n",
       "      <td>0.009243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.258272</td>\n",
       "      <td>31.264094</td>\n",
       "      <td>30.769495</td>\n",
       "      <td>28.162254</td>\n",
       "      <td>28.001292</td>\n",
       "      <td>0.086274</td>\n",
       "      <td>0.010768</td>\n",
       "      <td>0.010503</td>\n",
       "      <td>0.257513</td>\n",
       "      <td>0.012461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.124579</td>\n",
       "      <td>27.813954</td>\n",
       "      <td>26.165476</td>\n",
       "      <td>23.634714</td>\n",
       "      <td>23.350200</td>\n",
       "      <td>0.085855</td>\n",
       "      <td>0.009358</td>\n",
       "      <td>0.018329</td>\n",
       "      <td>0.292094</td>\n",
       "      <td>0.014269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.429582</td>\n",
       "      <td>22.281945</td>\n",
       "      <td>16.344174</td>\n",
       "      <td>14.032479</td>\n",
       "      <td>15.068175</td>\n",
       "      <td>0.077576</td>\n",
       "      <td>0.021040</td>\n",
       "      <td>0.058539</td>\n",
       "      <td>0.448510</td>\n",
       "      <td>0.017439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.958691</td>\n",
       "      <td>19.904945</td>\n",
       "      <td>12.452179</td>\n",
       "      <td>12.507805</td>\n",
       "      <td>12.005887</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.020513</td>\n",
       "      <td>0.260330</td>\n",
       "      <td>0.645429</td>\n",
       "      <td>0.021742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Error                                              \\\n",
       "Algorithm                binmf        bmf       bmf+      mpbmf      nimfa   \n",
       "Dataset          k                                                           \n",
       "full             2   73.344298  75.750915  72.333028  71.256986  71.321495   \n",
       "                 3   71.831318  74.280728  69.928525  69.385181  68.674021   \n",
       "                 5   69.252822  72.157767  65.764912  66.563674  64.856944   \n",
       "                 10  62.785281  68.657704  57.353965  61.535130  58.478444   \n",
       "                 15  56.163514  66.404657  50.373358  57.918306  53.723584   \n",
       "full0.1          2   43.009379  36.000430  35.010907  34.946703  35.164001   \n",
       "                 3   42.409356  35.899464  34.884510  34.948634  34.976351   \n",
       "                 5   39.331131  35.637114  34.608827  35.530870  34.223749   \n",
       "                 10  34.073479  35.023489  33.868040  35.812739  31.749037   \n",
       "                 15  29.300266  34.317619  33.025709  38.451906  28.995963   \n",
       "lr10             2   73.169735  75.817642  72.161664  71.090447  71.680565   \n",
       "                 3   71.561317  74.320028  69.554721  69.135761  68.961825   \n",
       "                 5   68.815887  72.048301  64.746181  66.119482  64.841498   \n",
       "                 10  61.768702  68.193327  28.368406  60.222202  57.948659   \n",
       "                 15  55.343812  65.645340   0.799573  56.017076  52.942195   \n",
       "lr10-0.1         2   32.765260  30.820627  30.521675  27.625313  28.510833   \n",
       "                 3   28.609959  28.506134  28.131885  25.238997  25.479182   \n",
       "                 5   17.199439  24.734379  23.198115  20.365842  19.927415   \n",
       "                 10   2.605244  18.313160  10.201085   7.566958   8.757867   \n",
       "                 15   0.196752  15.221658   2.504529   4.691869   5.410569   \n",
       "lr15             2   73.461105  75.708405  72.273592  71.187829  71.268859   \n",
       "                 3   71.885052  74.246647  69.898775  69.338224  68.712767   \n",
       "                 5   69.421449  72.067391  65.710864  66.565762  64.809208   \n",
       "                 10  62.643136  68.609598  56.540031  61.474079  58.391770   \n",
       "                 15  56.199033  66.368334  29.212435  57.732194  53.589677   \n",
       "lr15-0.1         2   39.467855  38.697035  38.229198  35.638083  36.530253   \n",
       "                 3   37.376478  37.087185  36.190913  33.650332  34.211802   \n",
       "                 5   30.334947  33.716537  32.177006  29.832138  29.483310   \n",
       "                 10  13.518119  28.122054  22.340419  20.330422  19.781748   \n",
       "                 15   3.752210  25.274851  14.232960  11.597783  13.381887   \n",
       "lr5              2   66.111364  72.472089  67.098743  66.013343  67.823084   \n",
       "                 3   61.581214  69.161153  60.017709  62.280223  64.038011   \n",
       "                 5   53.020314  63.956862  26.933413  55.245308  56.724761   \n",
       "                 10  34.338310  52.869364   0.693289  41.015698  42.546584   \n",
       "                 15  19.072401  43.320731   0.000000  32.752151  31.133041   \n",
       "lr5-0.1          2   20.671033  20.506771  20.369701  16.458187  15.809840   \n",
       "                 3   12.877655  16.982355  16.581775  13.068700  11.961674   \n",
       "                 5    2.529595  11.121688   8.431304   4.618262   5.122947   \n",
       "                 10   0.000000   5.149004   0.000000   0.723558   2.347018   \n",
       "                 15   0.000000   1.519957   0.000000   0.383233   1.447927   \n",
       "noisy10-0001     2   73.371909  75.830112  72.314566  71.212894  71.573618   \n",
       "                 3   71.633068  74.332280  69.618142  69.270222  69.007748   \n",
       "                 5   68.985594  72.054578  64.695129  66.218066  64.964312   \n",
       "                 10  62.120176  68.194114  33.776000  60.342012  58.077464   \n",
       "                 15  55.412943  65.566467   4.821331  56.164721  53.212566   \n",
       "noisy10-0001-0.1 2   33.303616  32.482432  32.142283  29.307728  29.963531   \n",
       "                 3   29.460065  30.046449  29.523761  26.942610  27.099691   \n",
       "                 5   19.396051  26.152327  24.632310  21.993109  21.320073   \n",
       "                 10   5.687233  19.784124  12.015600   9.252733  10.449424   \n",
       "                 15   2.168419  16.698047   4.913025   6.835038   7.201189   \n",
       "noisy10-001      2   73.081826  75.795304  72.079907  70.980806  71.675296   \n",
       "                 3   71.388300  74.325448  69.534284  69.028929  69.070412   \n",
       "                 5   68.799062  72.038974  64.659731  66.010443  64.777670   \n",
       "                 10  61.690641  68.305561  38.203974  60.187646  57.926486   \n",
       "                 15  55.107302  65.704424  16.733824  56.072349  52.782413   \n",
       "noisy10-001-0.1  2   39.271263  33.260074  33.025713  30.274989  30.929522   \n",
       "                 3   36.258272  31.264094  30.769495  28.162254  28.001292   \n",
       "                 5   28.124579  27.813954  26.165476  23.634714  23.350200   \n",
       "                 10  13.429582  22.281945  16.344174  14.032479  15.068175   \n",
       "                 15   5.958691  19.904945  12.452179  12.507805  12.005887   \n",
       "\n",
       "                         Time                                          \n",
       "Algorithm               binmf       bmf      bmf+     mpbmf     nimfa  \n",
       "Dataset          k                                                     \n",
       "full             2   0.177331  0.011210  0.008610  0.280658  0.011552  \n",
       "                 3   0.140231  0.014863  0.012492  0.309760  0.011651  \n",
       "                 5   0.139583  0.010872  0.011492  0.347684  0.013350  \n",
       "                 10  0.203146  0.015410  0.053407  0.486640  0.017212  \n",
       "                 15  0.232967  0.016217  0.272142  0.667299  0.021675  \n",
       "full0.1          2   0.098257  0.010760  0.011347  0.277318  0.009876  \n",
       "                 3   0.094788  0.007534  0.013918  0.302109  0.010645  \n",
       "                 5   0.088861  0.012673  0.018454  0.336946  0.012633  \n",
       "                 10  0.094921  0.017044  0.064458  0.459616  0.015913  \n",
       "                 15  0.102995  0.020859  0.269500  0.628404  0.019576  \n",
       "lr10             2   0.171184  0.013379  0.015495  0.281237  0.011453  \n",
       "                 3   0.174765  0.015792  0.020046  0.308018  0.011711  \n",
       "                 5   0.223248  0.020858  0.019687  0.345483  0.013624  \n",
       "                 10  0.289431  0.016190  0.051420  0.477845  0.017268  \n",
       "                 15  0.264179  0.019311  0.245181  0.659640  0.021258  \n",
       "lr10-0.1         2   0.073599  0.010030  0.014258  0.213402  0.005664  \n",
       "                 3   0.074419  0.011076  0.013308  0.248525  0.011488  \n",
       "                 5   0.068856  0.013058  0.018687  0.291977  0.013395  \n",
       "                 10  0.072697  0.016362  0.076154  0.434597  0.016920  \n",
       "                 15  0.065885  0.014753  0.261326  0.638779  0.022075  \n",
       "lr15             2   0.279565  0.014452  0.018608  0.277588  0.011339  \n",
       "                 3   0.232276  0.012746  0.011133  0.306455  0.011698  \n",
       "                 5   0.225033  0.014997  0.019006  0.339678  0.013028  \n",
       "                 10  0.140653  0.018659  0.051422  0.478283  0.017195  \n",
       "                 15  0.144722  0.013021  0.239873  0.652809  0.021137  \n",
       "lr15-0.1         2   0.090266  0.012055  0.010404  0.242158  0.009670  \n",
       "                 3   0.094768  0.009987  0.013022  0.274059  0.012790  \n",
       "                 5   0.090495  0.013158  0.017917  0.313237  0.014645  \n",
       "                 10  0.069222  0.020178  0.056258  0.457335  0.017878  \n",
       "                 15  0.085105  0.021152  0.247893  0.643755  0.021234  \n",
       "lr5              2   0.195308  0.004060  0.007883  0.274857  0.011892  \n",
       "                 3   0.168244  0.012764  0.012004  0.301523  0.013537  \n",
       "                 5   0.152431  0.010394  0.011867  0.339839  0.015420  \n",
       "                 10  0.136435  0.014717  0.072737  0.472532  0.019469  \n",
       "                 15  0.127316  0.018001  0.295959  0.658014  0.023838  \n",
       "lr5-0.1          2   0.072242  0.009361  0.006258  0.185606  0.004770  \n",
       "                 3   0.064584  0.005006  0.005821  0.209091  0.012251  \n",
       "                 5   0.075819  0.007038  0.008039  0.275875  0.014790  \n",
       "                 10  0.076249  0.019299  0.074956  0.460467  0.018124  \n",
       "                 15  0.066698  0.020186  0.297033  0.630887  0.022105  \n",
       "noisy10-0001     2   0.154078  0.013934  0.012840  0.290358  0.011308  \n",
       "                 3   0.156375  0.013779  0.015563  0.309285  0.011601  \n",
       "                 5   0.144317  0.017590  0.023805  0.345791  0.013636  \n",
       "                 10  0.141350  0.016828  0.053969  0.481068  0.017556  \n",
       "                 15  0.151302  0.018362  0.247057  0.661778  0.021622  \n",
       "noisy10-0001-0.1 2   0.081998  0.006312  0.009583  0.223646  0.007564  \n",
       "                 3   0.077983  0.006387  0.010063  0.255379  0.011568  \n",
       "                 5   0.072059  0.006637  0.009697  0.291923  0.013541  \n",
       "                 10  0.071803  0.016357  0.067387  0.441153  0.018231  \n",
       "                 15  0.073849  0.013914  0.254960  0.641788  0.022376  \n",
       "noisy10-001      2   0.139399  0.009654  0.011388  0.276129  0.011360  \n",
       "                 3   0.139142  0.012133  0.013341  0.302450  0.011976  \n",
       "                 5   0.146974  0.012433  0.012517  0.338912  0.013408  \n",
       "                 10  0.149543  0.015029  0.050654  0.474954  0.017228  \n",
       "                 15  0.149078  0.018006  0.254025  0.672944  0.021290  \n",
       "noisy10-001-0.1  2   0.071764  0.009901  0.011524  0.225325  0.009243  \n",
       "                 3   0.086274  0.010768  0.010503  0.257513  0.012461  \n",
       "                 5   0.085855  0.009358  0.018329  0.292094  0.014269  \n",
       "                 10  0.077576  0.021040  0.058539  0.448510  0.017439  \n",
       "                 15  0.081003  0.020513  0.260330  0.645429  0.021742  "
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = synth_df.groupby(['Dataset', 'k', 'Algorithm']).mean()\n",
    "grouped_df.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3e3543",
   "metadata": {},
   "source": [
    "# Results for $L_p$ Norms and Standard Matrix Product\n",
    "\n",
    "We now showcase the results of $L_p$ loss for the approximations produced by different heuristics.\n",
    "\n",
    "Runtimes have been omitted, as they are the same as in the case of the above experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "ca572822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load real data\n",
    "real_df_bmf = pd.read_pickle('./real_df_bmf_int.pkl')\n",
    "real_df_binmf = pd.read_pickle('./real_df_binmf_int.pkl')\n",
    "real_df_mpf = pd.read_pickle('./real_df_mpf_int.pkl')\n",
    "real_df_nimfa = pd.read_pickle('./real_df_nimfa_int.pkl')\n",
    "\n",
    "real_df = pd.concat([real_df_bmf, real_df_mpf, real_df_nimfa, real_df_binmf], ignore_index=True)\n",
    "real_l1 = real_df.loc[real_df['Algorithm'].isin(['binmf l1', 'bmf', 'bmf+ (int, l1)', 'mpbmf l1', 'nimfa l1'])]\n",
    "real_l2 = real_df.loc[real_df['Algorithm'].isin(['binmf l2', 'bmf', 'bmf+ (int, l2)', 'mpbmf l2', 'nimfa l2'])]\n",
    "real_l5 = real_df.loc[real_df['Algorithm'].isin(['binmf l5', 'bmf', 'bmf+ (int, l5)', 'mpbmf l5', 'nimfa l5'])]\n",
    "\n",
    "\n",
    "# load synthetic data\n",
    "synth_df_bmf = pd.read_pickle('./synth_df_bmf_int.pkl')\n",
    "synth_df_binmf = pd.read_pickle('./synth_df_binmf_int.pkl')\n",
    "synth_df_mpf = pd.read_pickle('./synth_df_mpf_int.pkl')\n",
    "synth_df_nimfa = pd.read_pickle('./synth_df_nimfa_int.pkl')\n",
    "\n",
    "synth_df = pd.concat([synth_df_bmf, synth_df_binmf, synth_df_mpf, synth_df_nimfa])\n",
    "\n",
    "synth_l1 = synth_df.loc[synth_df['Algorithm'].isin(['binmf l1', 'bmf', 'bmf+ (int, l1)', 'mpbmf l1', 'nimfa l1'])]\n",
    "synth_l2 = synth_df.loc[synth_df['Algorithm'].isin(['binmf l2', 'bmf', 'bmf+ (int, l2)', 'mpbmf l2', 'nimfa l2'])]\n",
    "synth_l5 = synth_df.loc[synth_df['Algorithm'].isin(['binmf l5', 'bmf', 'bmf+ (int, l5)', 'mpbmf l5', 'nimfa l5'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "c0b68474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>binmf l1</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+ (int, l1)</th>\n",
       "      <th>mpbmf l1</th>\n",
       "      <th>nimfa l1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">congress</th>\n",
       "      <th>2</th>\n",
       "      <td>2535.40000</td>\n",
       "      <td>1603.00000</td>\n",
       "      <td>1522.00000</td>\n",
       "      <td>1522.70000</td>\n",
       "      <td>2011.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2723.50000</td>\n",
       "      <td>1466.60000</td>\n",
       "      <td>1378.90000</td>\n",
       "      <td>1538.40000</td>\n",
       "      <td>2045.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2614.10000</td>\n",
       "      <td>1267.00000</td>\n",
       "      <td>1167.80000</td>\n",
       "      <td>1763.70000</td>\n",
       "      <td>2264.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3005.40000</td>\n",
       "      <td>1049.20000</td>\n",
       "      <td>969.90000</td>\n",
       "      <td>1876.80000</td>\n",
       "      <td>1102.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2711.40000</td>\n",
       "      <td>920.40000</td>\n",
       "      <td>872.30000</td>\n",
       "      <td>1677.20000</td>\n",
       "      <td>380.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">orl</th>\n",
       "      <th>2</th>\n",
       "      <td>4525.91425</td>\n",
       "      <td>1585.28850</td>\n",
       "      <td>1473.15475</td>\n",
       "      <td>3487.70375</td>\n",
       "      <td>2072.6775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4608.26300</td>\n",
       "      <td>1311.40900</td>\n",
       "      <td>1250.40375</td>\n",
       "      <td>4514.47350</td>\n",
       "      <td>3286.6725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4586.95800</td>\n",
       "      <td>1032.48625</td>\n",
       "      <td>997.73050</td>\n",
       "      <td>5925.21800</td>\n",
       "      <td>4545.2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5081.62300</td>\n",
       "      <td>722.43050</td>\n",
       "      <td>704.79500</td>\n",
       "      <td>8377.60575</td>\n",
       "      <td>3898.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5351.15800</td>\n",
       "      <td>568.44675</td>\n",
       "      <td>556.85200</td>\n",
       "      <td>10488.95875</td>\n",
       "      <td>3813.2350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">thyroid</th>\n",
       "      <th>2</th>\n",
       "      <td>32295.60000</td>\n",
       "      <td>12094.60000</td>\n",
       "      <td>10187.90000</td>\n",
       "      <td>19573.60000</td>\n",
       "      <td>8225.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48312.90000</td>\n",
       "      <td>9302.70000</td>\n",
       "      <td>9032.90000</td>\n",
       "      <td>26269.90000</td>\n",
       "      <td>17151.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47199.10000</td>\n",
       "      <td>6931.10000</td>\n",
       "      <td>6987.60000</td>\n",
       "      <td>18783.50000</td>\n",
       "      <td>46439.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>42135.60000</td>\n",
       "      <td>4298.70000</td>\n",
       "      <td>4343.30000</td>\n",
       "      <td>24350.70000</td>\n",
       "      <td>19392.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>43816.30000</td>\n",
       "      <td>3422.30000</td>\n",
       "      <td>3237.00000</td>\n",
       "      <td>27547.90000</td>\n",
       "      <td>11561.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithm       binmf l1          bmf  bmf+ (int, l1)     mpbmf l1    nimfa l1\n",
       "Dataset  k                                                                    \n",
       "congress 2    2535.40000   1603.00000      1522.00000   1522.70000   2011.0000\n",
       "         3    2723.50000   1466.60000      1378.90000   1538.40000   2045.0000\n",
       "         5    2614.10000   1267.00000      1167.80000   1763.70000   2264.0000\n",
       "         10   3005.40000   1049.20000       969.90000   1876.80000   1102.0000\n",
       "         15   2711.40000    920.40000       872.30000   1677.20000    380.0000\n",
       "orl      2    4525.91425   1585.28850      1473.15475   3487.70375   2072.6775\n",
       "         3    4608.26300   1311.40900      1250.40375   4514.47350   3286.6725\n",
       "         5    4586.95800   1032.48625       997.73050   5925.21800   4545.2375\n",
       "         10   5081.62300    722.43050       704.79500   8377.60575   3898.6275\n",
       "         15   5351.15800    568.44675       556.85200  10488.95875   3813.2350\n",
       "thyroid  2   32295.60000  12094.60000     10187.90000  19573.60000   8225.0000\n",
       "         3   48312.90000   9302.70000      9032.90000  26269.90000  17151.0000\n",
       "         5   47199.10000   6931.10000      6987.60000  18783.50000  46439.0000\n",
       "         10  42135.60000   4298.70000      4343.30000  24350.70000  19392.0000\n",
       "         15  43816.30000   3422.30000      3237.00000  27547.90000  11561.0000"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = real_l1.groupby(['Dataset', 'k', 'Algorithm']).mean()\n",
    "grouped_df['Error'].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "c6b85370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>binmf l2</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+ (int, l2)</th>\n",
       "      <th>mpbmf l2</th>\n",
       "      <th>nimfa l2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">congress</th>\n",
       "      <th>2</th>\n",
       "      <td>50.374597</td>\n",
       "      <td>40.037482</td>\n",
       "      <td>39.064050</td>\n",
       "      <td>39.111379</td>\n",
       "      <td>44.844175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.332590</td>\n",
       "      <td>38.296214</td>\n",
       "      <td>37.202150</td>\n",
       "      <td>40.129789</td>\n",
       "      <td>47.717921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51.612983</td>\n",
       "      <td>35.594943</td>\n",
       "      <td>34.461573</td>\n",
       "      <td>45.553266</td>\n",
       "      <td>49.699095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>57.956881</td>\n",
       "      <td>32.391357</td>\n",
       "      <td>31.115912</td>\n",
       "      <td>50.823223</td>\n",
       "      <td>33.376639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>52.429000</td>\n",
       "      <td>30.338095</td>\n",
       "      <td>29.337689</td>\n",
       "      <td>50.888113</td>\n",
       "      <td>20.396078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">orl</th>\n",
       "      <th>2</th>\n",
       "      <td>67.330998</td>\n",
       "      <td>39.815682</td>\n",
       "      <td>38.433442</td>\n",
       "      <td>61.410758</td>\n",
       "      <td>46.191368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.105114</td>\n",
       "      <td>36.213382</td>\n",
       "      <td>35.349707</td>\n",
       "      <td>78.544004</td>\n",
       "      <td>59.202006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68.738039</td>\n",
       "      <td>32.132324</td>\n",
       "      <td>31.609785</td>\n",
       "      <td>101.445172</td>\n",
       "      <td>72.031955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>75.935970</td>\n",
       "      <td>26.878067</td>\n",
       "      <td>26.564455</td>\n",
       "      <td>146.238995</td>\n",
       "      <td>66.185856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>79.559148</td>\n",
       "      <td>23.842121</td>\n",
       "      <td>23.613534</td>\n",
       "      <td>186.631093</td>\n",
       "      <td>63.444030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">thyroid</th>\n",
       "      <th>2</th>\n",
       "      <td>179.715887</td>\n",
       "      <td>109.975452</td>\n",
       "      <td>100.409661</td>\n",
       "      <td>142.967829</td>\n",
       "      <td>90.691786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220.107474</td>\n",
       "      <td>96.450505</td>\n",
       "      <td>90.637740</td>\n",
       "      <td>177.972751</td>\n",
       "      <td>132.034087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>220.003864</td>\n",
       "      <td>83.253228</td>\n",
       "      <td>81.855971</td>\n",
       "      <td>149.351599</td>\n",
       "      <td>248.991968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>206.860339</td>\n",
       "      <td>65.564472</td>\n",
       "      <td>65.139082</td>\n",
       "      <td>177.327663</td>\n",
       "      <td>139.255161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>209.714330</td>\n",
       "      <td>58.500427</td>\n",
       "      <td>57.562140</td>\n",
       "      <td>197.155522</td>\n",
       "      <td>107.522091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithm      binmf l2         bmf  bmf+ (int, l2)    mpbmf l2    nimfa l2\n",
       "Dataset  k                                                                 \n",
       "congress 2    50.374597   40.037482       39.064050   39.111379   44.844175\n",
       "         3    52.332590   38.296214       37.202150   40.129789   47.717921\n",
       "         5    51.612983   35.594943       34.461573   45.553266   49.699095\n",
       "         10   57.956881   32.391357       31.115912   50.823223   33.376639\n",
       "         15   52.429000   30.338095       29.337689   50.888113   20.396078\n",
       "orl      2    67.330998   39.815682       38.433442   61.410758   46.191368\n",
       "         3    68.105114   36.213382       35.349707   78.544004   59.202006\n",
       "         5    68.738039   32.132324       31.609785  101.445172   72.031955\n",
       "         10   75.935970   26.878067       26.564455  146.238995   66.185856\n",
       "         15   79.559148   23.842121       23.613534  186.631093   63.444030\n",
       "thyroid  2   179.715887  109.975452      100.409661  142.967829   90.691786\n",
       "         3   220.107474   96.450505       90.637740  177.972751  132.034087\n",
       "         5   220.003864   83.253228       81.855971  149.351599  248.991968\n",
       "         10  206.860339   65.564472       65.139082  177.327663  139.255161\n",
       "         15  209.714330   58.500427       57.562140  197.155522  107.522091"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = real_l2.groupby(['Dataset', 'k', 'Algorithm']).mean()\n",
    "grouped_df['Error'] = grouped_df['Error'].apply(lambda x: np.sqrt(x))\n",
    "grouped_df['Error'].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "1771f468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>binmf l5</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+ (int, l5)</th>\n",
       "      <th>mpbmf l5</th>\n",
       "      <th>nimfa l5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">congress</th>\n",
       "      <th>2</th>\n",
       "      <td>4.807647</td>\n",
       "      <td>4.375087</td>\n",
       "      <td>4.332224</td>\n",
       "      <td>4.388488</td>\n",
       "      <td>4.578070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.943204</td>\n",
       "      <td>4.297960</td>\n",
       "      <td>4.250074</td>\n",
       "      <td>4.826221</td>\n",
       "      <td>5.603591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.100251</td>\n",
       "      <td>4.174028</td>\n",
       "      <td>4.116247</td>\n",
       "      <td>5.923003</td>\n",
       "      <td>5.568467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.406303</td>\n",
       "      <td>4.019497</td>\n",
       "      <td>3.944662</td>\n",
       "      <td>6.985513</td>\n",
       "      <td>4.183864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.069224</td>\n",
       "      <td>3.915573</td>\n",
       "      <td>3.861609</td>\n",
       "      <td>7.601854</td>\n",
       "      <td>3.915233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">orl</th>\n",
       "      <th>2</th>\n",
       "      <td>5.411126</td>\n",
       "      <td>4.365376</td>\n",
       "      <td>4.303755</td>\n",
       "      <td>5.994646</td>\n",
       "      <td>4.955089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.506552</td>\n",
       "      <td>4.202886</td>\n",
       "      <td>4.162835</td>\n",
       "      <td>8.038793</td>\n",
       "      <td>5.812394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.864436</td>\n",
       "      <td>4.006608</td>\n",
       "      <td>3.980946</td>\n",
       "      <td>11.232400</td>\n",
       "      <td>6.842898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.244714</td>\n",
       "      <td>3.730433</td>\n",
       "      <td>3.713458</td>\n",
       "      <td>18.873718</td>\n",
       "      <td>6.533988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.774064</td>\n",
       "      <td>3.555805</td>\n",
       "      <td>3.541660</td>\n",
       "      <td>26.913122</td>\n",
       "      <td>5.919185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">thyroid</th>\n",
       "      <th>2</th>\n",
       "      <td>7.978429</td>\n",
       "      <td>6.554179</td>\n",
       "      <td>6.311074</td>\n",
       "      <td>7.990142</td>\n",
       "      <td>6.067743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.716929</td>\n",
       "      <td>6.219018</td>\n",
       "      <td>6.157791</td>\n",
       "      <td>10.264366</td>\n",
       "      <td>7.345233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.393117</td>\n",
       "      <td>5.863547</td>\n",
       "      <td>5.871882</td>\n",
       "      <td>9.686046</td>\n",
       "      <td>12.284920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.801714</td>\n",
       "      <td>5.329266</td>\n",
       "      <td>5.354880</td>\n",
       "      <td>10.939349</td>\n",
       "      <td>7.203184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.575015</td>\n",
       "      <td>5.091709</td>\n",
       "      <td>5.058701</td>\n",
       "      <td>12.225846</td>\n",
       "      <td>6.495298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithm    binmf l5       bmf  bmf+ (int, l5)   mpbmf l5   nimfa l5\n",
       "Dataset  k                                                           \n",
       "congress 2   4.807647  4.375087        4.332224   4.388488   4.578070\n",
       "         3   4.943204  4.297960        4.250074   4.826221   5.603591\n",
       "         5   5.100251  4.174028        4.116247   5.923003   5.568467\n",
       "         10  6.406303  4.019497        3.944662   6.985513   4.183864\n",
       "         15  5.069224  3.915573        3.861609   7.601854   3.915233\n",
       "orl      2   5.411126  4.365376        4.303755   5.994646   4.955089\n",
       "         3   5.506552  4.202886        4.162835   8.038793   5.812394\n",
       "         5   5.864436  4.006608        3.980946  11.232400   6.842898\n",
       "         10  7.244714  3.730433        3.713458  18.873718   6.533988\n",
       "         15  7.774064  3.555805        3.541660  26.913122   5.919185\n",
       "thyroid  2   7.978429  6.554179        6.311074   7.990142   6.067743\n",
       "         3   8.716929  6.219018        6.157791  10.264366   7.345233\n",
       "         5   9.393117  5.863547        5.871882   9.686046  12.284920\n",
       "         10  8.801714  5.329266        5.354880  10.939349   7.203184\n",
       "         15  8.575015  5.091709        5.058701  12.225846   6.495298"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = real_l5.groupby(['Dataset', 'k', 'Algorithm']).mean()\n",
    "grouped_df['Error'] = grouped_df['Error'].apply(lambda x: np.power(x, 1.0 / 5.0))\n",
    "grouped_df['Error'].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4202a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "c03cc000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>binmf l1</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+ (int, l1)</th>\n",
       "      <th>mpbmf l1</th>\n",
       "      <th>nimfa l1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">full</th>\n",
       "      <th>2</th>\n",
       "      <td>5894.808</td>\n",
       "      <td>5736.392</td>\n",
       "      <td>5383.992</td>\n",
       "      <td>5590.284</td>\n",
       "      <td>6056.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5841.592</td>\n",
       "      <td>5516.160</td>\n",
       "      <td>5204.740</td>\n",
       "      <td>5719.600</td>\n",
       "      <td>6183.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5799.004</td>\n",
       "      <td>5205.024</td>\n",
       "      <td>4959.436</td>\n",
       "      <td>5779.136</td>\n",
       "      <td>6418.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5637.484</td>\n",
       "      <td>4712.456</td>\n",
       "      <td>4578.772</td>\n",
       "      <td>5550.372</td>\n",
       "      <td>6107.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5516.280</td>\n",
       "      <td>4406.472</td>\n",
       "      <td>4323.488</td>\n",
       "      <td>5314.516</td>\n",
       "      <td>5569.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">full0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1934.784</td>\n",
       "      <td>1289.460</td>\n",
       "      <td>1227.364</td>\n",
       "      <td>1225.932</td>\n",
       "      <td>1499.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2135.224</td>\n",
       "      <td>1282.024</td>\n",
       "      <td>1221.808</td>\n",
       "      <td>1230.428</td>\n",
       "      <td>1744.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2228.592</td>\n",
       "      <td>1265.340</td>\n",
       "      <td>1202.316</td>\n",
       "      <td>1266.888</td>\n",
       "      <td>1869.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1738.056</td>\n",
       "      <td>1221.160</td>\n",
       "      <td>1153.768</td>\n",
       "      <td>1353.024</td>\n",
       "      <td>1535.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1804.804</td>\n",
       "      <td>1176.524</td>\n",
       "      <td>1100.732</td>\n",
       "      <td>1646.632</td>\n",
       "      <td>1234.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr10</th>\n",
       "      <th>2</th>\n",
       "      <td>5869.036</td>\n",
       "      <td>5741.388</td>\n",
       "      <td>5357.288</td>\n",
       "      <td>5590.468</td>\n",
       "      <td>5964.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5825.476</td>\n",
       "      <td>5517.924</td>\n",
       "      <td>5166.236</td>\n",
       "      <td>5748.572</td>\n",
       "      <td>6182.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5782.580</td>\n",
       "      <td>5197.728</td>\n",
       "      <td>4898.900</td>\n",
       "      <td>5782.228</td>\n",
       "      <td>5966.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5620.568</td>\n",
       "      <td>4647.344</td>\n",
       "      <td>4476.280</td>\n",
       "      <td>5617.380</td>\n",
       "      <td>5957.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5504.988</td>\n",
       "      <td>4295.128</td>\n",
       "      <td>4179.220</td>\n",
       "      <td>5388.244</td>\n",
       "      <td>5641.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr10-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1371.160</td>\n",
       "      <td>1029.800</td>\n",
       "      <td>1004.948</td>\n",
       "      <td>837.400</td>\n",
       "      <td>1235.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1526.156</td>\n",
       "      <td>890.364</td>\n",
       "      <td>856.028</td>\n",
       "      <td>715.292</td>\n",
       "      <td>1145.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1794.068</td>\n",
       "      <td>667.928</td>\n",
       "      <td>613.124</td>\n",
       "      <td>488.084</td>\n",
       "      <td>695.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1738.072</td>\n",
       "      <td>372.532</td>\n",
       "      <td>227.932</td>\n",
       "      <td>130.588</td>\n",
       "      <td>186.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1180.384</td>\n",
       "      <td>257.132</td>\n",
       "      <td>108.320</td>\n",
       "      <td>99.376</td>\n",
       "      <td>139.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr15</th>\n",
       "      <th>2</th>\n",
       "      <td>5868.216</td>\n",
       "      <td>5732.744</td>\n",
       "      <td>5375.496</td>\n",
       "      <td>5563.124</td>\n",
       "      <td>6036.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5823.016</td>\n",
       "      <td>5515.080</td>\n",
       "      <td>5197.868</td>\n",
       "      <td>5688.616</td>\n",
       "      <td>6248.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5784.820</td>\n",
       "      <td>5207.972</td>\n",
       "      <td>4952.756</td>\n",
       "      <td>5732.756</td>\n",
       "      <td>6429.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5633.284</td>\n",
       "      <td>4710.444</td>\n",
       "      <td>4569.272</td>\n",
       "      <td>5526.260</td>\n",
       "      <td>6235.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5502.188</td>\n",
       "      <td>4401.692</td>\n",
       "      <td>4318.540</td>\n",
       "      <td>5283.496</td>\n",
       "      <td>5712.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr15-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1753.676</td>\n",
       "      <td>1550.032</td>\n",
       "      <td>1506.412</td>\n",
       "      <td>1322.612</td>\n",
       "      <td>1937.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1827.800</td>\n",
       "      <td>1418.796</td>\n",
       "      <td>1360.876</td>\n",
       "      <td>1202.004</td>\n",
       "      <td>1936.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2082.312</td>\n",
       "      <td>1196.932</td>\n",
       "      <td>1121.884</td>\n",
       "      <td>982.676</td>\n",
       "      <td>1518.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2586.232</td>\n",
       "      <td>851.384</td>\n",
       "      <td>681.652</td>\n",
       "      <td>552.988</td>\n",
       "      <td>788.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2535.924</td>\n",
       "      <td>694.268</td>\n",
       "      <td>458.224</td>\n",
       "      <td>277.400</td>\n",
       "      <td>379.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr5</th>\n",
       "      <th>2</th>\n",
       "      <td>5401.548</td>\n",
       "      <td>5222.544</td>\n",
       "      <td>4775.464</td>\n",
       "      <td>4971.432</td>\n",
       "      <td>5158.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5315.208</td>\n",
       "      <td>4752.412</td>\n",
       "      <td>4401.440</td>\n",
       "      <td>5007.588</td>\n",
       "      <td>5853.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5243.020</td>\n",
       "      <td>4069.268</td>\n",
       "      <td>3772.132</td>\n",
       "      <td>4801.188</td>\n",
       "      <td>4812.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5488.900</td>\n",
       "      <td>2773.692</td>\n",
       "      <td>2561.648</td>\n",
       "      <td>3413.412</td>\n",
       "      <td>3162.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6221.272</td>\n",
       "      <td>1854.956</td>\n",
       "      <td>1670.116</td>\n",
       "      <td>2503.704</td>\n",
       "      <td>1936.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr5-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>881.416</td>\n",
       "      <td>485.096</td>\n",
       "      <td>480.432</td>\n",
       "      <td>338.836</td>\n",
       "      <td>526.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>907.088</td>\n",
       "      <td>338.632</td>\n",
       "      <td>331.076</td>\n",
       "      <td>225.828</td>\n",
       "      <td>264.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>780.300</td>\n",
       "      <td>158.824</td>\n",
       "      <td>117.388</td>\n",
       "      <td>48.220</td>\n",
       "      <td>44.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>492.636</td>\n",
       "      <td>36.216</td>\n",
       "      <td>11.104</td>\n",
       "      <td>71.872</td>\n",
       "      <td>142.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>488.580</td>\n",
       "      <td>6.548</td>\n",
       "      <td>2.016</td>\n",
       "      <td>166.268</td>\n",
       "      <td>170.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-0001</th>\n",
       "      <th>2</th>\n",
       "      <td>5855.764</td>\n",
       "      <td>5751.324</td>\n",
       "      <td>5354.672</td>\n",
       "      <td>5564.184</td>\n",
       "      <td>5991.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5805.412</td>\n",
       "      <td>5527.984</td>\n",
       "      <td>5167.532</td>\n",
       "      <td>5672.544</td>\n",
       "      <td>6207.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5758.980</td>\n",
       "      <td>5202.720</td>\n",
       "      <td>4897.220</td>\n",
       "      <td>5738.064</td>\n",
       "      <td>6078.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5596.988</td>\n",
       "      <td>4659.872</td>\n",
       "      <td>4473.416</td>\n",
       "      <td>5537.756</td>\n",
       "      <td>5948.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5484.512</td>\n",
       "      <td>4302.984</td>\n",
       "      <td>4172.204</td>\n",
       "      <td>5327.052</td>\n",
       "      <td>5467.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-0001-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1385.300</td>\n",
       "      <td>1048.852</td>\n",
       "      <td>1036.328</td>\n",
       "      <td>862.316</td>\n",
       "      <td>1320.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1496.448</td>\n",
       "      <td>912.300</td>\n",
       "      <td>877.020</td>\n",
       "      <td>736.556</td>\n",
       "      <td>1181.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1739.756</td>\n",
       "      <td>693.500</td>\n",
       "      <td>633.368</td>\n",
       "      <td>511.584</td>\n",
       "      <td>723.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1843.624</td>\n",
       "      <td>410.768</td>\n",
       "      <td>268.860</td>\n",
       "      <td>154.936</td>\n",
       "      <td>205.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1333.096</td>\n",
       "      <td>291.420</td>\n",
       "      <td>135.440</td>\n",
       "      <td>109.836</td>\n",
       "      <td>158.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-001</th>\n",
       "      <th>2</th>\n",
       "      <td>5845.100</td>\n",
       "      <td>5738.904</td>\n",
       "      <td>5341.192</td>\n",
       "      <td>5556.680</td>\n",
       "      <td>5991.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5801.880</td>\n",
       "      <td>5520.908</td>\n",
       "      <td>5150.836</td>\n",
       "      <td>5664.904</td>\n",
       "      <td>6221.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5760.008</td>\n",
       "      <td>5183.712</td>\n",
       "      <td>4885.804</td>\n",
       "      <td>5736.676</td>\n",
       "      <td>5939.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5601.580</td>\n",
       "      <td>4648.680</td>\n",
       "      <td>4459.152</td>\n",
       "      <td>5534.416</td>\n",
       "      <td>5811.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5489.404</td>\n",
       "      <td>4294.824</td>\n",
       "      <td>4165.028</td>\n",
       "      <td>5323.868</td>\n",
       "      <td>5357.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-001-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1491.660</td>\n",
       "      <td>1148.512</td>\n",
       "      <td>1124.300</td>\n",
       "      <td>944.544</td>\n",
       "      <td>1408.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1614.108</td>\n",
       "      <td>1012.868</td>\n",
       "      <td>975.472</td>\n",
       "      <td>822.304</td>\n",
       "      <td>1220.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1911.028</td>\n",
       "      <td>792.140</td>\n",
       "      <td>732.984</td>\n",
       "      <td>601.204</td>\n",
       "      <td>851.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2287.164</td>\n",
       "      <td>509.608</td>\n",
       "      <td>375.380</td>\n",
       "      <td>265.560</td>\n",
       "      <td>338.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2224.844</td>\n",
       "      <td>397.808</td>\n",
       "      <td>256.916</td>\n",
       "      <td>223.420</td>\n",
       "      <td>218.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithm            binmf l1       bmf  bmf+ (int, l1)  mpbmf l1  nimfa l1\n",
       "Dataset          k                                                         \n",
       "full             2   5894.808  5736.392        5383.992  5590.284   6056.24\n",
       "                 3   5841.592  5516.160        5204.740  5719.600   6183.36\n",
       "                 5   5799.004  5205.024        4959.436  5779.136   6418.88\n",
       "                 10  5637.484  4712.456        4578.772  5550.372   6107.28\n",
       "                 15  5516.280  4406.472        4323.488  5314.516   5569.40\n",
       "full0.1          2   1934.784  1289.460        1227.364  1225.932   1499.20\n",
       "                 3   2135.224  1282.024        1221.808  1230.428   1744.28\n",
       "                 5   2228.592  1265.340        1202.316  1266.888   1869.32\n",
       "                 10  1738.056  1221.160        1153.768  1353.024   1535.76\n",
       "                 15  1804.804  1176.524        1100.732  1646.632   1234.60\n",
       "lr10             2   5869.036  5741.388        5357.288  5590.468   5964.96\n",
       "                 3   5825.476  5517.924        5166.236  5748.572   6182.28\n",
       "                 5   5782.580  5197.728        4898.900  5782.228   5966.28\n",
       "                 10  5620.568  4647.344        4476.280  5617.380   5957.00\n",
       "                 15  5504.988  4295.128        4179.220  5388.244   5641.16\n",
       "lr10-0.1         2   1371.160  1029.800        1004.948   837.400   1235.84\n",
       "                 3   1526.156   890.364         856.028   715.292   1145.28\n",
       "                 5   1794.068   667.928         613.124   488.084    695.64\n",
       "                 10  1738.072   372.532         227.932   130.588    186.96\n",
       "                 15  1180.384   257.132         108.320    99.376    139.64\n",
       "lr15             2   5868.216  5732.744        5375.496  5563.124   6036.00\n",
       "                 3   5823.016  5515.080        5197.868  5688.616   6248.72\n",
       "                 5   5784.820  5207.972        4952.756  5732.756   6429.76\n",
       "                 10  5633.284  4710.444        4569.272  5526.260   6235.68\n",
       "                 15  5502.188  4401.692        4318.540  5283.496   5712.28\n",
       "lr15-0.1         2   1753.676  1550.032        1506.412  1322.612   1937.32\n",
       "                 3   1827.800  1418.796        1360.876  1202.004   1936.80\n",
       "                 5   2082.312  1196.932        1121.884   982.676   1518.40\n",
       "                 10  2586.232   851.384         681.652   552.988    788.68\n",
       "                 15  2535.924   694.268         458.224   277.400    379.80\n",
       "lr5              2   5401.548  5222.544        4775.464  4971.432   5158.32\n",
       "                 3   5315.208  4752.412        4401.440  5007.588   5853.20\n",
       "                 5   5243.020  4069.268        3772.132  4801.188   4812.52\n",
       "                 10  5488.900  2773.692        2561.648  3413.412   3162.64\n",
       "                 15  6221.272  1854.956        1670.116  2503.704   1936.76\n",
       "lr5-0.1          2    881.416   485.096         480.432   338.836    526.12\n",
       "                 3    907.088   338.632         331.076   225.828    264.32\n",
       "                 5    780.300   158.824         117.388    48.220     44.96\n",
       "                 10   492.636    36.216          11.104    71.872    142.32\n",
       "                 15   488.580     6.548           2.016   166.268    170.32\n",
       "noisy10-0001     2   5855.764  5751.324        5354.672  5564.184   5991.20\n",
       "                 3   5805.412  5527.984        5167.532  5672.544   6207.48\n",
       "                 5   5758.980  5202.720        4897.220  5738.064   6078.12\n",
       "                 10  5596.988  4659.872        4473.416  5537.756   5948.60\n",
       "                 15  5484.512  4302.984        4172.204  5327.052   5467.52\n",
       "noisy10-0001-0.1 2   1385.300  1048.852        1036.328   862.316   1320.36\n",
       "                 3   1496.448   912.300         877.020   736.556   1181.76\n",
       "                 5   1739.756   693.500         633.368   511.584    723.36\n",
       "                 10  1843.624   410.768         268.860   154.936    205.32\n",
       "                 15  1333.096   291.420         135.440   109.836    158.24\n",
       "noisy10-001      2   5845.100  5738.904        5341.192  5556.680   5991.76\n",
       "                 3   5801.880  5520.908        5150.836  5664.904   6221.68\n",
       "                 5   5760.008  5183.712        4885.804  5736.676   5939.36\n",
       "                 10  5601.580  4648.680        4459.152  5534.416   5811.92\n",
       "                 15  5489.404  4294.824        4165.028  5323.868   5357.44\n",
       "noisy10-001-0.1  2   1491.660  1148.512        1124.300   944.544   1408.24\n",
       "                 3   1614.108  1012.868         975.472   822.304   1220.72\n",
       "                 5   1911.028   792.140         732.984   601.204    851.16\n",
       "                 10  2287.164   509.608         375.380   265.560    338.72\n",
       "                 15  2224.844   397.808         256.916   223.420    218.32"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = synth_l1.groupby(['Dataset', 'k', 'Algorithm']).mean()\n",
    "grouped_df['Error'].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "6de79523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>binmf l2</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+ (int, l2)</th>\n",
       "      <th>mpbmf l2</th>\n",
       "      <th>nimfa l2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">full</th>\n",
       "      <th>2</th>\n",
       "      <td>76.852846</td>\n",
       "      <td>75.738973</td>\n",
       "      <td>73.371466</td>\n",
       "      <td>77.894210</td>\n",
       "      <td>78.332113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.483253</td>\n",
       "      <td>74.270856</td>\n",
       "      <td>72.106144</td>\n",
       "      <td>81.010567</td>\n",
       "      <td>81.237922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>76.200709</td>\n",
       "      <td>72.145852</td>\n",
       "      <td>70.458527</td>\n",
       "      <td>83.779568</td>\n",
       "      <td>85.528942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>75.161985</td>\n",
       "      <td>68.647331</td>\n",
       "      <td>67.627598</td>\n",
       "      <td>84.340382</td>\n",
       "      <td>83.833168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>74.388924</td>\n",
       "      <td>66.381262</td>\n",
       "      <td>65.754209</td>\n",
       "      <td>83.606292</td>\n",
       "      <td>79.756379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">full0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>43.986180</td>\n",
       "      <td>35.909052</td>\n",
       "      <td>35.014054</td>\n",
       "      <td>35.016396</td>\n",
       "      <td>38.719504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.548813</td>\n",
       "      <td>35.805363</td>\n",
       "      <td>34.903008</td>\n",
       "      <td>35.081562</td>\n",
       "      <td>41.776070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47.952476</td>\n",
       "      <td>35.571618</td>\n",
       "      <td>34.656428</td>\n",
       "      <td>35.617075</td>\n",
       "      <td>43.235633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>42.280019</td>\n",
       "      <td>34.945100</td>\n",
       "      <td>33.926332</td>\n",
       "      <td>37.027233</td>\n",
       "      <td>39.202041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>43.312769</td>\n",
       "      <td>34.300496</td>\n",
       "      <td>33.227218</td>\n",
       "      <td>41.726730</td>\n",
       "      <td>35.143705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr10</th>\n",
       "      <th>2</th>\n",
       "      <td>76.671690</td>\n",
       "      <td>75.771947</td>\n",
       "      <td>73.212239</td>\n",
       "      <td>78.168664</td>\n",
       "      <td>77.330460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.377981</td>\n",
       "      <td>74.282730</td>\n",
       "      <td>71.868574</td>\n",
       "      <td>81.820853</td>\n",
       "      <td>81.537967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>76.090762</td>\n",
       "      <td>72.095270</td>\n",
       "      <td>70.040303</td>\n",
       "      <td>84.745855</td>\n",
       "      <td>81.475150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>75.060616</td>\n",
       "      <td>68.171431</td>\n",
       "      <td>66.948428</td>\n",
       "      <td>87.534565</td>\n",
       "      <td>82.959026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>74.349311</td>\n",
       "      <td>65.537226</td>\n",
       "      <td>64.692040</td>\n",
       "      <td>87.902150</td>\n",
       "      <td>80.660027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr10-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>37.111400</td>\n",
       "      <td>32.090497</td>\n",
       "      <td>31.679646</td>\n",
       "      <td>29.020820</td>\n",
       "      <td>35.237480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.394974</td>\n",
       "      <td>29.838968</td>\n",
       "      <td>29.371142</td>\n",
       "      <td>26.990146</td>\n",
       "      <td>34.219293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43.393317</td>\n",
       "      <td>25.844303</td>\n",
       "      <td>25.010398</td>\n",
       "      <td>22.873478</td>\n",
       "      <td>27.161001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>43.498506</td>\n",
       "      <td>19.301088</td>\n",
       "      <td>16.173311</td>\n",
       "      <td>14.733771</td>\n",
       "      <td>15.236798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>34.987198</td>\n",
       "      <td>16.035336</td>\n",
       "      <td>11.985992</td>\n",
       "      <td>12.409029</td>\n",
       "      <td>12.612692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr15</th>\n",
       "      <th>2</th>\n",
       "      <td>76.674950</td>\n",
       "      <td>75.714886</td>\n",
       "      <td>73.290218</td>\n",
       "      <td>77.602809</td>\n",
       "      <td>78.024612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.361404</td>\n",
       "      <td>74.263585</td>\n",
       "      <td>72.126167</td>\n",
       "      <td>80.626695</td>\n",
       "      <td>82.115528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>76.106688</td>\n",
       "      <td>72.166280</td>\n",
       "      <td>70.407272</td>\n",
       "      <td>83.339234</td>\n",
       "      <td>85.557466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>75.133082</td>\n",
       "      <td>68.632674</td>\n",
       "      <td>67.602456</td>\n",
       "      <td>84.259480</td>\n",
       "      <td>85.126259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>74.298614</td>\n",
       "      <td>66.345249</td>\n",
       "      <td>65.713286</td>\n",
       "      <td>83.503677</td>\n",
       "      <td>81.078480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr15-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>41.878157</td>\n",
       "      <td>39.370446</td>\n",
       "      <td>38.912363</td>\n",
       "      <td>36.476568</td>\n",
       "      <td>44.162880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.878153</td>\n",
       "      <td>37.666909</td>\n",
       "      <td>36.949804</td>\n",
       "      <td>34.932907</td>\n",
       "      <td>44.728514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>46.264371</td>\n",
       "      <td>34.596705</td>\n",
       "      <td>33.588689</td>\n",
       "      <td>32.054142</td>\n",
       "      <td>40.102868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53.200827</td>\n",
       "      <td>29.178485</td>\n",
       "      <td>26.877128</td>\n",
       "      <td>26.311442</td>\n",
       "      <td>29.923235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53.342703</td>\n",
       "      <td>26.348966</td>\n",
       "      <td>22.716954</td>\n",
       "      <td>22.159422</td>\n",
       "      <td>21.608332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr5</th>\n",
       "      <th>2</th>\n",
       "      <td>73.539404</td>\n",
       "      <td>72.267171</td>\n",
       "      <td>69.120619</td>\n",
       "      <td>75.248017</td>\n",
       "      <td>72.027772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73.052584</td>\n",
       "      <td>68.937740</td>\n",
       "      <td>66.447272</td>\n",
       "      <td>80.015224</td>\n",
       "      <td>83.670783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72.888380</td>\n",
       "      <td>63.790814</td>\n",
       "      <td>61.832548</td>\n",
       "      <td>85.768456</td>\n",
       "      <td>75.538335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>77.634193</td>\n",
       "      <td>52.665852</td>\n",
       "      <td>51.455184</td>\n",
       "      <td>77.885069</td>\n",
       "      <td>59.438708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>87.479781</td>\n",
       "      <td>43.069200</td>\n",
       "      <td>42.180375</td>\n",
       "      <td>67.898336</td>\n",
       "      <td>45.414976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr5-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>29.809797</td>\n",
       "      <td>22.024895</td>\n",
       "      <td>21.710550</td>\n",
       "      <td>18.503513</td>\n",
       "      <td>22.965191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.447463</td>\n",
       "      <td>18.401956</td>\n",
       "      <td>18.161057</td>\n",
       "      <td>15.408958</td>\n",
       "      <td>16.577093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.371183</td>\n",
       "      <td>12.602539</td>\n",
       "      <td>11.314769</td>\n",
       "      <td>8.507173</td>\n",
       "      <td>7.879086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22.260189</td>\n",
       "      <td>6.017973</td>\n",
       "      <td>4.045738</td>\n",
       "      <td>8.898090</td>\n",
       "      <td>13.392535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22.119042</td>\n",
       "      <td>2.558906</td>\n",
       "      <td>1.735511</td>\n",
       "      <td>15.148465</td>\n",
       "      <td>13.564660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-0001</th>\n",
       "      <th>2</th>\n",
       "      <td>76.587858</td>\n",
       "      <td>75.837484</td>\n",
       "      <td>73.182840</td>\n",
       "      <td>77.836393</td>\n",
       "      <td>77.488580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.246364</td>\n",
       "      <td>74.350414</td>\n",
       "      <td>71.872693</td>\n",
       "      <td>80.877933</td>\n",
       "      <td>81.713402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75.937211</td>\n",
       "      <td>72.129883</td>\n",
       "      <td>70.015570</td>\n",
       "      <td>84.188265</td>\n",
       "      <td>82.654703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>74.905087</td>\n",
       "      <td>68.263255</td>\n",
       "      <td>66.907877</td>\n",
       "      <td>86.571566</td>\n",
       "      <td>83.005301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>74.216332</td>\n",
       "      <td>65.597134</td>\n",
       "      <td>64.711452</td>\n",
       "      <td>87.099920</td>\n",
       "      <td>79.242918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-0001-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>37.299062</td>\n",
       "      <td>32.385985</td>\n",
       "      <td>32.079090</td>\n",
       "      <td>29.463808</td>\n",
       "      <td>36.466423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.035676</td>\n",
       "      <td>30.204304</td>\n",
       "      <td>29.837828</td>\n",
       "      <td>27.402263</td>\n",
       "      <td>34.683714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42.677629</td>\n",
       "      <td>26.334388</td>\n",
       "      <td>25.422431</td>\n",
       "      <td>23.504723</td>\n",
       "      <td>27.692598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>45.131630</td>\n",
       "      <td>20.267412</td>\n",
       "      <td>17.164498</td>\n",
       "      <td>15.879547</td>\n",
       "      <td>16.118313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>37.465824</td>\n",
       "      <td>17.071028</td>\n",
       "      <td>12.992613</td>\n",
       "      <td>13.483768</td>\n",
       "      <td>13.461055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-001</th>\n",
       "      <th>2</th>\n",
       "      <td>76.494366</td>\n",
       "      <td>75.755554</td>\n",
       "      <td>73.103789</td>\n",
       "      <td>77.833720</td>\n",
       "      <td>77.540699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.217951</td>\n",
       "      <td>74.302813</td>\n",
       "      <td>71.765479</td>\n",
       "      <td>80.917588</td>\n",
       "      <td>82.141342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75.948035</td>\n",
       "      <td>71.998000</td>\n",
       "      <td>69.933740</td>\n",
       "      <td>84.247896</td>\n",
       "      <td>81.343715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>74.938028</td>\n",
       "      <td>68.181229</td>\n",
       "      <td>66.865776</td>\n",
       "      <td>86.425320</td>\n",
       "      <td>81.707772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>74.260057</td>\n",
       "      <td>65.534907</td>\n",
       "      <td>64.558903</td>\n",
       "      <td>86.913773</td>\n",
       "      <td>78.382651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-001-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>38.691860</td>\n",
       "      <td>33.889703</td>\n",
       "      <td>33.461381</td>\n",
       "      <td>30.832580</td>\n",
       "      <td>37.584039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.462575</td>\n",
       "      <td>31.825587</td>\n",
       "      <td>31.325644</td>\n",
       "      <td>28.958453</td>\n",
       "      <td>35.294192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44.653197</td>\n",
       "      <td>28.144982</td>\n",
       "      <td>27.259274</td>\n",
       "      <td>25.328166</td>\n",
       "      <td>29.968650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50.290317</td>\n",
       "      <td>22.574499</td>\n",
       "      <td>20.225430</td>\n",
       "      <td>19.133635</td>\n",
       "      <td>19.663164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>49.986838</td>\n",
       "      <td>19.945125</td>\n",
       "      <td>17.058839</td>\n",
       "      <td>17.496628</td>\n",
       "      <td>15.435025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithm             binmf l2        bmf  bmf+ (int, l2)   mpbmf l2  \\\n",
       "Dataset          k                                                     \n",
       "full             2   76.852846  75.738973       73.371466  77.894210   \n",
       "                 3   76.483253  74.270856       72.106144  81.010567   \n",
       "                 5   76.200709  72.145852       70.458527  83.779568   \n",
       "                 10  75.161985  68.647331       67.627598  84.340382   \n",
       "                 15  74.388924  66.381262       65.754209  83.606292   \n",
       "full0.1          2   43.986180  35.909052       35.014054  35.016396   \n",
       "                 3   46.548813  35.805363       34.903008  35.081562   \n",
       "                 5   47.952476  35.571618       34.656428  35.617075   \n",
       "                 10  42.280019  34.945100       33.926332  37.027233   \n",
       "                 15  43.312769  34.300496       33.227218  41.726730   \n",
       "lr10             2   76.671690  75.771947       73.212239  78.168664   \n",
       "                 3   76.377981  74.282730       71.868574  81.820853   \n",
       "                 5   76.090762  72.095270       70.040303  84.745855   \n",
       "                 10  75.060616  68.171431       66.948428  87.534565   \n",
       "                 15  74.349311  65.537226       64.692040  87.902150   \n",
       "lr10-0.1         2   37.111400  32.090497       31.679646  29.020820   \n",
       "                 3   39.394974  29.838968       29.371142  26.990146   \n",
       "                 5   43.393317  25.844303       25.010398  22.873478   \n",
       "                 10  43.498506  19.301088       16.173311  14.733771   \n",
       "                 15  34.987198  16.035336       11.985992  12.409029   \n",
       "lr15             2   76.674950  75.714886       73.290218  77.602809   \n",
       "                 3   76.361404  74.263585       72.126167  80.626695   \n",
       "                 5   76.106688  72.166280       70.407272  83.339234   \n",
       "                 10  75.133082  68.632674       67.602456  84.259480   \n",
       "                 15  74.298614  66.345249       65.713286  83.503677   \n",
       "lr15-0.1         2   41.878157  39.370446       38.912363  36.476568   \n",
       "                 3   42.878153  37.666909       36.949804  34.932907   \n",
       "                 5   46.264371  34.596705       33.588689  32.054142   \n",
       "                 10  53.200827  29.178485       26.877128  26.311442   \n",
       "                 15  53.342703  26.348966       22.716954  22.159422   \n",
       "lr5              2   73.539404  72.267171       69.120619  75.248017   \n",
       "                 3   73.052584  68.937740       66.447272  80.015224   \n",
       "                 5   72.888380  63.790814       61.832548  85.768456   \n",
       "                 10  77.634193  52.665852       51.455184  77.885069   \n",
       "                 15  87.479781  43.069200       42.180375  67.898336   \n",
       "lr5-0.1          2   29.809797  22.024895       21.710550  18.503513   \n",
       "                 3   30.447463  18.401956       18.161057  15.408958   \n",
       "                 5   28.371183  12.602539       11.314769   8.507173   \n",
       "                 10  22.260189   6.017973        4.045738   8.898090   \n",
       "                 15  22.119042   2.558906        1.735511  15.148465   \n",
       "noisy10-0001     2   76.587858  75.837484       73.182840  77.836393   \n",
       "                 3   76.246364  74.350414       71.872693  80.877933   \n",
       "                 5   75.937211  72.129883       70.015570  84.188265   \n",
       "                 10  74.905087  68.263255       66.907877  86.571566   \n",
       "                 15  74.216332  65.597134       64.711452  87.099920   \n",
       "noisy10-0001-0.1 2   37.299062  32.385985       32.079090  29.463808   \n",
       "                 3   39.035676  30.204304       29.837828  27.402263   \n",
       "                 5   42.677629  26.334388       25.422431  23.504723   \n",
       "                 10  45.131630  20.267412       17.164498  15.879547   \n",
       "                 15  37.465824  17.071028       12.992613  13.483768   \n",
       "noisy10-001      2   76.494366  75.755554       73.103789  77.833720   \n",
       "                 3   76.217951  74.302813       71.765479  80.917588   \n",
       "                 5   75.948035  71.998000       69.933740  84.247896   \n",
       "                 10  74.938028  68.181229       66.865776  86.425320   \n",
       "                 15  74.260057  65.534907       64.558903  86.913773   \n",
       "noisy10-001-0.1  2   38.691860  33.889703       33.461381  30.832580   \n",
       "                 3   40.462575  31.825587       31.325644  28.958453   \n",
       "                 5   44.653197  28.144982       27.259274  25.328166   \n",
       "                 10  50.290317  22.574499       20.225430  19.133635   \n",
       "                 15  49.986838  19.945125       17.058839  17.496628   \n",
       "\n",
       "Algorithm             nimfa l2  \n",
       "Dataset          k              \n",
       "full             2   78.332113  \n",
       "                 3   81.237922  \n",
       "                 5   85.528942  \n",
       "                 10  83.833168  \n",
       "                 15  79.756379  \n",
       "full0.1          2   38.719504  \n",
       "                 3   41.776070  \n",
       "                 5   43.235633  \n",
       "                 10  39.202041  \n",
       "                 15  35.143705  \n",
       "lr10             2   77.330460  \n",
       "                 3   81.537967  \n",
       "                 5   81.475150  \n",
       "                 10  82.959026  \n",
       "                 15  80.660027  \n",
       "lr10-0.1         2   35.237480  \n",
       "                 3   34.219293  \n",
       "                 5   27.161001  \n",
       "                 10  15.236798  \n",
       "                 15  12.612692  \n",
       "lr15             2   78.024612  \n",
       "                 3   82.115528  \n",
       "                 5   85.557466  \n",
       "                 10  85.126259  \n",
       "                 15  81.078480  \n",
       "lr15-0.1         2   44.162880  \n",
       "                 3   44.728514  \n",
       "                 5   40.102868  \n",
       "                 10  29.923235  \n",
       "                 15  21.608332  \n",
       "lr5              2   72.027772  \n",
       "                 3   83.670783  \n",
       "                 5   75.538335  \n",
       "                 10  59.438708  \n",
       "                 15  45.414976  \n",
       "lr5-0.1          2   22.965191  \n",
       "                 3   16.577093  \n",
       "                 5    7.879086  \n",
       "                 10  13.392535  \n",
       "                 15  13.564660  \n",
       "noisy10-0001     2   77.488580  \n",
       "                 3   81.713402  \n",
       "                 5   82.654703  \n",
       "                 10  83.005301  \n",
       "                 15  79.242918  \n",
       "noisy10-0001-0.1 2   36.466423  \n",
       "                 3   34.683714  \n",
       "                 5   27.692598  \n",
       "                 10  16.118313  \n",
       "                 15  13.461055  \n",
       "noisy10-001      2   77.540699  \n",
       "                 3   82.141342  \n",
       "                 5   81.343715  \n",
       "                 10  81.707772  \n",
       "                 15  78.382651  \n",
       "noisy10-001-0.1  2   37.584039  \n",
       "                 3   35.294192  \n",
       "                 5   29.968650  \n",
       "                 10  19.663164  \n",
       "                 15  15.435025  "
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = synth_l2.groupby(['Dataset', 'k', 'Algorithm']).mean()\n",
    "grouped_df['Error'] = grouped_df['Error'].apply(lambda x: np.power(x, 1.0 / 2.0))\n",
    "grouped_df['Error'].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "609a8b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>binmf l5</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+ (int, l5)</th>\n",
       "      <th>mpbmf l5</th>\n",
       "      <th>nimfa l5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">full</th>\n",
       "      <th>2</th>\n",
       "      <td>5.709662</td>\n",
       "      <td>5.645830</td>\n",
       "      <td>5.573243</td>\n",
       "      <td>6.623580</td>\n",
       "      <td>5.916772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.689753</td>\n",
       "      <td>5.601797</td>\n",
       "      <td>5.536553</td>\n",
       "      <td>7.190142</td>\n",
       "      <td>6.589811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.680013</td>\n",
       "      <td>5.537128</td>\n",
       "      <td>5.484059</td>\n",
       "      <td>7.719604</td>\n",
       "      <td>7.237889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.661819</td>\n",
       "      <td>5.428120</td>\n",
       "      <td>5.396488</td>\n",
       "      <td>8.192812</td>\n",
       "      <td>7.335222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.655592</td>\n",
       "      <td>5.355724</td>\n",
       "      <td>5.336094</td>\n",
       "      <td>8.383578</td>\n",
       "      <td>7.145863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">full0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>4.542830</td>\n",
       "      <td>4.188722</td>\n",
       "      <td>4.148468</td>\n",
       "      <td>4.148800</td>\n",
       "      <td>4.316899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.822656</td>\n",
       "      <td>4.183880</td>\n",
       "      <td>4.141375</td>\n",
       "      <td>4.152558</td>\n",
       "      <td>4.456946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.063126</td>\n",
       "      <td>4.172933</td>\n",
       "      <td>4.129251</td>\n",
       "      <td>4.192450</td>\n",
       "      <td>4.511664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.802219</td>\n",
       "      <td>4.143378</td>\n",
       "      <td>4.095769</td>\n",
       "      <td>4.410590</td>\n",
       "      <td>4.346528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.960931</td>\n",
       "      <td>4.112635</td>\n",
       "      <td>4.057893</td>\n",
       "      <td>5.122604</td>\n",
       "      <td>4.157290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr10</th>\n",
       "      <th>2</th>\n",
       "      <td>5.699014</td>\n",
       "      <td>5.646813</td>\n",
       "      <td>5.569297</td>\n",
       "      <td>6.688777</td>\n",
       "      <td>5.732525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.686743</td>\n",
       "      <td>5.602155</td>\n",
       "      <td>5.528542</td>\n",
       "      <td>7.344077</td>\n",
       "      <td>6.667270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.675929</td>\n",
       "      <td>5.535575</td>\n",
       "      <td>5.471720</td>\n",
       "      <td>7.929253</td>\n",
       "      <td>6.935350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.663337</td>\n",
       "      <td>5.413037</td>\n",
       "      <td>5.375428</td>\n",
       "      <td>8.705329</td>\n",
       "      <td>7.327559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.669851</td>\n",
       "      <td>5.328380</td>\n",
       "      <td>5.302143</td>\n",
       "      <td>9.059634</td>\n",
       "      <td>7.263842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr10-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>4.295613</td>\n",
       "      <td>4.004521</td>\n",
       "      <td>3.986817</td>\n",
       "      <td>3.906272</td>\n",
       "      <td>4.210570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.537224</td>\n",
       "      <td>3.889677</td>\n",
       "      <td>3.861228</td>\n",
       "      <td>3.913300</td>\n",
       "      <td>4.334765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.017272</td>\n",
       "      <td>3.672366</td>\n",
       "      <td>3.620641</td>\n",
       "      <td>4.009149</td>\n",
       "      <td>4.231611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.382734</td>\n",
       "      <td>3.267629</td>\n",
       "      <td>3.060302</td>\n",
       "      <td>4.305219</td>\n",
       "      <td>3.883186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.531693</td>\n",
       "      <td>3.034109</td>\n",
       "      <td>2.721945</td>\n",
       "      <td>4.088766</td>\n",
       "      <td>3.373991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr15</th>\n",
       "      <th>2</th>\n",
       "      <td>5.702608</td>\n",
       "      <td>5.645111</td>\n",
       "      <td>5.572802</td>\n",
       "      <td>6.592169</td>\n",
       "      <td>5.843531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.686066</td>\n",
       "      <td>5.601578</td>\n",
       "      <td>5.537248</td>\n",
       "      <td>7.155039</td>\n",
       "      <td>6.715910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.676892</td>\n",
       "      <td>5.537755</td>\n",
       "      <td>5.483563</td>\n",
       "      <td>7.685152</td>\n",
       "      <td>7.238682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.661165</td>\n",
       "      <td>5.427657</td>\n",
       "      <td>5.395445</td>\n",
       "      <td>8.209804</td>\n",
       "      <td>7.438783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.655606</td>\n",
       "      <td>5.354562</td>\n",
       "      <td>5.334341</td>\n",
       "      <td>8.391509</td>\n",
       "      <td>7.267310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr15-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>4.455199</td>\n",
       "      <td>4.345784</td>\n",
       "      <td>4.323074</td>\n",
       "      <td>4.283166</td>\n",
       "      <td>4.632281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.567936</td>\n",
       "      <td>4.269569</td>\n",
       "      <td>4.234036</td>\n",
       "      <td>4.310061</td>\n",
       "      <td>4.942165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.968499</td>\n",
       "      <td>4.126805</td>\n",
       "      <td>4.080082</td>\n",
       "      <td>4.419670</td>\n",
       "      <td>4.930579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.841593</td>\n",
       "      <td>3.855006</td>\n",
       "      <td>3.751995</td>\n",
       "      <td>4.913029</td>\n",
       "      <td>4.762278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.076676</td>\n",
       "      <td>3.700884</td>\n",
       "      <td>3.518433</td>\n",
       "      <td>5.212544</td>\n",
       "      <td>4.426069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr5</th>\n",
       "      <th>2</th>\n",
       "      <td>5.598305</td>\n",
       "      <td>5.540850</td>\n",
       "      <td>5.444594</td>\n",
       "      <td>6.872751</td>\n",
       "      <td>5.619429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.627383</td>\n",
       "      <td>5.437294</td>\n",
       "      <td>5.360723</td>\n",
       "      <td>7.900090</td>\n",
       "      <td>7.457598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.808194</td>\n",
       "      <td>5.271124</td>\n",
       "      <td>5.203323</td>\n",
       "      <td>8.981801</td>\n",
       "      <td>7.186115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.176545</td>\n",
       "      <td>4.882156</td>\n",
       "      <td>4.837851</td>\n",
       "      <td>8.909599</td>\n",
       "      <td>6.236612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.633325</td>\n",
       "      <td>4.504709</td>\n",
       "      <td>4.472501</td>\n",
       "      <td>8.611140</td>\n",
       "      <td>5.263301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr5-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>3.972705</td>\n",
       "      <td>3.444812</td>\n",
       "      <td>3.433576</td>\n",
       "      <td>3.301082</td>\n",
       "      <td>3.526390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.133373</td>\n",
       "      <td>3.205868</td>\n",
       "      <td>3.193134</td>\n",
       "      <td>3.323270</td>\n",
       "      <td>3.349374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.146156</td>\n",
       "      <td>2.755391</td>\n",
       "      <td>2.652291</td>\n",
       "      <td>3.331675</td>\n",
       "      <td>3.132798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.517180</td>\n",
       "      <td>2.050124</td>\n",
       "      <td>1.794100</td>\n",
       "      <td>2.938873</td>\n",
       "      <td>3.704769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.463865</td>\n",
       "      <td>1.456202</td>\n",
       "      <td>1.298531</td>\n",
       "      <td>4.812589</td>\n",
       "      <td>3.272854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-0001</th>\n",
       "      <th>2</th>\n",
       "      <td>5.697702</td>\n",
       "      <td>5.648766</td>\n",
       "      <td>5.568971</td>\n",
       "      <td>6.647344</td>\n",
       "      <td>5.732496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.682947</td>\n",
       "      <td>5.604197</td>\n",
       "      <td>5.529245</td>\n",
       "      <td>7.235768</td>\n",
       "      <td>6.675025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.672116</td>\n",
       "      <td>5.536638</td>\n",
       "      <td>5.472085</td>\n",
       "      <td>7.870074</td>\n",
       "      <td>7.047361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.659962</td>\n",
       "      <td>5.415952</td>\n",
       "      <td>5.374807</td>\n",
       "      <td>8.614149</td>\n",
       "      <td>7.344876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.672041</td>\n",
       "      <td>5.330328</td>\n",
       "      <td>5.300685</td>\n",
       "      <td>8.983674</td>\n",
       "      <td>7.179427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-0001-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>4.302347</td>\n",
       "      <td>4.019230</td>\n",
       "      <td>4.005295</td>\n",
       "      <td>3.939872</td>\n",
       "      <td>4.295237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.529464</td>\n",
       "      <td>3.908657</td>\n",
       "      <td>3.881584</td>\n",
       "      <td>3.943650</td>\n",
       "      <td>4.317222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.965911</td>\n",
       "      <td>3.700064</td>\n",
       "      <td>3.652266</td>\n",
       "      <td>4.095703</td>\n",
       "      <td>4.247288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.556934</td>\n",
       "      <td>3.332110</td>\n",
       "      <td>3.148063</td>\n",
       "      <td>4.424451</td>\n",
       "      <td>4.017441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.808042</td>\n",
       "      <td>3.111028</td>\n",
       "      <td>2.830090</td>\n",
       "      <td>4.217316</td>\n",
       "      <td>3.493876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-001</th>\n",
       "      <th>2</th>\n",
       "      <td>5.685240</td>\n",
       "      <td>5.646324</td>\n",
       "      <td>5.565944</td>\n",
       "      <td>6.657435</td>\n",
       "      <td>5.753339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.679850</td>\n",
       "      <td>5.602761</td>\n",
       "      <td>5.525443</td>\n",
       "      <td>7.258678</td>\n",
       "      <td>6.758828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.674098</td>\n",
       "      <td>5.532586</td>\n",
       "      <td>5.467798</td>\n",
       "      <td>7.887534</td>\n",
       "      <td>6.940174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.662795</td>\n",
       "      <td>5.413348</td>\n",
       "      <td>5.369915</td>\n",
       "      <td>8.588463</td>\n",
       "      <td>7.234668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.678144</td>\n",
       "      <td>5.328305</td>\n",
       "      <td>5.296951</td>\n",
       "      <td>8.947377</td>\n",
       "      <td>7.131759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-001-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>4.358399</td>\n",
       "      <td>4.092862</td>\n",
       "      <td>4.074138</td>\n",
       "      <td>4.009412</td>\n",
       "      <td>4.301728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.557482</td>\n",
       "      <td>3.991265</td>\n",
       "      <td>3.964967</td>\n",
       "      <td>4.044487</td>\n",
       "      <td>4.370777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.040970</td>\n",
       "      <td>3.799797</td>\n",
       "      <td>3.761566</td>\n",
       "      <td>4.150737</td>\n",
       "      <td>4.362217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.801490</td>\n",
       "      <td>3.478942</td>\n",
       "      <td>3.342468</td>\n",
       "      <td>4.538358</td>\n",
       "      <td>4.052895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.920248</td>\n",
       "      <td>3.310813</td>\n",
       "      <td>3.130902</td>\n",
       "      <td>4.414239</td>\n",
       "      <td>3.520941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithm            binmf l5       bmf  bmf+ (int, l5)  mpbmf l5  nimfa l5\n",
       "Dataset          k                                                         \n",
       "full             2   5.709662  5.645830        5.573243  6.623580  5.916772\n",
       "                 3   5.689753  5.601797        5.536553  7.190142  6.589811\n",
       "                 5   5.680013  5.537128        5.484059  7.719604  7.237889\n",
       "                 10  5.661819  5.428120        5.396488  8.192812  7.335222\n",
       "                 15  5.655592  5.355724        5.336094  8.383578  7.145863\n",
       "full0.1          2   4.542830  4.188722        4.148468  4.148800  4.316899\n",
       "                 3   4.822656  4.183880        4.141375  4.152558  4.456946\n",
       "                 5   5.063126  4.172933        4.129251  4.192450  4.511664\n",
       "                 10  4.802219  4.143378        4.095769  4.410590  4.346528\n",
       "                 15  4.960931  4.112635        4.057893  5.122604  4.157290\n",
       "lr10             2   5.699014  5.646813        5.569297  6.688777  5.732525\n",
       "                 3   5.686743  5.602155        5.528542  7.344077  6.667270\n",
       "                 5   5.675929  5.535575        5.471720  7.929253  6.935350\n",
       "                 10  5.663337  5.413037        5.375428  8.705329  7.327559\n",
       "                 15  5.669851  5.328380        5.302143  9.059634  7.263842\n",
       "lr10-0.1         2   4.295613  4.004521        3.986817  3.906272  4.210570\n",
       "                 3   4.537224  3.889677        3.861228  3.913300  4.334765\n",
       "                 5   5.017272  3.672366        3.620641  4.009149  4.231611\n",
       "                 10  5.382734  3.267629        3.060302  4.305219  3.883186\n",
       "                 15  4.531693  3.034109        2.721945  4.088766  3.373991\n",
       "lr15             2   5.702608  5.645111        5.572802  6.592169  5.843531\n",
       "                 3   5.686066  5.601578        5.537248  7.155039  6.715910\n",
       "                 5   5.676892  5.537755        5.483563  7.685152  7.238682\n",
       "                 10  5.661165  5.427657        5.395445  8.209804  7.438783\n",
       "                 15  5.655606  5.354562        5.334341  8.391509  7.267310\n",
       "lr15-0.1         2   4.455199  4.345784        4.323074  4.283166  4.632281\n",
       "                 3   4.567936  4.269569        4.234036  4.310061  4.942165\n",
       "                 5   4.968499  4.126805        4.080082  4.419670  4.930579\n",
       "                 10  5.841593  3.855006        3.751995  4.913029  4.762278\n",
       "                 15  6.076676  3.700884        3.518433  5.212544  4.426069\n",
       "lr5              2   5.598305  5.540850        5.444594  6.872751  5.619429\n",
       "                 3   5.627383  5.437294        5.360723  7.900090  7.457598\n",
       "                 5   5.808194  5.271124        5.203323  8.981801  7.186115\n",
       "                 10  7.176545  4.882156        4.837851  8.909599  6.236612\n",
       "                 15  8.633325  4.504709        4.472501  8.611140  5.263301\n",
       "lr5-0.1          2   3.972705  3.444812        3.433576  3.301082  3.526390\n",
       "                 3   4.133373  3.205868        3.193134  3.323270  3.349374\n",
       "                 5   4.146156  2.755391        2.652291  3.331675  3.132798\n",
       "                 10  3.517180  2.050124        1.794100  2.938873  3.704769\n",
       "                 15  3.463865  1.456202        1.298531  4.812589  3.272854\n",
       "noisy10-0001     2   5.697702  5.648766        5.568971  6.647344  5.732496\n",
       "                 3   5.682947  5.604197        5.529245  7.235768  6.675025\n",
       "                 5   5.672116  5.536638        5.472085  7.870074  7.047361\n",
       "                 10  5.659962  5.415952        5.374807  8.614149  7.344876\n",
       "                 15  5.672041  5.330328        5.300685  8.983674  7.179427\n",
       "noisy10-0001-0.1 2   4.302347  4.019230        4.005295  3.939872  4.295237\n",
       "                 3   4.529464  3.908657        3.881584  3.943650  4.317222\n",
       "                 5   4.965911  3.700064        3.652266  4.095703  4.247288\n",
       "                 10  5.556934  3.332110        3.148063  4.424451  4.017441\n",
       "                 15  4.808042  3.111028        2.830090  4.217316  3.493876\n",
       "noisy10-001      2   5.685240  5.646324        5.565944  6.657435  5.753339\n",
       "                 3   5.679850  5.602761        5.525443  7.258678  6.758828\n",
       "                 5   5.674098  5.532586        5.467798  7.887534  6.940174\n",
       "                 10  5.662795  5.413348        5.369915  8.588463  7.234668\n",
       "                 15  5.678144  5.328305        5.296951  8.947377  7.131759\n",
       "noisy10-001-0.1  2   4.358399  4.092862        4.074138  4.009412  4.301728\n",
       "                 3   4.557482  3.991265        3.964967  4.044487  4.370777\n",
       "                 5   5.040970  3.799797        3.761566  4.150737  4.362217\n",
       "                 10  5.801490  3.478942        3.342468  4.538358  4.052895\n",
       "                 15  5.920248  3.310813        3.130902  4.414239  3.520941"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = synth_l5.groupby(['Dataset', 'k', 'Algorithm']).mean()\n",
    "grouped_df['Error'] = grouped_df['Error'].apply(lambda x: np.power(x, 1.0 / 5.0))\n",
    "grouped_df['Error'].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69848acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e5268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
