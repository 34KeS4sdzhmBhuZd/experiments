{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11399db6",
   "metadata": {},
   "source": [
    "# Binary Matrix Factorization\n",
    "\n",
    "Requires the following packages to be installed in the environment: \n",
    "\n",
    "```\n",
    "- numpy\n",
    "- scikit-learn\n",
    "- matplotlib\n",
    "- opencv-python\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c4d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import perf_counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ee3a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def nearest_neighbor(points, data, n_neighbors = 1, p=2):\n",
    "    \"\"\"Function for finding the nearest neighbor of points in a dataset.\n",
    "    \n",
    "    Used to replace the k-means Steiner points with the nearest neighbor\n",
    "    in the dataset.\n",
    "    \n",
    "    Wraps the scipy nearest neighbor class.\"\"\"\n",
    "    \n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto', p=p, n_jobs=-1).fit(data)\n",
    "    _, indices = nbrs.kneighbors(points)\n",
    "    #print(np.bincount(indices.flatten()))\n",
    "    \n",
    "    return data[indices.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e60e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import minkowski\n",
    "\n",
    "def l_p_norm(v, p=2):\n",
    "    return np.power(np.linalg.norm(v, ord=p), p)    \n",
    "\n",
    "def l_p_dist(u, v, p=2):\n",
    "    return np.power(np.linalg.norm(u-v, ord=p), p)\n",
    "\n",
    "# vector valued functions\n",
    "def l_1_dist(u, v):\n",
    "    return l_p_dist(u,v,1)\n",
    "\n",
    "def l_2_dist(u, v):\n",
    "    return l_p_dist(u,v,2)\n",
    "\n",
    "def l_5_dist(u, v):\n",
    "    return l_p_dist(u,v,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e62fb",
   "metadata": {},
   "source": [
    "# Kumar et al.'s algorithm for Binary Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "5315334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, k_means\n",
    "\n",
    "class BMFKMeans:\n",
    "    '''The proposed algorithm of Kumar et al. (2019) to obtain a low-rank binary matrix\n",
    "    that approximates a given matrix.'''\n",
    "    \n",
    "    def __init__(self, k, max_iter=300):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def __fit(self, data):\n",
    "        #t0 = time()\n",
    "        kmeans = KMeans(init=\"k-means++\", n_clusters=self.k, max_iter=self.max_iter, n_init='auto')\n",
    "        kmeans.fit(data) # get clusters\n",
    "        #print(\"Elapsed time for k-means: %f\" % (time() - t0))\n",
    "        #cluster_centers_, labels_, inertia_ = k_means(data, self.k, n_init='auto', max_iter=self.max_iter)\n",
    "        \n",
    "        #t1 = time()\n",
    "        self.centers_ = nearest_neighbor(kmeans.cluster_centers_, data, p=1)\n",
    "        self.low_rank_ = nearest_neighbor(data, self.centers_) # self.centers_[kmeans.labels_]\n",
    "        #print(\"Elapsed time for nearest-neighbors: %f\" % (time() - t1))\n",
    "        \n",
    "    def fit(self, data, labels = []):\n",
    "        if (data.ndim == 2):\n",
    "            self.__fit(data)\n",
    "            return self\n",
    "        else: \n",
    "            raise ValueError(\"Can not factorize a dataset of shape % s.\" % str(data.shape))\n",
    "            \n",
    "    def results(self):\n",
    "        return self.low_rank_\n",
    "    \n",
    "    def score(self, data, label):\n",
    "        return np.square(np.linalg.norm(data - self.low_rank_, ord='fro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8438e0",
   "metadata": {},
   "source": [
    "# Our algorithm for Binary Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, k_means\n",
    "\n",
    "class BMFKMeans_plus:\n",
    "    '''The proposed algorithm of Kumar et al. (2019) to obtain a low-rank binary matrix\n",
    "    that approximates a given matrix - with post processing.'''\n",
    "    \n",
    "    def __init__(self, k, max_iter=300):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def __fit(self, data):\n",
    "        #t0 = time()\n",
    "        kmeans = KMeans(init=\"k-means++\", n_clusters=self.k, max_iter=self.max_iter, n_init='auto')\n",
    "        kmeans.fit(data) # get clusters\n",
    "        #print(\"Elapsed time for k-means: %f\" % (time() - t0))\n",
    "        #cluster_centers_, labels_, inertia_ = k_means(data, self.k, n_init='auto', max_iter=self.max_iter)\n",
    "        \n",
    "        #t1 = time()\n",
    "        self.centers_ = nearest_neighbor(kmeans.cluster_centers_, data, p=1)\n",
    "        self.low_rank_ = self.optimize(data)\n",
    "        #print(\"Elapsed time for nearest-neighbors: %f\" % (time() - t1))\n",
    "        \n",
    "    def fit(self, data, labels = []):\n",
    "        if (data.ndim == 2):\n",
    "            self.__fit(data)\n",
    "            return self\n",
    "        else: \n",
    "            raise ValueError(\"Can not factorize a dataset of shape % s.\" % str(data.shape))\n",
    "            \n",
    "    def results(self):\n",
    "        return self.low_rank_\n",
    "    \n",
    "    def score(self, data, label):\n",
    "        return np.linalg.norm(data - self.low_rank_, ord='fro')\n",
    "    \n",
    "    def optimize(self, data):\n",
    "        combinations = []\n",
    "        # enumerate all possible linear combinations\n",
    "        for i in range(2**self.k):\n",
    "            #if i % 10000 == 0 and i > 0:\n",
    "            #    print(i)\n",
    "            bits = []\n",
    "            for j, c in enumerate(bin(i)[:1:-1], 1):\n",
    "                if c == '1':\n",
    "                    bits.append(j-1)\n",
    "            combinations.append(np.sum(self.centers_[bits], axis=0))\n",
    "        combinations = np.mod(np.array(combinations), 2)\n",
    "        combinations = np.unique(combinations, axis=0)\n",
    "        # print(\"Obtained %d unique combinations.\" % combinations.shape[0])\n",
    "        return nearest_neighbor(data, np.array(combinations), p=1)\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c470bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, k_means\n",
    "\n",
    "class BMFKMeans_plus_int_1:\n",
    "    '''The proposed algorithm of Kumar et al. (2019) to obtain a low-rank binary matrix\n",
    "    that approximates a given matrix, with post-processing.'''\n",
    "    \n",
    "    def __init__(self, k, max_iter=300):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def __fit(self, data):\n",
    "        #t0 = time()\n",
    "        kmeans = KMeans(init=\"k-means++\", n_clusters=self.k, max_iter=self.max_iter, n_init='auto')\n",
    "        kmeans.fit(data) # get clusters\n",
    "        #print(\"Elapsed time for k-means: %f\" % (time() - t0))\n",
    "        #cluster_centers_, labels_, inertia_ = k_means(data, self.k, n_init='auto', max_iter=self.max_iter)\n",
    "        \n",
    "        #t1 = time()\n",
    "        self.centers_ = nearest_neighbor(kmeans.cluster_centers_, data, p=1)\n",
    "        self.low_rank_ = self.optimize(data)\n",
    "        #print(\"Elapsed time for nearest-neighbors: %f\" % (time() - t1))\n",
    "        \n",
    "    def fit(self, data, labels = []):\n",
    "        if (data.ndim == 2):\n",
    "            self.__fit(data)\n",
    "            return self\n",
    "        else: \n",
    "            raise ValueError(\"Can not factorize a dataset of shape % s.\" % str(data.shape))\n",
    "            \n",
    "    def results(self):\n",
    "        return self.low_rank_\n",
    "    \n",
    "    def score(self, data, label):\n",
    "        return l_p_norm((data - self.low_rank_).flatten(), p=1)\n",
    "    \n",
    "    def optimize(self, data):\n",
    "        combinations = []\n",
    "        # enumerate all possible linear combinations\n",
    "        for i in range(2**self.k):\n",
    "            #if i % 10000 == 0 and i > 0:\n",
    "            #    print(i)\n",
    "            bits = []\n",
    "            for j, c in enumerate(bin(i)[:1:-1], 1):\n",
    "                if c == '1':\n",
    "                    bits.append(j-1)\n",
    "            combinations.append(np.sum(self.centers_[bits], axis=0))\n",
    "        # combinations = np.mod(np.array(combinations), 2)\n",
    "        combinations = np.unique(combinations, axis=0)\n",
    "        # print(\"Obtained %d unique combinations.\" % combinations.shape[0])\n",
    "        return nearest_neighbor(data, np.array(combinations), p=1)\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c0fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, k_means\n",
    "\n",
    "class BMFKMeans_plus_int_2:\n",
    "    '''The proposed algorithm of Kumar et al. (2019) to obtain a low-rank binary matrix\n",
    "    that approximates a given matrix, with post-processing.'''\n",
    "    \n",
    "    def __init__(self, k, max_iter=300):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def __fit(self, data):\n",
    "        #t0 = time()\n",
    "        kmeans = KMeans(init=\"k-means++\", n_clusters=self.k, max_iter=self.max_iter, n_init='auto')\n",
    "        kmeans.fit(data) # get clusters\n",
    "        #print(\"Elapsed time for k-means: %f\" % (time() - t0))\n",
    "        #cluster_centers_, labels_, inertia_ = k_means(data, self.k, n_init='auto', max_iter=self.max_iter)\n",
    "        \n",
    "        #t1 = time()\n",
    "        self.centers_ = nearest_neighbor(kmeans.cluster_centers_, data, p=1)\n",
    "        self.low_rank_ = self.optimize(data)\n",
    "        #print(\"Elapsed time for nearest-neighbors: %f\" % (time() - t1))\n",
    "        \n",
    "    def fit(self, data, labels = []):\n",
    "        if (data.ndim == 2):\n",
    "            self.__fit(data)\n",
    "            return self\n",
    "        else: \n",
    "            raise ValueError(\"Can not factorize a dataset of shape % s.\" % str(data.shape))\n",
    "            \n",
    "    def results(self):\n",
    "        return self.low_rank_\n",
    "    \n",
    "    def score(self, data, label):\n",
    "        return l_p_norm((data - self.low_rank_).flatten(), p=2)\n",
    "    \n",
    "    def optimize(self, data):\n",
    "        combinations = []\n",
    "        # enumerate all possible linear combinations\n",
    "        for i in range(2**self.k):\n",
    "            #if i % 10000 == 0 and i > 0:\n",
    "            #    print(i)\n",
    "            bits = []\n",
    "            for j, c in enumerate(bin(i)[:1:-1], 1):\n",
    "                if c == '1':\n",
    "                    bits.append(j-1)\n",
    "            combinations.append(np.sum(self.centers_[bits], axis=0))\n",
    "        # combinations = np.mod(np.array(combinations), 2)\n",
    "        combinations = np.unique(combinations, axis=0)\n",
    "        # print(\"Obtained %d unique combinations.\" % combinations.shape[0])\n",
    "        return nearest_neighbor(data, np.array(combinations), p=2)\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4945ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, k_means\n",
    "\n",
    "class BMFKMeans_plus_int_5:\n",
    "    '''The proposed algorithm of Kumar et al. (2019) to obtain a low-rank binary matrix\n",
    "    that approximates a given matrix, with post-processing.'''\n",
    "    \n",
    "    def __init__(self, k, max_iter=300):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def __fit(self, data):\n",
    "        #t0 = time()\n",
    "        kmeans = KMeans(init=\"k-means++\", n_clusters=self.k, max_iter=self.max_iter, n_init='auto')\n",
    "        kmeans.fit(data) # get clusters\n",
    "        #print(\"Elapsed time for k-means: %f\" % (time() - t0))\n",
    "        #cluster_centers_, labels_, inertia_ = k_means(data, self.k, n_init='auto', max_iter=self.max_iter)\n",
    "        \n",
    "        #t1 = time()\n",
    "        self.centers_ = nearest_neighbor(kmeans.cluster_centers_, data, p=1)\n",
    "        self.low_rank_ = self.optimize(data)\n",
    "        #print(\"Elapsed time for nearest-neighbors: %f\" % (time() - t1))\n",
    "        \n",
    "    def fit(self, data, labels = []):\n",
    "        if (data.ndim == 2):\n",
    "            self.__fit(data)\n",
    "            return self\n",
    "        else: \n",
    "            raise ValueError(\"Can not factorize a dataset of shape % s.\" % str(data.shape))\n",
    "            \n",
    "    def results(self):\n",
    "        return self.low_rank_\n",
    "    \n",
    "    def score(self, data, label):\n",
    "        return l_p_norm((data - self.low_rank_).flatten(), p=5)\n",
    "    \n",
    "    def optimize(self, data):\n",
    "        combinations = []\n",
    "        # enumerate all possible linear combinations\n",
    "        for i in range(2**self.k):\n",
    "            #if i % 10000 == 0 and i > 0:\n",
    "            #    print(i)\n",
    "            bits = []\n",
    "            for j, c in enumerate(bin(i)[:1:-1], 1):\n",
    "                if c == '1':\n",
    "                    bits.append(j-1)\n",
    "            combinations.append(np.sum(self.centers_[bits], axis=0))\n",
    "        # combinations = np.mod(np.array(combinations), 2)\n",
    "        combinations = np.unique(combinations, axis=0)\n",
    "        # print(\"Obtained %d unique combinations.\" % combinations.shape[0])\n",
    "        return nearest_neighbor(data, np.array(combinations), p=5)\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "35ad96e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.099833886584822"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmf = BMFKMeans(15)\n",
    "bmf.fit(congress)\n",
    "np.sqrt(bmf.score(congress, congress))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5d53a",
   "metadata": {},
   "source": [
    "# Coreset Constructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420203a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LWCoreset:\n",
    "    '''An algorithm for computing light-weight coresets, based on the paper\n",
    "    Scalable k-means clustering via lightweight coresets by Bachem, Lucic and Krause\n",
    "    \n",
    "    This gives an additive-multiplicative guarantee on the costs of k-means\n",
    "    clustering.'''\n",
    "    def __init__(self, m):\n",
    "        self.m = m\n",
    "    \n",
    "    def fit(self, data):\n",
    "        if data.ndim != 2:\n",
    "            raise ValueError(\"Dataset needs to be of dimension 2, is of dimension % s\" % data.ndims)\n",
    "        \n",
    "        n, d = data.shape\n",
    "        \n",
    "        #t0 = perf_counter()\n",
    "        mean = np.mean(data, axis=0)\n",
    "        dists = np.square(np.linalg.norm(data - mean, axis=1))\n",
    "        \n",
    "        self.p = (1.0 / n + dists / np.sum(dists))/2.0\n",
    "        #print(\"Calculated Distribution in %f s\" % (perf_counter() - t0))\n",
    "\n",
    "        #t0 = perf_counter()\n",
    "        self.indices = np.random.choice(n, size=self.m, replace=True, p=self.p)\n",
    "        #print(\"Sampled Indices in %f s\" % (perf_counter() - t0))\n",
    "\n",
    "        #t0 = perf_counter()\n",
    "        self.coreset = data[self.indices]\n",
    "        self.weights = 1.0 / (self.m * self.p[self.indices])\n",
    "        #print(\"Selected Coreset and Weights in %f s\" % (perf_counter() - t0))\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def result(self):\n",
    "        return (self.coreset, self.weights)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import kmeans_plusplus\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils.extmath import row_norms\n",
    "\n",
    "class KMeansCoreset:\n",
    "    def __init__(self, delta, k):\n",
    "        self.delta = delta\n",
    "        self.k = k\n",
    "        #self.d = d\n",
    "        \n",
    "    def fit(self, X, size):\n",
    "        n, d = X.shape\n",
    "        \n",
    "        # calculate squared norms of points\n",
    "        #t0 = perf_counter()\n",
    "        model = KMeans(self.k)\n",
    "        norms = row_norms(X, squared=True)\n",
    "        cs = model._init_centroids(X, init='k-means++',\n",
    "                                  x_squared_norms=norms, random_state=np.random.RandomState(seed=0))\n",
    "        #print(\"D2 sampling took %f\" % (perf_counter() - t0))\n",
    "        \n",
    "        \n",
    "        dist = row_norms(X - nearest_neighbor(X, cs), squared=True)\n",
    "        cs_cost = np.sum(dist)\n",
    "        c_total = cs_cost / n      \n",
    "        \n",
    "        nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(cs)\n",
    "        _, indices = nbrs.kneighbors(X) # euclidean distance and labels\n",
    "        indices = indices.flatten()\n",
    "        \n",
    "        keys, counts = np.unique(indices, return_counts=True)\n",
    "        cluster_sizes = np.array(counts)\n",
    "        \n",
    "        \n",
    "        if c_total < 0.00001:\n",
    "            #print(\"Coreset centers cover whole space.\")\n",
    "            self.coreset = cs\n",
    "            self.weights = np.ones(cs.shape)/ self.k\n",
    "            return self\n",
    "        \n",
    "        # calculate sensitivity\n",
    "        cluster_cost = np.bincount(indices, dist)\n",
    "        cluster_sizes_ = cluster_sizes[indices]\n",
    "        \n",
    "        alpha = 16 * np.log2(self.k) + 32\n",
    "        s = alpha / c_total * dist + (2 * alpha * cluster_cost[indices] / c_total + 4 * n) / cluster_sizes_\n",
    "        \n",
    "        \n",
    "        p = s / np.sum(s)\n",
    "        \n",
    "        self.indices = np.random.choice(n, size = size, p = p)\n",
    "        self.coreset = X[self.indices]\n",
    "        self.weights = 1.0 / (size * p[self.indices])\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def result(self):\n",
    "        return (self.coreset, self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, k_means\n",
    "\n",
    "class BMFCoreset:\n",
    "    '''Using a Coreset for BMF'''\n",
    "    \n",
    "    def __init__(self, k, size, max_iter=300):\n",
    "        self.k = k\n",
    "        self.size = size\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def __fit(self, data):\n",
    "        n, d = data.shape\n",
    "        \n",
    "        #kmcs = LWCoreset(self.size).fit(data)\n",
    "        #t0 = perf_counter()\n",
    "        kmcs = KMeansCoreset(0.99, self.k).fit(data, self.size)\n",
    "        cs, ws = kmcs.result()\n",
    "        #print(\"Calculated Coreset in %f s\" % (perf_counter() - t0))\n",
    "        if cs.shape[0] > k:\n",
    "            kmeans = KMeans(init=\"k-means++\", n_clusters=self.k, max_iter=self.max_iter, n_init='auto')\n",
    "            kmeans.fit(cs, sample_weight=ws) # get clusters\n",
    "            self.centers_ = nearest_neighbor(kmeans.cluster_centers_, data)\n",
    "        else:\n",
    "            self.centers_ = cs\n",
    "        #print(\"Elapsed time for k-means: %f\" % (time() - t0))\n",
    "        #cluster_centers_, labels_, inertia_ = k_means(data, self.k, n_init='auto', max_iter=self.max_iter)\n",
    "        \n",
    "        #t1 = time()\n",
    "        #self.low_rank_ = nearest_neighbor(data, self.centers_)\n",
    "        self.low_rank_ = self.optimize(data)\n",
    "\n",
    "        #self.low_rank_ = centers_[labels_]\n",
    "        #print(\"Elapsed time for nearest-neighbors: %f\" % (time() - t1))\n",
    "        \n",
    "    def fit(self, data, labels = []):\n",
    "        if (data.ndim == 2):\n",
    "            self.__fit(data)\n",
    "            return self\n",
    "        else: \n",
    "            raise ValueError(\"Can not factorize a dataset of shape % s.\" % str(data.shape))\n",
    "            \n",
    "    def results(self):\n",
    "        return self.low_rank_\n",
    "    \n",
    "    def score(self, data, label):\n",
    "        return np.linalg.norm(data - self.low_rank_, ord='fro')\n",
    "    \n",
    "    def optimize(self, data):\n",
    "        combinations = []\n",
    "        # enumerate all possible linear combinations\n",
    "        for i in range(2**self.k):\n",
    "            if i % 10000 == 0 and i > 0:\n",
    "                print(i)\n",
    "            bits = []\n",
    "            for j, c in enumerate(bin(i)[:1:-1], 1):\n",
    "                if c == '1':\n",
    "                    bits.append(j-1)\n",
    "            combinations.append(np.sum(self.centers_[bits], axis=0))\n",
    "        combinations = np.mod(np.array(combinations), 2)\n",
    "        combinations = np.unique(combinations, axis=0)\n",
    "        # print(\"Obtained %d unique combinations.\" % combinations.shape[0])\n",
    "        return nearest_neighbor(data, np.array(combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d40c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, k_means\n",
    "\n",
    "class BMFLWCoreset:\n",
    "    '''Using a Lightweight Coreset for BMF'''\n",
    "    \n",
    "    def __init__(self, k, size, max_iter=300):\n",
    "        self.k = k\n",
    "        self.size = size\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def __fit(self, data):\n",
    "        n, d = data.shape\n",
    "        \n",
    "        #t0 = perf_counter()\n",
    "        kmcs = LWCoreset(self.size).fit(data)\n",
    "        cs, ws = kmcs.result()\n",
    "        #print(\"Calculated Coreset in %f s\" % (perf_counter() - t0))\n",
    "        \n",
    "        kmeans = KMeans(init=\"k-means++\", n_clusters=self.k, max_iter=self.max_iter, n_init='auto')\n",
    "        kmeans.fit(cs, sample_weight=ws) # get clusters\n",
    "        #print(\"Elapsed time for k-means: %f\" % (time() - t0))\n",
    "        #cluster_centers_, labels_, inertia_ = k_means(data, self.k, n_init='auto', max_iter=self.max_iter)\n",
    "        \n",
    "        #t1 = time()\n",
    "        self.centers_ = nearest_neighbor(kmeans.cluster_centers_, data)\n",
    "        #self.low_rank_ = nearest_neighbor(data, self.centers_)\n",
    "        self.low_rank_ = self.optimize(data)\n",
    "        \n",
    "    def fit(self, data, labels = []):\n",
    "        if (data.ndim == 2):\n",
    "            self.__fit(data)\n",
    "            return self\n",
    "        else: \n",
    "            raise ValueError(\"Can not factorize a dataset of shape % s.\" % str(data.shape))\n",
    "            \n",
    "    def results(self):\n",
    "        return self.low_rank_\n",
    "    \n",
    "    def score(self, data, label):\n",
    "        return np.linalg.norm(data - self.low_rank_, ord='fro')\n",
    "\n",
    "    def optimize(self, data):\n",
    "        combinations = []\n",
    "        # enumerate all possible linear combinations\n",
    "        for i in range(2**self.k):\n",
    "            if i % 10000 == 0 and i > 0:\n",
    "                print(i)\n",
    "            bits = []\n",
    "            for j, c in enumerate(bin(i)[:1:-1], 1):\n",
    "                if c == '1':\n",
    "                    bits.append(j-1)\n",
    "            combinations.append(np.sum(self.centers_[bits], axis=0))\n",
    "        combinations = np.mod(np.array(combinations), 2)\n",
    "        combinations = np.unique(combinations, axis=0)\n",
    "        # print(\"Obtained %d unique combinations.\" % combinations.shape[0])\n",
    "        return nearest_neighbor(data, np.array(combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, Binarizer\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "def bench_bmf(bmf, name, k, data):\n",
    "    \"\"\"Benchmark to evaluate binary matrix factorization algorithms.\n",
    "    \n",
    "    Parameters\n",
    "    -----------------\n",
    "    bmf: BMF instance\n",
    "        a BMF instance with k already set\n",
    "    name: str\n",
    "        Name of the algorithm.\n",
    "    data: ndarray of shape (n_matrices, n_d1, n_d2)\n",
    "        A dataset of matrices to find low rank binary approximations to.\n",
    "    \"\"\"\n",
    "    results = [name, k]\n",
    "    warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "    \n",
    "    # normalize the data\n",
    "    shape_ = data.shape\n",
    "    if data.ndim == 3:\n",
    "        data = data.reshape(shape_[0] * shape_[1], shape_[2])  \n",
    "    data = Binarizer(threshold=0.33).transform(MinMaxScaler().fit_transform(data)).reshape(shape_)\n",
    "\n",
    "    \n",
    "    \n",
    "    if data.ndim == 2:\n",
    "        # data is a single matrix\n",
    "        t0 = perf_counter()\n",
    "        bmf.fit(data)\n",
    "        fit_time = perf_counter() - t0\n",
    "        results.append(fit_time * 1000)\n",
    "        results.append(bmf.score(data,data))\n",
    "        results.append(bmf.score(data,data))\n",
    "\n",
    "    if data.ndim == 3:\n",
    "        # dataset is a number of matrices\n",
    "        times = []\n",
    "        error = []\n",
    "        i = 0\n",
    "\n",
    "        for d in data:\n",
    "            #sleep(1)\n",
    "            t0 = perf_counter()\n",
    "            bmf.fit(d)\n",
    "            fit_time = perf_counter() - t0\n",
    "            err = bmf.score(d,d)\n",
    "            #t1 = perf_counter()\n",
    "            #bmf.fit(d.T)\n",
    "            #fit_time = fit_time + (perf_counter() - t1)\n",
    "            #err = min(err_1, bmf.score(d.T, d.T))\n",
    "            times.append(fit_time * 1000)\n",
    "            error.append(err)\n",
    "            i+=1\n",
    "            if i % 25 == 0:\n",
    "                print(\"\\r\" + name + \"-\" + str(k) + \": Processed %d elements\" % i, end=\"\")\n",
    "            # Show the results\n",
    "        \n",
    "        #m = 10\n",
    "        #largest = sorted(range(len(error)), key = lambda sub: error[sub])[-m:]\n",
    "        #print((\"Worst %d instances are \" % m) + str(largest))\n",
    "        \n",
    "        results.append(np.average(times))\n",
    "        results.append(np.average(error))\n",
    "        results.append(np.median(error))\n",
    "    \n",
    "    formatter_result = (\n",
    "        \"{:8s}\\t{:d}\\t{:2.3f}ms\\t{:.3f}\\t{:.3f}          \"\n",
    "    )\n",
    "    print(\"\\r\" + formatter_result.format(*results))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa891496",
   "metadata": {},
   "source": [
    "# Synthetic Data Generation\n",
    "\n",
    "The following functions are used for sampling full rank synthetic data, low rank synthetic data and noisy low rank synthetic data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fa1c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_random(n, d, q):\n",
    "    \"\"\"Generate a random n by d matrix where each entry is 1 with probability q\"\"\"\n",
    "    return np.random.choice(2, size=(n,d), p=[1-q, q])\n",
    "    \n",
    "def generate_synthetic_rank_k(n, d, q, k):\n",
    "    \"\"\"Generate a random n by d matrix via two uniformly sampled low rank matrices\"\"\"\n",
    "    A_ = np.random.choice(2, size=(n,k), p=[1-q, q])\n",
    "    B_ = np.random.choice(2, size=(k,d), p=[1-q, q])\n",
    "    return np.mod(A_ @ B_, 2)\n",
    "\n",
    "def generate_noisy_rank_k(n,d,q,k,p):\n",
    "    \"\"\"Generate a random n by d matrix via two uniformly sampled low rank matrices, where with probability p we flip a bit\"\"\"\n",
    "    A_ = np.random.choice(2, size=(n,k), p=[1-q, q])\n",
    "    B_ = np.random.choice(2, size=(k,d), p=[1-q, q])\n",
    "    C = np.mod(A_ @ B_, 2)\n",
    "    \n",
    "    flip = np.random.rand(n,d) < p\n",
    "    C[flip] = 1 - C[flip]\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464607c7",
   "metadata": {},
   "source": [
    "# Loading the Datasets\n",
    "\n",
    "We load the MNIST, ORL, ThyroidRL and Congress Vote Datasets and process them into binary matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6058543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the mnist dataset\n",
    "\n",
    "import gzip\n",
    "\n",
    "f = gzip.open('./datasets/mnist/train-images-idx3-ubyte.gz')\n",
    "image_size = 28\n",
    "num_images = 60000\n",
    "\n",
    "f.read(16)\n",
    "buf = f.read(image_size**2 * num_images)\n",
    "mnist = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "mnist = mnist.reshape(num_images, image_size, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4350d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "\n",
    "# we assume that all pgm files live in the same directory \n",
    "orl = np.array([cv2.imread(file,0) for file in glob.glob(\"./datasets/orl/*.pgm*\")])\n",
    "orl_shape = orl.shape\n",
    "orl = orl.reshape((orl_shape[0] * orl_shape[1] * orl_shape[2], 1))\n",
    "orl = Binarizer(threshold=0.33).fit_transform(MinMaxScaler().fit_transform(np.array(orl)))\n",
    "orl = orl.reshape(orl_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4c1de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read congressional votes dataset\n",
    "\n",
    "def convert_voting(s):\n",
    "    if s == b'y':\n",
    "        return 1.0\n",
    "    if s == b'n':\n",
    "        return 0.0\n",
    "    if s == b'?':\n",
    "        return 0.0\n",
    "    if s == b'republican':\n",
    "        return 1.0\n",
    "    if s == b'democrat':\n",
    "        return 0.0\n",
    "\n",
    "from numpy import loadtxt\n",
    "file = open('./datasets/house-votes-84.csv')\n",
    "congress = loadtxt(file, delimiter=',', skiprows=1, converters=convert_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aea3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "thyroid =pd.read_csv('./datasets/thyroidDF.csv')\n",
    "display(thyroid)\n",
    "thyroid.drop(['age', 'TT4', 'T4U', 'TSH', 'T3', 'FTI', 'TBG', 'referral_source', 'target', 'patient_id'], axis=1, inplace=True)\n",
    "\n",
    "thyroid_map = {'F' : 1.0, 'M': 0.0, 'f': 0.0, 't': 1.0, 'NaN': 0.0}\n",
    "thyroid = thyroid.replace(thyroid_map).to_numpy()\n",
    "\n",
    "thyroid[np.argwhere(np.isnan(thyroid))] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac686fa",
   "metadata": {},
   "source": [
    "# Coreset Size Experiments\n",
    "\n",
    "Here we evaluate the effect of coreset size on the Frobenius norm error. We generate 100 full rank binary matrices and compare the effect of coreset size on the average error of 10 runs of each algorithm. We run the experiment for values of $k \\in \\{2,3,5,10,15\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0de792",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_low_rank_test = generate_noisy_rank_k(5000,50,0.5,5,0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e15227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "ks = [2, 3, 5, 10]\n",
    "n_runs = 20\n",
    "\n",
    "datasets = [cs_low_rank_test, congress, thyroid]\n",
    "dataset_names = [\"low_rank\", \"congress\", \"thyroid\"]\n",
    "\n",
    "coreset_dataframe = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Size': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "            \n",
    "for k in ks:\n",
    "    for (name, data) in zip(dataset_names, datasets):\n",
    "        for i in range(n_runs):\n",
    "            print(i)\n",
    "            bmf = BMFKMeans_plus(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"k-means bmf\", k=k, data=data)\n",
    "            \n",
    "            for size in sizes: \n",
    "                row = pd.Series({'Dataset': name, 'Algorithm': 'bmf+', 'k': k, 'Size': size, 'Error': res[3], 'Time': res[2]})\n",
    "                coreset_dataframe = pd.concat([coreset_dataframe, row.to_frame().T], ignore_index=True)\n",
    "\n",
    "            for size in sizes:\n",
    "                coreset_size = max(k, np.ceil(data.shape[1] * size).astype(int))\n",
    "                \n",
    "                bmf = BMFCoreset(k, coreset_size)\n",
    "                res = bench_bmf(bmf=bmf, name=\"coreset bmf\", k=k, data=data)\n",
    "                \n",
    "                row = pd.Series(\n",
    "                    {'Dataset': name, 'Algorithm': 'coreset-bmf+', 'k': k, 'Size': size, 'Error': res[3], 'Time': res[2]})\n",
    "                coreset_dataframe = pd.concat([coreset_dataframe, row.to_frame().T], ignore_index=True)\n",
    "                \n",
    "                bmf = BMFLWCoreset(k, coreset_size)\n",
    "                res = bench_bmf(bmf=bmf, name=\"lw bmf\", k=k, data=data)\n",
    "                \n",
    "                row = pd.Series(\n",
    "                    {'Dataset': name, 'Algorithm': 'lw-coreset-bmf+', 'k': k, 'Size': size, 'Error': res[3], 'Time': res[2]})\n",
    "                coreset_dataframe = pd.concat([coreset_dataframe, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"colorblind\")\n",
    "\n",
    "cs_df = coreset_dataframe\n",
    "\n",
    "plot = sns.FacetGrid(data=cs_df[(cs_df['k'] == 5) | (cs_df['k'] == 10)], hue='Algorithm', col='Dataset', row='k', sharey=False, sharex=False)\n",
    "\n",
    "plot.map(sns.lineplot, 'Size', 'Error', errorbar=\"se\")\n",
    "\n",
    "plot.add_legend(title=\"Algorithm\")\n",
    "\n",
    "fig = plot.fig\n",
    "fig.savefig(\"coreset-plot.png\", transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bc40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coreset time \n",
    "sizes = [0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "ks = [2, 3, 5, 10]\n",
    "n_runs = 20\n",
    "\n",
    "datasets = [cs_low_rank_test, congress, thyroid]\n",
    "dataset_names = [\"low_rank\", \"congress\", \"thyroid\"]\n",
    "\n",
    "coreset_time = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Size': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for k in ks:\n",
    "    for (name, data) in zip(dataset_names, datasets):\n",
    "        print(name)\n",
    "        for i in range(n_runs):\n",
    "            print(i)\n",
    "            for size in sizes:\n",
    "                coreset_size = max(k, np.ceil(data.shape[1] * size).astype(int))\n",
    "                \n",
    "                t0 = perf_counter()\n",
    "                kmcs = KMeansCoreset(0.99, k).fit(data, coreset_size)\n",
    "                res = perf_counter() - t0\n",
    "                \n",
    "                row = pd.Series(\n",
    "                    {'Dataset': name, 'Algorithm': 'coreset', 'k': k, 'Size': size, 'Time': res})\n",
    "                coreset_time = pd.concat([coreset_time, row.to_frame().T], ignore_index=True)\n",
    "                \n",
    "                t0 = perf_counter()\n",
    "                kmcs = LWCoreset(coreset_size).fit(data)\n",
    "                res = perf_counter() - t0\n",
    "                \n",
    "                row = pd.Series(\n",
    "                    {'Dataset': name, 'Algorithm': 'lw-coreset', 'k': k, 'Size': size, 'Time': res})\n",
    "                coreset_time = pd.concat([coreset_time, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6a433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cst_df = coreset_time\n",
    "\n",
    "cst_df.groupby(['k', 'Algorithm'])['Time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8a7cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_df.groupby(['k', 'Algorithm', 'Dataset']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eec214",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_df.to_pickle('./cs_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c8a8d4",
   "metadata": {},
   "source": [
    "# Comparative Experiments on Real and Synthetic Data\n",
    "\n",
    "In the experimental setup of these experiments, we compare only the quality (and runtime) of the approximation produced, using only the final matrix produced by the heuristics, without taking into account the low-rank factors produced by the algorithm and whether these are binary. Furthermore, the algorithms are used in a black box manner, which means that they may use the Boolean semiring, or GF(2) to perform matrix operations internally or may use non Boolean factors. \n",
    "\n",
    "We compare the frobenius norm error of the algorithms.\n",
    "\n",
    "Even under ideal conditions, our post-processing step produces the best quality approximation with only a small runtime overhead for small k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708551bf",
   "metadata": {},
   "source": [
    "## Benchmarking on Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e04c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_full = np.array([generate_synthetic_random(250, 50, 0.5) for i in range(25)])\n",
    "synthetic_low_rank_5 = np.array([generate_synthetic_rank_k(250, 50, 0.5, 5) for i in range(25)])\n",
    "synthetic_low_rank_10 = np.array([generate_synthetic_rank_k(250, 50, 0.5, 10) for i in range(25)])\n",
    "synthetic_low_rank_15 = np.array([generate_synthetic_rank_k(250, 50, 0.5, 15) for i in range(25)])\n",
    "synthetic_noisy_10_001 = np.array([generate_noisy_rank_k(250, 50, 0.5, 10, 0.01) for i in range(25)])\n",
    "synthetic_noisy_10_0001 = np.array([generate_noisy_rank_k(250, 50, 0.5, 10, 0.001) for i in range(25)])\n",
    "synthetic_full_ = np.array([generate_synthetic_random(250, 50, 0.1) for i in range(25)])\n",
    "synthetic_low_rank_5_ = np.array([generate_synthetic_rank_k(250, 50, 0.1, 5) for i in range(25)])\n",
    "synthetic_low_rank_10_ = np.array([generate_synthetic_rank_k(250, 50, 0.1, 10) for i in range(25)])\n",
    "synthetic_low_rank_15_ = np.array([generate_synthetic_rank_k(250, 50, 0.1, 15) for i in range(25)])\n",
    "synthetic_noisy_10_001_ = np.array([generate_noisy_rank_k(250, 50, 0.1, 10, 0.01) for i in range(25)])\n",
    "synthetic_noisy_10_0001_ = np.array([generate_noisy_rank_k(250, 50, 0.1, 10, 0.001) for i in range(25)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419f53a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "datasets = [synthetic_full, synthetic_low_rank_5, synthetic_low_rank_10, synthetic_low_rank_15, \n",
    "           synthetic_noisy_10_001, synthetic_noisy_10_0001,\n",
    "            synthetic_full_, synthetic_low_rank_5_, synthetic_low_rank_10_, synthetic_low_rank_15_, \n",
    "           synthetic_noisy_10_001_, synthetic_noisy_10_0001_]\n",
    "dataset_names = [\"full\", \"lr5\", \"lr10\", \"lr15\", \"noisy10-001\", \"noisy10-0001\", \n",
    "                 \"full0.1\", \"lr5-0.1\", \"lr10-0.1\", \"lr15-0.1\", \"noisy10-001-0.1\", \"noisy10-0001-0.1\", \n",
    "                ]\n",
    "\n",
    "synth_df = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "            \n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        for i in range(n_runs):\n",
    "            bmf = BMFKMeans(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf', 'k': k, 'Error': res[3], 'Time': (res[2] / 1000)})\n",
    "            synth_df = pd.concat([synth_df, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            bmf = BMFKMeans_plus(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf+\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf+', 'k': k, 'Error': res[3], 'Time': (res[2]/1000)})\n",
    "            synth_df = pd.concat([synth_df, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25736020",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_df.to_pickle('./synth_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb664609",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nimfa\n",
    "\n",
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "synth_df_nimfa = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        for i in range(n_runs):\n",
    "            avg_error = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()\n",
    "                bmf = nimfa.Bmf(mat, seed=\"nndsvd\", rank=k, max_iter=10000, lambda_w=1.1, lambda_h=1.1)\n",
    "                bmf_fit = bmf()\n",
    "                bmf_fitted = bmf.fitted()\n",
    "                bmf_fitted = Binarizer(threshold=0.5).fit_transform(np.array(bmf_fitted))\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                avg_error.append(np.linalg.norm(bmf_fitted - mat))\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'nimfa', 'k': k, 'Error': np.average(avg_error), 'Time': np.average(avg_time)})\n",
    "            synth_df_nimfa = pd.concat([synth_df_nimfa, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20de25b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "synth_df_nimfa.to_pickle('./synth_df_nimfa.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72711f32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from binmf import fit_spfact\n",
    "\n",
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "synth_df_binmf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        for i in range(n_runs):\n",
    "            avg_error = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()\n",
    "                nrows, ncols = mat.shape\n",
    "\n",
    "                sp_mat = csr_matrix(mat)\n",
    "                row_fact = np.random.normal(size=(nrows, k))\n",
    "                col_fact = np.random.normal(size=(ncols, k))\n",
    "                fit_spfact(sp_mat, row_fact, col_fact, reg_param=1e-1, niter=200, nthreads=8) #adjust number of threads for your setup\n",
    "                approx = row_fact @ col_fact.T\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                \n",
    "                avg_error.append(np.linalg.norm(Binarizer(threshold=0.5).fit_transform(approx) - mat))\n",
    "            \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'binmf', 'k': k, 'Error': np.average(avg_error), 'Time': np.average(avg_time)})\n",
    "            \n",
    "            synth_df_binmf = pd.concat([synth_df_binmf, row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dafa4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_df_binmf.to_pickle('./synth_df_binmf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: Ravanbakhsh Siamak, Poczos Barnabas, Greiner Russell, Boolean Matrix Factorization and Noisy Completion via Message Passing, ICML 2016\n",
    "\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def log_ratio(x):\n",
    "    return np.log(x) - np.log(1. - x)\n",
    "\n",
    "def get_random_matrices(M, N, K, p_x_1 = .5, p_y_1 = .5, p_flip = 0, p_observe = .1):\n",
    "    X = (np.random.rand(M, K) < p_x_1).astype(int)\n",
    "    Y = (np.random.rand(N, K) < p_y_1).astype(int)\n",
    "    Z = (X.dot(Y.T) > 0).astype(int)\n",
    "    mask = np.random.rand(M,N) < p_observe\n",
    "    O = Z.copy()\n",
    "    \n",
    "    flip = np.random.rand(M,N) < p_flip\n",
    "    O[flip] = 1 - O[flip]\n",
    "    mats = {'X':X, 'Y':Y, 'Z':Z, 'O':O, 'mask':mask}\n",
    "    return mats\n",
    "\n",
    "def hamming(X,Y):\n",
    "    return np.sum(np.abs(X - Y) > 1e-5)\n",
    "\n",
    "def density(X):\n",
    "    return np.sum(X)/float(np.prod(X.shape))\n",
    "\n",
    "\n",
    "def rec_error(Z, Zh):\n",
    "    return np.sum(np.abs(Z - Zh))/float(np.prod(Z.shape))\n",
    "\n",
    "\n",
    "def read_csv(fname, delimiter = ','):\n",
    "    mat = np.genfromtxt(fname, delimiter=delimiter)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8193dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pdb\n",
    "\n",
    "\n",
    "class MatrixCompletion(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 O, #observed matrix (only the parts indicated by mask will be used)\n",
    "                 K, #hidden dim\n",
    "                 mask = None,#boolean matrix the same size as O\n",
    "                 min_sum = True,                 \n",
    "                 tol = 1e-4,#tolerance for message updates\n",
    "                 learning_rate = .2, #damping parameter\n",
    "                 max_iter = 500, #maximum number of message passing updates\n",
    "                 verbose = False,\n",
    "                 p_x_1 = .5, #the prior probability of x=1. For regularization use small or large values in [0,1]\n",
    "                 p_y_1 = .5, #the prior probability of y=1. For regularization use small or large values in [0,1]\n",
    "                 #note that when p_x and p_y are uniform the MAP assignment is not sensitive\n",
    "                 #to the following values, assuming they are the same and above .5\n",
    "                 p_1_given_1 = .99, #the model of the noisy channel: probability of observing 1 for the input of 1\n",
    "                 p_0_given_0 = .99, #similar to the above\n",
    "                ):\n",
    "        \n",
    "        assert(p_x_1 < 1 and p_x_1 > 0)\n",
    "        assert(p_y_1 < 1 and p_y_1 > 0)\n",
    "        assert(p_1_given_1 > .5 and p_1_given_1 < 1)\n",
    "        assert(p_0_given_0 > .5 and p_0_given_0 < 1)                \n",
    "        \n",
    "        self.O = O.astype(int)\n",
    "        self.M,self.N = O.shape\n",
    "        self.K = K\n",
    "        self.verbose = verbose\n",
    "\n",
    "        assert(self.K < min(self.M,self.N))\n",
    "        if mask is not None:\n",
    "            assert(mask.shape[0] == self.M and mask.shape[1] == self.N)\n",
    "            self.mask = mask.astype(bool)\n",
    "        else:\n",
    "            self.mask = np.ones(O.shape, dtype=bool)\n",
    "            \n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.min_sum = min_sum\n",
    "        self.num_edges = np.sum(self.mask)        \n",
    "\n",
    "        self.update_adj_list()\n",
    "        \n",
    "        # will be used frequently\n",
    "        self.pos_edges = np.nonzero(O[mask])[0]\n",
    "        self.neg_edges = np.nonzero(1 - O[mask])[0]\n",
    "        self.range_edges = np.arange(self.num_edges)\n",
    "        self.cx = np.log(p_x_1) - np.log(1 - p_x_1)\n",
    "        self.cy = np.log(p_y_1) - np.log(1 - p_y_1)\n",
    "        self.co1 = np.log(p_1_given_1) - np.log(1. - p_0_given_0) #log(p(1|1)/p(1|0))\n",
    "        self.co0 = np.log(1. - p_1_given_1) - np.log(p_0_given_0) ##log(p(0|1)/p(0|0))\n",
    "\n",
    "    \n",
    "    def init_msgs_n_marginals(self):\n",
    "        self.marg_x = np.zeros((self.M, self.K))\n",
    "        self.marg_y = np.zeros((self.N, self.K))\n",
    "        self.in_x = np.zeros((self.num_edges, self.K)) #message going towards variable X: phi in the papger\n",
    "        self.new_in_x = np.zeros((self.num_edges, self.K)) #the new one\n",
    "        \n",
    "        self.out_x = np.log((np.random.rand(self.num_edges, self.K)))#/self.M #message leaving variable x: phi_hat in the paper \n",
    "        self.in_y = np.zeros((self.num_edges, self.K)) #message leaving variable y: psi in the paper\n",
    "        self.new_in_y = np.zeros((self.num_edges, self.K))\n",
    "        self.out_y = np.log(np.random.rand(self.num_edges, self.K))#/self.N #psi_hat in the paper\n",
    "        self.in_z = np.zeros((self.num_edges, self.K)) #gamma in the paper\n",
    "        self.out_z = np.zeros((self.num_edges, self.K)) #gamma_hat in the paper\n",
    "        \n",
    "        \n",
    "    def update_adj_list(self):\n",
    "        ''' nbM: list of indices of nonzeros organized in rows\n",
    "        nbM: list of indices of nonzeros organized in columns\n",
    "        '''\n",
    "        \n",
    "        Mnz,Nnz = np.nonzero(self.mask)\n",
    "        M = self.M\n",
    "        N = self.N\n",
    "        nbM = [[] for i in range(M)] \n",
    "        nbN = [[] for i in range(N)]\n",
    "\n",
    "        for z in range(len(Mnz)):\n",
    "            nbN[Nnz[z]].append(z)\n",
    "            nbM[Mnz[z]].append(z)\n",
    "\n",
    "        for i in range(M):\n",
    "            nbM[i] = np.array(nbM[i], dtype=int)\n",
    "        for i in range(N):\n",
    "            nbN[i] = np.array(nbN[i], dtype=int)\n",
    "            \n",
    "        self.rows = nbM\n",
    "        self.cols = nbN\n",
    "\n",
    "        \n",
    "    \n",
    "    def run(self):\n",
    "        self.init_msgs_n_marginals()\n",
    "        iters = 1\n",
    "        diff_msg = np.inf\n",
    "\n",
    "        while (diff_msg > self.tol and iters <= self.max_iter) or iters < 5:\n",
    "            self.update_min_sum()#(outX, outY, inZ, outZ, newInX, newInY, posEdges, negEdges,  opt)\n",
    "            diff_msg = np.max(np.abs(self.new_in_x - self.in_x))\n",
    "            self.in_x *= (1. - self.learning_rate)\n",
    "            self.in_x += self.learning_rate * (self.new_in_x)\n",
    "            self.in_y *= (1. - self.learning_rate)\n",
    "            self.in_y += self.learning_rate * (self.new_in_y)\n",
    "            self.update_margs()\n",
    "            if self.verbose:\n",
    "                print(\"iter %d, diff:%f\" %(iters, diff_msg))\n",
    "            #else:\n",
    "                #print(iters)\n",
    "                #sys.stdout.flush()\n",
    "                \n",
    "            iters += 1\n",
    "\n",
    "        #recover X and Y from marginals and reconstruct Z\n",
    "        self.X = (self.marg_x > 0).astype(int)\n",
    "        self.Y = (self.marg_y > 0).astype(int)\n",
    "        self.Z = (self.X.dot(self.Y.T) > 0).astype(int)\n",
    "\n",
    "        \n",
    "        \n",
    "    def update_min_sum(self):\n",
    "        self.in_z = np.minimum(np.minimum(self.out_x + self.out_y, self.out_x), self.out_y) #gamma update in the paper\n",
    "        \n",
    "        inz_pos = np.maximum(0.,self.in_z) # calculate it now, because we're chaning inz\n",
    "        #find the second larges element along the 1st axis (there's also a 0nd! axis)\n",
    "        inz_max_ind = np.argmax(self.in_z, axis=1)\n",
    "        inz_max = np.maximum(-self.in_z[self.range_edges, inz_max_ind],0)\n",
    "        self.in_z[self.range_edges, inz_max_ind] = -np.inf\n",
    "        inz_max_sec = np.maximum(-np.max(self.in_z, axis=1),0) # update for gamma_hat in the paper\n",
    "        sum_val = np.sum(inz_pos, axis=1)\n",
    "        #penalties/rewards for confoming with observations\n",
    "        sum_val[self.pos_edges] += self.co1\n",
    "        sum_val[self.neg_edges] += self.co0\n",
    "        \n",
    "        tmp_inz_max = inz_max.copy()\n",
    "        inz_pos =  sum_val[:, np.newaxis] - inz_pos\n",
    "        \n",
    "        for k in range(self.K):\n",
    "            self_max_ind = np.nonzero(inz_max_ind == k)[0]#find the indices where the max incoming message is from k\n",
    "            tmp_inz_max[self_max_ind] = inz_max_sec.take(self_max_ind)#replace the value of the max with the second largest value\n",
    "            self.out_z[:, k] = np.minimum( tmp_inz_max, inz_pos[:,k])#see the update for gamma_hat\n",
    "            tmp_inz_max[self_max_ind] = inz_max.take(self_max_ind)#fix tmp_iz_max for the next iter\n",
    "\n",
    "        # update in_x and in_y: phi_hat and psi_hat in the paper\n",
    "        self.new_in_x = np.maximum(self.out_z + self.out_y, 0) - np.maximum(self.out_y,0)\n",
    "        self.new_in_y = np.maximum(self.out_z + self.out_x, 0) - np.maximum(self.out_x,0)\n",
    "\n",
    "    \n",
    "\n",
    "    def update_margs(self):\n",
    "        #updates for phi and psi\n",
    "        for m in range(self.M):\n",
    "            self.marg_x[m,:] = np.sum(self.in_x.take(self.rows[m],axis=0), axis=0) + self.cx\n",
    "            self.out_x[self.rows[m], :] = -self.in_x.take(self.rows[m],axis=0) + self.marg_x[m,:]\n",
    "\n",
    "        for n in range(self.N):\n",
    "            self.marg_y[n, :] = np.sum(self.in_y.take(self.cols[n], axis=0), axis=0) + self.cy\n",
    "            self.out_y[self.cols[n], :] = -self.in_y.take(self.cols[n], axis=0) + self.marg_y[n,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc590f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "synth_mpf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        for i in range(n_runs):\n",
    "            avg_error = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()             \n",
    "                \n",
    "                mask = np.random.rand(mat.shape[0], mat.shape[1]) < 0.99\n",
    "                comp = MatrixCompletion(mat, k, mask = mask, min_sum = True, verbose = False, max_iter = 100)\n",
    "                comp.run()\n",
    "                \n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                avg_error.append(np.linalg.norm(Binarizer(threshold=0.5).fit_transform(comp.Z) - mat))\n",
    "            \n",
    "            print(np.average(avg_error))\n",
    "            print(np.average(avg_time))\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'mpbmf', 'k': k, 'Error': np.average(avg_error), 'Time': np.average(avg_time)})\n",
    "            \n",
    "            synth_mpf = pd.concat([synth_mpf, row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad536e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_mpf.to_pickle(\"./synth_mpf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba37a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_df\n",
    "synth_df_bmf = synth_df[(synth_df['Algorithm'] == 'bmf') | (synth_df['Algorithm'] == 'bmf+')]\n",
    "\n",
    "display(synth_df_bmf)\n",
    "\n",
    "synth_df_bmf.to_pickle(\"./synth_df_bmf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a10d4d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "synth_df.groupby([\"Dataset\", \"k\", \"Algorithm\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7470ad",
   "metadata": {},
   "source": [
    "## Benchmarking on Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14af2b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "# datasets are generally three dimensional\n",
    "datasets = [ orl, np.array([congress]), np.array([thyroid]) ]\n",
    "dataset_names = [\"orl\", \"congress\", \"thyroid\",  \n",
    "                ]\n",
    "\n",
    "real_df_bmf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "            \n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        for i in range(n_runs):\n",
    "            bmf = BMFKMeans(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf', 'k': k, 'Error': res[3], 'Time': (res[2] / 1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            bmf = BMFKMeans_plus(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf+\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf+', 'k': k, 'Error': res[3], 'Time': (res[2]/1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebccd752",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_bmf.to_pickle('./real_df_bmf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nimfa\n",
    "\n",
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_nimfa = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        for i in range(n_runs):\n",
    "            avg_error = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()\n",
    "                bmf = nimfa.Bmf(mat, seed=\"nndsvd\", rank=k, max_iter=10000, lambda_w=1.1, lambda_h=1.1)\n",
    "                bmf_fit = bmf()\n",
    "                bmf_fitted = bmf.fitted()\n",
    "                bmf_fitted = Binarizer(threshold=0.5).fit_transform(np.array(bmf_fitted))\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                avg_error.append(np.linalg.norm(bmf_fitted - mat))\n",
    "                print(bmf_fitted)\n",
    "                print(mat)\n",
    "                print(avg_error[-1])\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'nimfa', 'k': k, 'Error': np.average(avg_error), 'Time': np.average(avg_time)})\n",
    "            real_df_nimfa = pd.concat([real_df_nimfa, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c062af",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_nimfa.to_pickle('./real_df_nimfa.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a8ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from binmf import fit_spfact\n",
    "\n",
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_binmf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        for i in range(n_runs):\n",
    "            avg_error = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()\n",
    "                nrows, ncols = mat.shape\n",
    "\n",
    "                sp_mat = csr_matrix(mat)\n",
    "                row_fact = np.random.normal(size=(nrows, k))\n",
    "                col_fact = np.random.normal(size=(ncols, k))\n",
    "                fit_spfact(sp_mat, row_fact, col_fact, reg_param=1e-1, niter=200, nthreads=8) #adjust number of threads for your setup\n",
    "                approx = row_fact @ col_fact.T\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                \n",
    "                avg_error.append(np.linalg.norm(Binarizer(threshold=0).fit_transform(approx) - mat))\n",
    "            \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'binmf', 'k': k, 'Error': np.average(avg_error), 'Time': np.average(avg_time)})\n",
    "            \n",
    "            real_df_binmf = pd.concat([real_df_binmf, row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ee532",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_binmf.to_pickle('./real_df_binmf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c4598",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_mpf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        for i in range(n_runs):\n",
    "            avg_error = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()             \n",
    "                \n",
    "                mask = np.random.rand(mat.shape[0], mat.shape[1]) < 0.99\n",
    "                comp = MatrixCompletion(mat, k, mask = mask, min_sum = True, verbose = False, max_iter = 100)\n",
    "                comp.run()\n",
    "                \n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                avg_error.append(np.linalg.norm(Binarizer(threshold=0.5).fit_transform(comp.Z) - mat))\n",
    "            \n",
    "            print(np.average(avg_error))\n",
    "            print(np.average(avg_time))\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'mpbmf', 'k': k, 'Error': np.average(avg_error), 'Time': np.average(avg_time)})\n",
    "            \n",
    "            real_df_mpf = pd.concat([real_df_mpf, row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b47e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_mpf.to_pickle('./real_df_mpf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab9210",
   "metadata": {},
   "source": [
    "# Comparisons on Real Data for different lp-norms and regular matrix multiplication\n",
    "\n",
    "We now compare the approximations produced by the heuristics for Lp norms on the integers for $p \\in \\{1, 2, 5\\}$. Note that the case $p = 2$ is the setting of minimizing the Frobenius norm that we initially discuss in our paper. \n",
    "\n",
    "As some of the heuristics do not produce low rank factors that are boolean, we binarize them using a threshold chosen such that the error across experiments is minimized. This is the case for the NIMFA and binmf heuristics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b45129",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "# datasets are generally three dimensional\n",
    "datasets = [ orl, np.array([congress]), np.array([thyroid]) ]\n",
    "dataset_names = [\"orl\", \"congress\", \"thyroid\",  \n",
    "                ]\n",
    "\n",
    "real_df_bmf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "            \n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        for i in range(n_runs):\n",
    "            bmf = BMFKMeans(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf', 'k': k, 'Error': res[3], 'Time': (res[2] / 1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            bmf = BMFKMeans_plus_int_1(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf+ (int, l1)\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf+ (int, l1)', 'k': k, 'Error': res[3], 'Time': (res[2]/1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            bmf = BMFKMeans_plus_int_2(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf+ (int, l2)\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf+ (int, l2)', 'k': k, 'Error': res[3], 'Time': (res[2]/1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            bmf = BMFKMeans_plus_int_5(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf+ (int, l5)\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf+ (int, l5)', 'k': k, 'Error': res[3], 'Time': (res[2]/1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_bmf.to_pickle('./real_df_bmf_int.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b161ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmf = nimfa.Bmf(congress, seed=\"nndsvd\", rank=15, max_iter=10000, lambda_w=1.1, lambda_h=1.1)\n",
    "bmf_fit = bmf()\n",
    "b = Binarizer(threshold=0.3)               \n",
    "l = b.fit_transform(np.asarray(bmf.basis()))\n",
    "r = b.fit_transform(np.asarray(bmf.coef()))\n",
    "#l = bmf.basis()\n",
    "#r = bmf.coef()\n",
    "bmf_fitted = l @ r\n",
    "\n",
    "print(np.square(np.linalg.norm(congress - bmf_fitted)))\n",
    "\n",
    "plt.imshow(bmf_fitted)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08f52da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04bb963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nimfa\n",
    "\n",
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_nimfa = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        for i in range(n_runs):\n",
    "            avg_error_l1 = []\n",
    "            avg_error_l2 = []\n",
    "            avg_error_l5 = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()\n",
    "                bmf = nimfa.Bmf(mat, seed=\"nndsvd\", rank=k, max_iter=10000, lambda_w=1.1, lambda_h=1.1)\n",
    "                bmf_fit = bmf()\n",
    "                b = Binarizer(threshold=0.3)               \n",
    "                l = b.fit_transform(np.asarray(bmf.basis()))\n",
    "                r = b.fit_transform(np.asarray(bmf.coef()))\n",
    "                bmf_fitted = l @ r\n",
    "\n",
    "                #bmf_fitted = bmf.fitted()\n",
    "                #bmf_fitted = Binarizer(threshold=0.5).fit_transform(np.array(bmf_fitted))\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                avg_error_l2.append(np.square(np.linalg.norm(bmf_fitted - mat)))\n",
    "                avg_error_l1.append(np.sum(np.abs(bmf_fitted - mat)))\n",
    "                avg_error_l5.append(np.power(np.linalg.norm((bmf_fitted-mat).flatten(), ord=5) , 5))\n",
    "                #print(bmf_fitted)\n",
    "                #print(mat)\n",
    "                #print(avg_error[-1])\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'nimfa l1', 'k': k, 'Error': np.average(avg_error_l1), 'Time': np.average(avg_time)})\n",
    "            real_df_nimfa = pd.concat([real_df_nimfa, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'nimfa l2', 'k': k, 'Error': np.average(avg_error_l2), 'Time': np.average(avg_time)})\n",
    "            real_df_nimfa = pd.concat([real_df_nimfa, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'nimfa l5', 'k': k, 'Error': np.average(avg_error_l5), 'Time': np.average(avg_time)})\n",
    "            real_df_nimfa = pd.concat([real_df_nimfa, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da48050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_nimfa.to_pickle('./real_df_nimfa_int.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95110ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from binmf import fit_spfact\n",
    "\n",
    "mat = orl[6]\n",
    "k = 15\n",
    "\n",
    "nrows, ncols = mat.shape\n",
    "\n",
    "sp_mat = csr_matrix(mat)\n",
    "row_fact = np.random.normal(size=(nrows, k))\n",
    "col_fact = np.random.normal(size=(ncols, k))\n",
    "fit_spfact(sp_mat, row_fact, col_fact, reg_param=1e-1, niter=200, nthreads=8) #adjust number of threads for your setup\n",
    "b = Binarizer(threshold=0.6)\n",
    "approx = b.fit_transform(row_fact) @ b.fit_transform(col_fact.T)\n",
    "\n",
    "print(np.square(np.linalg.norm(mat - approx)))\n",
    "\n",
    "plt.imshow(approx)\n",
    "print(approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095501ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from binmf import fit_spfact\n",
    "\n",
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_binmf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(\"k: %s\" % k)\n",
    "        for i in range(n_runs):\n",
    "            print(i)\n",
    "            j=0\n",
    "            avg_error_l1 = []\n",
    "            avg_error_l2 = []\n",
    "            avg_error_l5 = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                if j % 50 == 0:\n",
    "                    print(j) \n",
    "                j+=1\n",
    "                \n",
    "                t0 = perf_counter()\n",
    "                nrows, ncols = mat.shape\n",
    "\n",
    "                sp_mat = csr_matrix(mat)\n",
    "                b = Binarizer(threshold=0.6)\n",
    "                row_fact = np.random.normal(size=(nrows, k))\n",
    "                col_fact = np.random.normal(size=(ncols, k))\n",
    "                fit_spfact(sp_mat, row_fact, col_fact, reg_param=1e-1, niter=200, nthreads=8) #adjust number of threads for your setup\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "\n",
    "                bmf_fitted = b.fit_transform(row_fact) @ b.fit_transform(col_fact.T)\n",
    "                \n",
    "                avg_error_l2.append(np.square(np.linalg.norm(bmf_fitted - mat)))\n",
    "                avg_error_l1.append(np.sum(np.abs(bmf_fitted - mat)))\n",
    "                avg_error_l5.append(np.power(np.linalg.norm((bmf_fitted-mat).flatten(), ord=5) , 5))\n",
    "            \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'binmf l1', 'k': k, 'Error': np.average(avg_error_l1), 'Time': np.average(avg_time)})\n",
    "            real_df_binmf = pd.concat([real_df_binmf, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'binmf l2', 'k': k, 'Error': np.average(avg_error_l2), 'Time': np.average(avg_time)})\n",
    "            real_df_binmf = pd.concat([real_df_binmf, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'binmf l5', 'k': k, 'Error': np.average(avg_error_l5), 'Time': np.average(avg_time)})\n",
    "            real_df_binmf = pd.concat([real_df_binmf, row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b06705",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_binmf.to_pickle('./real_df_binmf_int.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b13e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = orl[0]\n",
    "k = 15\n",
    "\n",
    "mask = np.random.rand(mat.shape[0], mat.shape[1]) < 0.99\n",
    "comp = MatrixCompletion(mat, k, mask = mask, min_sum = True, verbose = False, max_iter = 100)\n",
    "comp.run()\n",
    "\n",
    "print(comp.Y)\n",
    "print(comp.X)\n",
    "plt.imshow(comp.X @ comp.Y.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca06b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_mpf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print('k: %s' % k)\n",
    "        for i in range(n_runs):\n",
    "            print(i)\n",
    "            avg_error_l1 = []\n",
    "            avg_error_l2 = []\n",
    "            avg_error_l5 = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()             \n",
    "                \n",
    "                mask = np.random.rand(mat.shape[0], mat.shape[1]) < 0.99\n",
    "                comp = MatrixCompletion(mat, k, mask = mask, min_sum = True, verbose = False, max_iter = 100)\n",
    "                comp.run()\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                bmf_fitted = comp.X @ comp.Y.T\n",
    "                \n",
    "                #avg_error.append(np.linalg.norm(Binarizer(threshold=0.5).fit_transform(comp.Z) - mat))\n",
    "                avg_error_l2.append(np.square(np.linalg.norm(bmf_fitted - mat)))\n",
    "                avg_error_l1.append(np.sum(np.abs(bmf_fitted - mat)))\n",
    "                avg_error_l5.append(np.power(np.linalg.norm((bmf_fitted-mat).flatten(), ord=5) , 5))\n",
    "\n",
    "           \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'mpbmf l1', 'k': k, 'Error': np.average(avg_error_l1), 'Time': np.average(avg_time)})\n",
    "            real_df_mpf = pd.concat([real_df_mpf, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'mpbmf l2', 'k': k, 'Error': np.average(avg_error_l2), 'Time': np.average(avg_time)})\n",
    "            real_df_mpf = pd.concat([real_df_mpf, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'mpbmf l5', 'k': k, 'Error': np.average(avg_error_l5), 'Time': np.average(avg_time)})\n",
    "            real_df_mpf = pd.concat([real_df_mpf, row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f350be",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_mpf.to_pickle('./real_df_mpf_int.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b835562b",
   "metadata": {},
   "source": [
    "# Int with Synthetic\n",
    "\n",
    "In this section we perform experiments where the matrix multiplication is performed in the standard way over the reals, rather than the boolean semiring or GF(2). This is especially bad for existing heuristics, as they internally are usually tuned to the Boolean semiring. The NIMFA and binmf heuristics do not have a guarantee on producing 0-1 valued low rank factors U and V, so we apply a best-effort thresholding, to produce these factors.\n",
    "\n",
    "*We note again here, that the existing heuristics are not tuned to this setting and therefore we do not expect them to perform well*. The heuristic of Kumar et. al and our extension that guesses a good U V pair based on centers obtained from the coreset does "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d9af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "# datasets are generally three dimensional\n",
    "datasets = [synthetic_full, synthetic_low_rank_5, synthetic_low_rank_10, synthetic_low_rank_15, \n",
    "           synthetic_noisy_10_001, synthetic_noisy_10_0001,\n",
    "            synthetic_full_, synthetic_low_rank_5_, synthetic_low_rank_10_, synthetic_low_rank_15_, \n",
    "           synthetic_noisy_10_001_, synthetic_noisy_10_0001_]\n",
    "dataset_names = [\"full\", \"lr5\", \"lr10\", \"lr15\", \"noisy10-001\", \"noisy10-0001\", \n",
    "                 \"full0.1\", \"lr5-0.1\", \"lr10-0.1\", \"lr15-0.1\", \"noisy10-001-0.1\", \"noisy10-0001-0.1\", \n",
    "                ]\n",
    "\n",
    "real_df_bmf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "            \n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        for i in range(n_runs):\n",
    "            bmf = BMFKMeans(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf', 'k': k, 'Error': res[3], 'Time': (res[2] / 1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            bmf = BMFKMeans_plus_int_1(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf+ (int, l1)\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf+ (int, l1)', 'k': k, 'Error': res[3], 'Time': (res[2]/1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            bmf = BMFKMeans_plus_int_2(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf+ (int, l2)\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf+ (int, l2)', 'k': k, 'Error': res[3], 'Time': (res[2]/1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            bmf = BMFKMeans_plus_int_5(k)\n",
    "            res = bench_bmf(bmf=bmf, name=\"bmf+ (int, l5)\", k=k, data=data)\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'bmf+ (int, l5)', 'k': k, 'Error': res[3], 'Time': (res[2]/1000)})\n",
    "            real_df_bmf = pd.concat([real_df_bmf, row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faee44db",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_bmf.to_pickle('./synth_df_bmf_int.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5168cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nimfa\n",
    "\n",
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_nimfa = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        for i in range(n_runs):\n",
    "            avg_error_l1 = []\n",
    "            avg_error_l2 = []\n",
    "            avg_error_l5 = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()\n",
    "                bmf = nimfa.Bmf(mat, seed=\"nndsvd\", rank=k, max_iter=10000, lambda_w=1.1, lambda_h=1.1)\n",
    "                bmf_fit = bmf()\n",
    "                b = Binarizer(threshold=0.3)               \n",
    "                l = b.fit_transform(np.asarray(bmf.basis()))\n",
    "                r = b.fit_transform(np.asarray(bmf.coef()))\n",
    "                bmf_fitted = l @ r\n",
    "\n",
    "                #bmf_fitted = bmf.fitted()\n",
    "                #bmf_fitted = Binarizer(threshold=0.5).fit_transform(np.array(bmf_fitted))\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                avg_error_l2.append(np.square(np.linalg.norm(bmf_fitted - mat)))\n",
    "                avg_error_l1.append(np.sum(np.abs(bmf_fitted - mat)))\n",
    "                avg_error_l5.append(np.power(np.linalg.norm((bmf_fitted-mat).flatten(), ord=5) , 5))\n",
    "                #print(bmf_fitted)\n",
    "                #print(mat)\n",
    "                #print(avg_error[-1])\n",
    "                \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'nimfa l1', 'k': k, 'Error': np.average(avg_error_l1), 'Time': np.average(avg_time)})\n",
    "            real_df_nimfa = pd.concat([real_df_nimfa, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'nimfa l2', 'k': k, 'Error': np.average(avg_error_l2), 'Time': np.average(avg_time)})\n",
    "            real_df_nimfa = pd.concat([real_df_nimfa, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'nimfa l5', 'k': k, 'Error': np.average(avg_error_l5), 'Time': np.average(avg_time)})\n",
    "            real_df_nimfa = pd.concat([real_df_nimfa, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae51e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_nimfa.to_pickle('./synth_df_nimfa_int.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8fb3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from binmf import fit_spfact\n",
    "\n",
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_binmf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print(\"k: %s\" % k)\n",
    "        for i in range(n_runs):\n",
    "            print(i)\n",
    "            avg_error_l1 = []\n",
    "            avg_error_l2 = []\n",
    "            avg_error_l5 = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()\n",
    "                nrows, ncols = mat.shape\n",
    "\n",
    "                sp_mat = csr_matrix(mat)\n",
    "                b = Binarizer(threshold=0.6)\n",
    "                row_fact = np.random.normal(size=(nrows, k))\n",
    "                col_fact = np.random.normal(size=(ncols, k))\n",
    "                fit_spfact(sp_mat, row_fact, col_fact, reg_param=1e-1, niter=200, nthreads=8) #adjust number of threads for your setup\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "\n",
    "                bmf_fitted = b.fit_transform(row_fact) @ b.fit_transform(col_fact.T)\n",
    "                \n",
    "                avg_error_l2.append(np.square(np.linalg.norm(bmf_fitted - mat)))\n",
    "                avg_error_l1.append(np.sum(np.abs(bmf_fitted - mat)))\n",
    "                avg_error_l5.append(np.power(np.linalg.norm((bmf_fitted-mat).flatten(), ord=5) , 5))\n",
    "            \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'binmf l1', 'k': k, 'Error': np.average(avg_error_l1), 'Time': np.average(avg_time)})\n",
    "            real_df_binmf = pd.concat([real_df_binmf, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'binmf l2', 'k': k, 'Error': np.average(avg_error_l2), 'Time': np.average(avg_time)})\n",
    "            real_df_binmf = pd.concat([real_df_binmf, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'binmf l5', 'k': k, 'Error': np.average(avg_error_l5), 'Time': np.average(avg_time)})\n",
    "            real_df_binmf = pd.concat([real_df_binmf, row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_binmf.to_pickle('./synth_df_binmf_int.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f767616",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [2, 3, 5, 10, 15]\n",
    "n_runs = 10\n",
    "\n",
    "real_df_mpf = pd.DataFrame.from_dict({\n",
    "    'Dataset': [],\n",
    "    'Algorithm': [],\n",
    "    'k': [],\n",
    "    'Error': [],\n",
    "    'Time': []\n",
    "})\n",
    "\n",
    "for (name, data) in zip(dataset_names, datasets):\n",
    "    print(name)\n",
    "    for k in ks:\n",
    "        print('k: %s' % k)\n",
    "        for i in range(n_runs):\n",
    "            print(i)\n",
    "            avg_error_l1 = []\n",
    "            avg_error_l2 = []\n",
    "            avg_error_l5 = []\n",
    "            avg_time = []\n",
    "            for mat in data:\n",
    "                t0 = perf_counter()             \n",
    "                \n",
    "                mask = np.random.rand(mat.shape[0], mat.shape[1]) < 0.99\n",
    "                comp = MatrixCompletion(mat, k, mask = mask, min_sum = True, verbose = False, max_iter = 100)\n",
    "                comp.run()\n",
    "                avg_time.append(perf_counter() - t0)\n",
    "                bmf_fitted = comp.X @ comp.Y.T\n",
    "                \n",
    "                #avg_error.append(np.linalg.norm(Binarizer(threshold=0.5).fit_transform(comp.Z) - mat))\n",
    "                avg_error_l2.append(np.square(np.linalg.norm(bmf_fitted - mat)))\n",
    "                avg_error_l1.append(np.sum(np.abs(bmf_fitted - mat)))\n",
    "                avg_error_l5.append(np.power(np.linalg.norm((bmf_fitted-mat).flatten(), ord=5) , 5))\n",
    "\n",
    "           \n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'mpbmf l1', 'k': k, 'Error': np.average(avg_error_l1), 'Time': np.average(avg_time)})\n",
    "            real_df_mpf = pd.concat([real_df_mpf, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'mpbmf l2', 'k': k, 'Error': np.average(avg_error_l2), 'Time': np.average(avg_time)})\n",
    "            real_df_mpf = pd.concat([real_df_mpf, row.to_frame().T], ignore_index=True)\n",
    "            row = pd.Series(\n",
    "                {'Dataset': name, 'Algorithm': 'mpbmf l5', 'k': k, 'Error': np.average(avg_error_l5), 'Time': np.average(avg_time)})\n",
    "            real_df_mpf = pd.concat([real_df_mpf, row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e41dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df_mpf.to_pickle('./synth_df_mpf_int.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d49e3",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "We first analyze the outcomes of the \"steelmanned\" heuristic comparison, where each heuristic is used as detailed by the implementers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "1deba27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load real data\n",
    "real_df_bmf = pd.read_pickle('./real_df_bmf.pkl')\n",
    "real_df_binmf = pd.read_pickle('./real_df_binmf.pkl')\n",
    "real_df_mpf = pd.read_pickle('./real_df_mpf.pkl')\n",
    "real_df_nimfa = pd.read_pickle('./real_df_nimfa.pkl')\n",
    "\n",
    "real_df = pd.concat([real_df_bmf, real_df_mpf, real_df_nimfa, real_df_binmf], ignore_index=True)\n",
    "\n",
    "# load synthetic data\n",
    "synth_df_bmf = pd.read_pickle('./synth_df_bmf.pkl')\n",
    "synth_df_binmf = pd.read_pickle('./synth_df_binmf.pkl')\n",
    "synth_df_mpf = pd.read_pickle('./synth_mpf.pkl')\n",
    "synth_df_nimfa = pd.read_pickle('./synth_df_nimfa.pkl')\n",
    "\n",
    "synth_df = pd.concat([synth_df_bmf, synth_df_binmf, synth_df_mpf, synth_df_nimfa])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2d1716",
   "metadata": {},
   "source": [
    "## Results for Real Data\n",
    "\n",
    "Here we show the Frobenius norm error and Runtime (in seconds) for each algorithm on real datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "74b4f476",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Error</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>binmf</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+</th>\n",
       "      <th>mpbmf</th>\n",
       "      <th>nimfa</th>\n",
       "      <th>binmf</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+</th>\n",
       "      <th>mpbmf</th>\n",
       "      <th>nimfa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">congress</th>\n",
       "      <th>2</th>\n",
       "      <td>36.458482</td>\n",
       "      <td>40.037482</td>\n",
       "      <td>38.820098</td>\n",
       "      <td>38.809791</td>\n",
       "      <td>36.359318</td>\n",
       "      <td>0.090348</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.280718</td>\n",
       "      <td>0.006909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.512418</td>\n",
       "      <td>38.363051</td>\n",
       "      <td>36.624927</td>\n",
       "      <td>35.889981</td>\n",
       "      <td>32.710854</td>\n",
       "      <td>0.102086</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>0.311166</td>\n",
       "      <td>0.013638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24.286930</td>\n",
       "      <td>35.696393</td>\n",
       "      <td>32.712793</td>\n",
       "      <td>31.141360</td>\n",
       "      <td>27.748874</td>\n",
       "      <td>0.119905</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.332855</td>\n",
       "      <td>0.016217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.899723</td>\n",
       "      <td>32.730459</td>\n",
       "      <td>23.919929</td>\n",
       "      <td>22.471524</td>\n",
       "      <td>18.439089</td>\n",
       "      <td>0.102877</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.016910</td>\n",
       "      <td>0.407083</td>\n",
       "      <td>0.022573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.929173</td>\n",
       "      <td>14.807827</td>\n",
       "      <td>15.469016</td>\n",
       "      <td>9.591663</td>\n",
       "      <td>0.089422</td>\n",
       "      <td>0.007394</td>\n",
       "      <td>0.246655</td>\n",
       "      <td>0.480527</td>\n",
       "      <td>0.027471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">orl</th>\n",
       "      <th>2</th>\n",
       "      <td>33.713419</td>\n",
       "      <td>39.376678</td>\n",
       "      <td>37.785530</td>\n",
       "      <td>35.857652</td>\n",
       "      <td>33.521305</td>\n",
       "      <td>0.090572</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.203744</td>\n",
       "      <td>0.011625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.626366</td>\n",
       "      <td>35.716104</td>\n",
       "      <td>34.569188</td>\n",
       "      <td>32.237612</td>\n",
       "      <td>29.711777</td>\n",
       "      <td>0.088825</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.241613</td>\n",
       "      <td>0.013129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.105650</td>\n",
       "      <td>31.672486</td>\n",
       "      <td>30.712163</td>\n",
       "      <td>27.680846</td>\n",
       "      <td>25.577315</td>\n",
       "      <td>0.084834</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.005817</td>\n",
       "      <td>0.289372</td>\n",
       "      <td>0.015375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.099023</td>\n",
       "      <td>26.449686</td>\n",
       "      <td>25.714423</td>\n",
       "      <td>21.628539</td>\n",
       "      <td>21.382890</td>\n",
       "      <td>0.081724</td>\n",
       "      <td>0.004258</td>\n",
       "      <td>0.022310</td>\n",
       "      <td>0.415707</td>\n",
       "      <td>0.019140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.205162</td>\n",
       "      <td>23.414144</td>\n",
       "      <td>22.794089</td>\n",
       "      <td>17.845095</td>\n",
       "      <td>19.691523</td>\n",
       "      <td>0.081194</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>0.318042</td>\n",
       "      <td>0.575532</td>\n",
       "      <td>0.022177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">thyroid</th>\n",
       "      <th>2</th>\n",
       "      <td>95.822162</td>\n",
       "      <td>106.600675</td>\n",
       "      <td>98.622961</td>\n",
       "      <td>90.474314</td>\n",
       "      <td>91.580566</td>\n",
       "      <td>0.376068</td>\n",
       "      <td>0.012622</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>7.063550</td>\n",
       "      <td>0.044308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.365356</td>\n",
       "      <td>94.480695</td>\n",
       "      <td>90.472925</td>\n",
       "      <td>75.475512</td>\n",
       "      <td>73.925638</td>\n",
       "      <td>0.312943</td>\n",
       "      <td>0.014406</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>7.822042</td>\n",
       "      <td>0.092907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.023772</td>\n",
       "      <td>82.704286</td>\n",
       "      <td>80.395914</td>\n",
       "      <td>78.513723</td>\n",
       "      <td>61.846584</td>\n",
       "      <td>0.398811</td>\n",
       "      <td>0.031802</td>\n",
       "      <td>0.025212</td>\n",
       "      <td>8.860249</td>\n",
       "      <td>0.132118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23.591007</td>\n",
       "      <td>66.032060</td>\n",
       "      <td>55.419848</td>\n",
       "      <td>54.045930</td>\n",
       "      <td>52.933921</td>\n",
       "      <td>0.346888</td>\n",
       "      <td>0.028935</td>\n",
       "      <td>0.059646</td>\n",
       "      <td>12.686316</td>\n",
       "      <td>0.241407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.571106</td>\n",
       "      <td>57.552221</td>\n",
       "      <td>38.903848</td>\n",
       "      <td>39.232925</td>\n",
       "      <td>46.711883</td>\n",
       "      <td>0.348516</td>\n",
       "      <td>0.026658</td>\n",
       "      <td>0.313364</td>\n",
       "      <td>16.237675</td>\n",
       "      <td>0.432735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Error                                                   Time  \\\n",
       "Algorithm        binmf         bmf       bmf+      mpbmf      nimfa     binmf   \n",
       "Dataset  k                                                                      \n",
       "congress 2   36.458482   40.037482  38.820098  38.809791  36.359318  0.090348   \n",
       "         3   32.512418   38.363051  36.624927  35.889981  32.710854  0.102086   \n",
       "         5   24.286930   35.696393  32.712793  31.141360  27.748874  0.119905   \n",
       "         10   5.899723   32.730459  23.919929  22.471524  18.439089  0.102877   \n",
       "         15   0.000000   30.929173  14.807827  15.469016   9.591663  0.089422   \n",
       "orl      2   33.713419   39.376678  37.785530  35.857652  33.521305  0.090572   \n",
       "         3   28.626366   35.716104  34.569188  32.237612  29.711777  0.088825   \n",
       "         5   22.105650   31.672486  30.712163  27.680846  25.577315  0.084834   \n",
       "         10  12.099023   26.449686  25.714423  21.628539  21.382890  0.081724   \n",
       "         15   5.205162   23.414144  22.794089  17.845095  19.691523  0.081194   \n",
       "thyroid  2   95.822162  106.600675  98.622961  90.474314  91.580566  0.376068   \n",
       "         3   84.365356   94.480695  90.472925  75.475512  73.925638  0.312943   \n",
       "         5   50.023772   82.704286  80.395914  78.513723  61.846584  0.398811   \n",
       "         10  23.591007   66.032060  55.419848  54.045930  52.933921  0.346888   \n",
       "         15   3.571106   57.552221  38.903848  39.232925  46.711883  0.348516   \n",
       "\n",
       "                                                      \n",
       "Algorithm         bmf      bmf+      mpbmf     nimfa  \n",
       "Dataset  k                                            \n",
       "congress 2   0.001975  0.003310   0.280718  0.006909  \n",
       "         3   0.002328  0.004103   0.311166  0.013638  \n",
       "         5   0.004624  0.005205   0.332855  0.016217  \n",
       "         10  0.003197  0.016910   0.407083  0.022573  \n",
       "         15  0.007394  0.246655   0.480527  0.027471  \n",
       "orl      2   0.001990  0.002936   0.203744  0.011625  \n",
       "         3   0.002908  0.004662   0.241613  0.013129  \n",
       "         5   0.003809  0.005817   0.289372  0.015375  \n",
       "         10  0.004258  0.022310   0.415707  0.019140  \n",
       "         15  0.006068  0.318042   0.575532  0.022177  \n",
       "thyroid  2   0.012622  0.014159   7.063550  0.044308  \n",
       "         3   0.014406  0.018722   7.822042  0.092907  \n",
       "         5   0.031802  0.025212   8.860249  0.132118  \n",
       "         10  0.028935  0.059646  12.686316  0.241407  \n",
       "         15  0.026658  0.313364  16.237675  0.432735  "
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = real_df.groupby(['Dataset', 'k', 'Algorithm']).mean()\n",
    "grouped_df.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b009d7",
   "metadata": {},
   "source": [
    "## Results for Synthetic Data\n",
    "\n",
    "Here we show the Frobenius norm error and Runtime (in seconds) for each algorithm on synthetic datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "ab2fec5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Error</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>binmf</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+</th>\n",
       "      <th>mpbmf</th>\n",
       "      <th>nimfa</th>\n",
       "      <th>binmf</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+</th>\n",
       "      <th>mpbmf</th>\n",
       "      <th>nimfa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">full</th>\n",
       "      <th>2</th>\n",
       "      <td>73.344298</td>\n",
       "      <td>75.750915</td>\n",
       "      <td>72.333028</td>\n",
       "      <td>71.256986</td>\n",
       "      <td>71.321495</td>\n",
       "      <td>0.177331</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>0.008610</td>\n",
       "      <td>0.280658</td>\n",
       "      <td>0.011552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.831318</td>\n",
       "      <td>74.280728</td>\n",
       "      <td>69.928525</td>\n",
       "      <td>69.385181</td>\n",
       "      <td>68.674021</td>\n",
       "      <td>0.140231</td>\n",
       "      <td>0.014863</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.309760</td>\n",
       "      <td>0.011651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69.252822</td>\n",
       "      <td>72.157767</td>\n",
       "      <td>65.764912</td>\n",
       "      <td>66.563674</td>\n",
       "      <td>64.856944</td>\n",
       "      <td>0.139583</td>\n",
       "      <td>0.010872</td>\n",
       "      <td>0.011492</td>\n",
       "      <td>0.347684</td>\n",
       "      <td>0.013350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62.785281</td>\n",
       "      <td>68.657704</td>\n",
       "      <td>57.353965</td>\n",
       "      <td>61.535130</td>\n",
       "      <td>58.478444</td>\n",
       "      <td>0.203146</td>\n",
       "      <td>0.015410</td>\n",
       "      <td>0.053407</td>\n",
       "      <td>0.486640</td>\n",
       "      <td>0.017212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>56.163514</td>\n",
       "      <td>66.404657</td>\n",
       "      <td>50.373358</td>\n",
       "      <td>57.918306</td>\n",
       "      <td>53.723584</td>\n",
       "      <td>0.232967</td>\n",
       "      <td>0.016217</td>\n",
       "      <td>0.272142</td>\n",
       "      <td>0.667299</td>\n",
       "      <td>0.021675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">full0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>43.009379</td>\n",
       "      <td>36.000430</td>\n",
       "      <td>35.010907</td>\n",
       "      <td>34.946703</td>\n",
       "      <td>35.164001</td>\n",
       "      <td>0.098257</td>\n",
       "      <td>0.010760</td>\n",
       "      <td>0.011347</td>\n",
       "      <td>0.277318</td>\n",
       "      <td>0.009876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.409356</td>\n",
       "      <td>35.899464</td>\n",
       "      <td>34.884510</td>\n",
       "      <td>34.948634</td>\n",
       "      <td>34.976351</td>\n",
       "      <td>0.094788</td>\n",
       "      <td>0.007534</td>\n",
       "      <td>0.013918</td>\n",
       "      <td>0.302109</td>\n",
       "      <td>0.010645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39.331131</td>\n",
       "      <td>35.637114</td>\n",
       "      <td>34.608827</td>\n",
       "      <td>35.530870</td>\n",
       "      <td>34.223749</td>\n",
       "      <td>0.088861</td>\n",
       "      <td>0.012673</td>\n",
       "      <td>0.018454</td>\n",
       "      <td>0.336946</td>\n",
       "      <td>0.012633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>34.073479</td>\n",
       "      <td>35.023489</td>\n",
       "      <td>33.868040</td>\n",
       "      <td>35.812739</td>\n",
       "      <td>31.749037</td>\n",
       "      <td>0.094921</td>\n",
       "      <td>0.017044</td>\n",
       "      <td>0.064458</td>\n",
       "      <td>0.459616</td>\n",
       "      <td>0.015913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29.300266</td>\n",
       "      <td>34.317619</td>\n",
       "      <td>33.025709</td>\n",
       "      <td>38.451906</td>\n",
       "      <td>28.995963</td>\n",
       "      <td>0.102995</td>\n",
       "      <td>0.020859</td>\n",
       "      <td>0.269500</td>\n",
       "      <td>0.628404</td>\n",
       "      <td>0.019576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr10</th>\n",
       "      <th>2</th>\n",
       "      <td>73.169735</td>\n",
       "      <td>75.817642</td>\n",
       "      <td>72.161664</td>\n",
       "      <td>71.090447</td>\n",
       "      <td>71.680565</td>\n",
       "      <td>0.171184</td>\n",
       "      <td>0.013379</td>\n",
       "      <td>0.015495</td>\n",
       "      <td>0.281237</td>\n",
       "      <td>0.011453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.561317</td>\n",
       "      <td>74.320028</td>\n",
       "      <td>69.554721</td>\n",
       "      <td>69.135761</td>\n",
       "      <td>68.961825</td>\n",
       "      <td>0.174765</td>\n",
       "      <td>0.015792</td>\n",
       "      <td>0.020046</td>\n",
       "      <td>0.308018</td>\n",
       "      <td>0.011711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68.815887</td>\n",
       "      <td>72.048301</td>\n",
       "      <td>64.746181</td>\n",
       "      <td>66.119482</td>\n",
       "      <td>64.841498</td>\n",
       "      <td>0.223248</td>\n",
       "      <td>0.020858</td>\n",
       "      <td>0.019687</td>\n",
       "      <td>0.345483</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>61.768702</td>\n",
       "      <td>68.193327</td>\n",
       "      <td>28.368406</td>\n",
       "      <td>60.222202</td>\n",
       "      <td>57.948659</td>\n",
       "      <td>0.289431</td>\n",
       "      <td>0.016190</td>\n",
       "      <td>0.051420</td>\n",
       "      <td>0.477845</td>\n",
       "      <td>0.017268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55.343812</td>\n",
       "      <td>65.645340</td>\n",
       "      <td>0.799573</td>\n",
       "      <td>56.017076</td>\n",
       "      <td>52.942195</td>\n",
       "      <td>0.264179</td>\n",
       "      <td>0.019311</td>\n",
       "      <td>0.245181</td>\n",
       "      <td>0.659640</td>\n",
       "      <td>0.021258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr10-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>32.765260</td>\n",
       "      <td>30.820627</td>\n",
       "      <td>30.521675</td>\n",
       "      <td>27.625313</td>\n",
       "      <td>28.510833</td>\n",
       "      <td>0.073599</td>\n",
       "      <td>0.010030</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>0.213402</td>\n",
       "      <td>0.005664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.609959</td>\n",
       "      <td>28.506134</td>\n",
       "      <td>28.131885</td>\n",
       "      <td>25.238997</td>\n",
       "      <td>25.479182</td>\n",
       "      <td>0.074419</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>0.013308</td>\n",
       "      <td>0.248525</td>\n",
       "      <td>0.011488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.199439</td>\n",
       "      <td>24.734379</td>\n",
       "      <td>23.198115</td>\n",
       "      <td>20.365842</td>\n",
       "      <td>19.927415</td>\n",
       "      <td>0.068856</td>\n",
       "      <td>0.013058</td>\n",
       "      <td>0.018687</td>\n",
       "      <td>0.291977</td>\n",
       "      <td>0.013395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.605244</td>\n",
       "      <td>18.313160</td>\n",
       "      <td>10.201085</td>\n",
       "      <td>7.566958</td>\n",
       "      <td>8.757867</td>\n",
       "      <td>0.072697</td>\n",
       "      <td>0.016362</td>\n",
       "      <td>0.076154</td>\n",
       "      <td>0.434597</td>\n",
       "      <td>0.016920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.196752</td>\n",
       "      <td>15.221658</td>\n",
       "      <td>2.504529</td>\n",
       "      <td>4.691869</td>\n",
       "      <td>5.410569</td>\n",
       "      <td>0.065885</td>\n",
       "      <td>0.014753</td>\n",
       "      <td>0.261326</td>\n",
       "      <td>0.638779</td>\n",
       "      <td>0.022075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr15</th>\n",
       "      <th>2</th>\n",
       "      <td>73.461105</td>\n",
       "      <td>75.708405</td>\n",
       "      <td>72.273592</td>\n",
       "      <td>71.187829</td>\n",
       "      <td>71.268859</td>\n",
       "      <td>0.279565</td>\n",
       "      <td>0.014452</td>\n",
       "      <td>0.018608</td>\n",
       "      <td>0.277588</td>\n",
       "      <td>0.011339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.885052</td>\n",
       "      <td>74.246647</td>\n",
       "      <td>69.898775</td>\n",
       "      <td>69.338224</td>\n",
       "      <td>68.712767</td>\n",
       "      <td>0.232276</td>\n",
       "      <td>0.012746</td>\n",
       "      <td>0.011133</td>\n",
       "      <td>0.306455</td>\n",
       "      <td>0.011698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69.421449</td>\n",
       "      <td>72.067391</td>\n",
       "      <td>65.710864</td>\n",
       "      <td>66.565762</td>\n",
       "      <td>64.809208</td>\n",
       "      <td>0.225033</td>\n",
       "      <td>0.014997</td>\n",
       "      <td>0.019006</td>\n",
       "      <td>0.339678</td>\n",
       "      <td>0.013028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62.643136</td>\n",
       "      <td>68.609598</td>\n",
       "      <td>56.540031</td>\n",
       "      <td>61.474079</td>\n",
       "      <td>58.391770</td>\n",
       "      <td>0.140653</td>\n",
       "      <td>0.018659</td>\n",
       "      <td>0.051422</td>\n",
       "      <td>0.478283</td>\n",
       "      <td>0.017195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>56.199033</td>\n",
       "      <td>66.368334</td>\n",
       "      <td>29.212435</td>\n",
       "      <td>57.732194</td>\n",
       "      <td>53.589677</td>\n",
       "      <td>0.144722</td>\n",
       "      <td>0.013021</td>\n",
       "      <td>0.239873</td>\n",
       "      <td>0.652809</td>\n",
       "      <td>0.021137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr15-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>39.467855</td>\n",
       "      <td>38.697035</td>\n",
       "      <td>38.229198</td>\n",
       "      <td>35.638083</td>\n",
       "      <td>36.530253</td>\n",
       "      <td>0.090266</td>\n",
       "      <td>0.012055</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>0.242158</td>\n",
       "      <td>0.009670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.376478</td>\n",
       "      <td>37.087185</td>\n",
       "      <td>36.190913</td>\n",
       "      <td>33.650332</td>\n",
       "      <td>34.211802</td>\n",
       "      <td>0.094768</td>\n",
       "      <td>0.009987</td>\n",
       "      <td>0.013022</td>\n",
       "      <td>0.274059</td>\n",
       "      <td>0.012790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.334947</td>\n",
       "      <td>33.716537</td>\n",
       "      <td>32.177006</td>\n",
       "      <td>29.832138</td>\n",
       "      <td>29.483310</td>\n",
       "      <td>0.090495</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>0.313237</td>\n",
       "      <td>0.014645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.518119</td>\n",
       "      <td>28.122054</td>\n",
       "      <td>22.340419</td>\n",
       "      <td>20.330422</td>\n",
       "      <td>19.781748</td>\n",
       "      <td>0.069222</td>\n",
       "      <td>0.020178</td>\n",
       "      <td>0.056258</td>\n",
       "      <td>0.457335</td>\n",
       "      <td>0.017878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.752210</td>\n",
       "      <td>25.274851</td>\n",
       "      <td>14.232960</td>\n",
       "      <td>11.597783</td>\n",
       "      <td>13.381887</td>\n",
       "      <td>0.085105</td>\n",
       "      <td>0.021152</td>\n",
       "      <td>0.247893</td>\n",
       "      <td>0.643755</td>\n",
       "      <td>0.021234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr5</th>\n",
       "      <th>2</th>\n",
       "      <td>66.111364</td>\n",
       "      <td>72.472089</td>\n",
       "      <td>67.098743</td>\n",
       "      <td>66.013343</td>\n",
       "      <td>67.823084</td>\n",
       "      <td>0.195308</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.007883</td>\n",
       "      <td>0.274857</td>\n",
       "      <td>0.011892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.581214</td>\n",
       "      <td>69.161153</td>\n",
       "      <td>60.017709</td>\n",
       "      <td>62.280223</td>\n",
       "      <td>64.038011</td>\n",
       "      <td>0.168244</td>\n",
       "      <td>0.012764</td>\n",
       "      <td>0.012004</td>\n",
       "      <td>0.301523</td>\n",
       "      <td>0.013537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53.020314</td>\n",
       "      <td>63.956862</td>\n",
       "      <td>26.933413</td>\n",
       "      <td>55.245308</td>\n",
       "      <td>56.724761</td>\n",
       "      <td>0.152431</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.339839</td>\n",
       "      <td>0.015420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>34.338310</td>\n",
       "      <td>52.869364</td>\n",
       "      <td>0.693289</td>\n",
       "      <td>41.015698</td>\n",
       "      <td>42.546584</td>\n",
       "      <td>0.136435</td>\n",
       "      <td>0.014717</td>\n",
       "      <td>0.072737</td>\n",
       "      <td>0.472532</td>\n",
       "      <td>0.019469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19.072401</td>\n",
       "      <td>43.320731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.752151</td>\n",
       "      <td>31.133041</td>\n",
       "      <td>0.127316</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>0.658014</td>\n",
       "      <td>0.023838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr5-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>20.671033</td>\n",
       "      <td>20.506771</td>\n",
       "      <td>20.369701</td>\n",
       "      <td>16.458187</td>\n",
       "      <td>15.809840</td>\n",
       "      <td>0.072242</td>\n",
       "      <td>0.009361</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>0.185606</td>\n",
       "      <td>0.004770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.877655</td>\n",
       "      <td>16.982355</td>\n",
       "      <td>16.581775</td>\n",
       "      <td>13.068700</td>\n",
       "      <td>11.961674</td>\n",
       "      <td>0.064584</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.209091</td>\n",
       "      <td>0.012251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.529595</td>\n",
       "      <td>11.121688</td>\n",
       "      <td>8.431304</td>\n",
       "      <td>4.618262</td>\n",
       "      <td>5.122947</td>\n",
       "      <td>0.075819</td>\n",
       "      <td>0.007038</td>\n",
       "      <td>0.008039</td>\n",
       "      <td>0.275875</td>\n",
       "      <td>0.014790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.149004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.723558</td>\n",
       "      <td>2.347018</td>\n",
       "      <td>0.076249</td>\n",
       "      <td>0.019299</td>\n",
       "      <td>0.074956</td>\n",
       "      <td>0.460467</td>\n",
       "      <td>0.018124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.519957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383233</td>\n",
       "      <td>1.447927</td>\n",
       "      <td>0.066698</td>\n",
       "      <td>0.020186</td>\n",
       "      <td>0.297033</td>\n",
       "      <td>0.630887</td>\n",
       "      <td>0.022105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-0001</th>\n",
       "      <th>2</th>\n",
       "      <td>73.371909</td>\n",
       "      <td>75.830112</td>\n",
       "      <td>72.314566</td>\n",
       "      <td>71.212894</td>\n",
       "      <td>71.573618</td>\n",
       "      <td>0.154078</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>0.012840</td>\n",
       "      <td>0.290358</td>\n",
       "      <td>0.011308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.633068</td>\n",
       "      <td>74.332280</td>\n",
       "      <td>69.618142</td>\n",
       "      <td>69.270222</td>\n",
       "      <td>69.007748</td>\n",
       "      <td>0.156375</td>\n",
       "      <td>0.013779</td>\n",
       "      <td>0.015563</td>\n",
       "      <td>0.309285</td>\n",
       "      <td>0.011601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68.985594</td>\n",
       "      <td>72.054578</td>\n",
       "      <td>64.695129</td>\n",
       "      <td>66.218066</td>\n",
       "      <td>64.964312</td>\n",
       "      <td>0.144317</td>\n",
       "      <td>0.017590</td>\n",
       "      <td>0.023805</td>\n",
       "      <td>0.345791</td>\n",
       "      <td>0.013636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62.120176</td>\n",
       "      <td>68.194114</td>\n",
       "      <td>33.776000</td>\n",
       "      <td>60.342012</td>\n",
       "      <td>58.077464</td>\n",
       "      <td>0.141350</td>\n",
       "      <td>0.016828</td>\n",
       "      <td>0.053969</td>\n",
       "      <td>0.481068</td>\n",
       "      <td>0.017556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55.412943</td>\n",
       "      <td>65.566467</td>\n",
       "      <td>4.821331</td>\n",
       "      <td>56.164721</td>\n",
       "      <td>53.212566</td>\n",
       "      <td>0.151302</td>\n",
       "      <td>0.018362</td>\n",
       "      <td>0.247057</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.021622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-0001-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>33.303616</td>\n",
       "      <td>32.482432</td>\n",
       "      <td>32.142283</td>\n",
       "      <td>29.307728</td>\n",
       "      <td>29.963531</td>\n",
       "      <td>0.081998</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.223646</td>\n",
       "      <td>0.007564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.460065</td>\n",
       "      <td>30.046449</td>\n",
       "      <td>29.523761</td>\n",
       "      <td>26.942610</td>\n",
       "      <td>27.099691</td>\n",
       "      <td>0.077983</td>\n",
       "      <td>0.006387</td>\n",
       "      <td>0.010063</td>\n",
       "      <td>0.255379</td>\n",
       "      <td>0.011568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.396051</td>\n",
       "      <td>26.152327</td>\n",
       "      <td>24.632310</td>\n",
       "      <td>21.993109</td>\n",
       "      <td>21.320073</td>\n",
       "      <td>0.072059</td>\n",
       "      <td>0.006637</td>\n",
       "      <td>0.009697</td>\n",
       "      <td>0.291923</td>\n",
       "      <td>0.013541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.687233</td>\n",
       "      <td>19.784124</td>\n",
       "      <td>12.015600</td>\n",
       "      <td>9.252733</td>\n",
       "      <td>10.449424</td>\n",
       "      <td>0.071803</td>\n",
       "      <td>0.016357</td>\n",
       "      <td>0.067387</td>\n",
       "      <td>0.441153</td>\n",
       "      <td>0.018231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.168419</td>\n",
       "      <td>16.698047</td>\n",
       "      <td>4.913025</td>\n",
       "      <td>6.835038</td>\n",
       "      <td>7.201189</td>\n",
       "      <td>0.073849</td>\n",
       "      <td>0.013914</td>\n",
       "      <td>0.254960</td>\n",
       "      <td>0.641788</td>\n",
       "      <td>0.022376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-001</th>\n",
       "      <th>2</th>\n",
       "      <td>73.081826</td>\n",
       "      <td>75.795304</td>\n",
       "      <td>72.079907</td>\n",
       "      <td>70.980806</td>\n",
       "      <td>71.675296</td>\n",
       "      <td>0.139399</td>\n",
       "      <td>0.009654</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>0.276129</td>\n",
       "      <td>0.011360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.388300</td>\n",
       "      <td>74.325448</td>\n",
       "      <td>69.534284</td>\n",
       "      <td>69.028929</td>\n",
       "      <td>69.070412</td>\n",
       "      <td>0.139142</td>\n",
       "      <td>0.012133</td>\n",
       "      <td>0.013341</td>\n",
       "      <td>0.302450</td>\n",
       "      <td>0.011976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68.799062</td>\n",
       "      <td>72.038974</td>\n",
       "      <td>64.659731</td>\n",
       "      <td>66.010443</td>\n",
       "      <td>64.777670</td>\n",
       "      <td>0.146974</td>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.012517</td>\n",
       "      <td>0.338912</td>\n",
       "      <td>0.013408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>61.690641</td>\n",
       "      <td>68.305561</td>\n",
       "      <td>38.203974</td>\n",
       "      <td>60.187646</td>\n",
       "      <td>57.926486</td>\n",
       "      <td>0.149543</td>\n",
       "      <td>0.015029</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>0.474954</td>\n",
       "      <td>0.017228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55.107302</td>\n",
       "      <td>65.704424</td>\n",
       "      <td>16.733824</td>\n",
       "      <td>56.072349</td>\n",
       "      <td>52.782413</td>\n",
       "      <td>0.149078</td>\n",
       "      <td>0.018006</td>\n",
       "      <td>0.254025</td>\n",
       "      <td>0.672944</td>\n",
       "      <td>0.021290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-001-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>39.271263</td>\n",
       "      <td>33.260074</td>\n",
       "      <td>33.025713</td>\n",
       "      <td>30.274989</td>\n",
       "      <td>30.929522</td>\n",
       "      <td>0.071764</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.011524</td>\n",
       "      <td>0.225325</td>\n",
       "      <td>0.009243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.258272</td>\n",
       "      <td>31.264094</td>\n",
       "      <td>30.769495</td>\n",
       "      <td>28.162254</td>\n",
       "      <td>28.001292</td>\n",
       "      <td>0.086274</td>\n",
       "      <td>0.010768</td>\n",
       "      <td>0.010503</td>\n",
       "      <td>0.257513</td>\n",
       "      <td>0.012461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.124579</td>\n",
       "      <td>27.813954</td>\n",
       "      <td>26.165476</td>\n",
       "      <td>23.634714</td>\n",
       "      <td>23.350200</td>\n",
       "      <td>0.085855</td>\n",
       "      <td>0.009358</td>\n",
       "      <td>0.018329</td>\n",
       "      <td>0.292094</td>\n",
       "      <td>0.014269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.429582</td>\n",
       "      <td>22.281945</td>\n",
       "      <td>16.344174</td>\n",
       "      <td>14.032479</td>\n",
       "      <td>15.068175</td>\n",
       "      <td>0.077576</td>\n",
       "      <td>0.021040</td>\n",
       "      <td>0.058539</td>\n",
       "      <td>0.448510</td>\n",
       "      <td>0.017439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.958691</td>\n",
       "      <td>19.904945</td>\n",
       "      <td>12.452179</td>\n",
       "      <td>12.507805</td>\n",
       "      <td>12.005887</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.020513</td>\n",
       "      <td>0.260330</td>\n",
       "      <td>0.645429</td>\n",
       "      <td>0.021742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Error                                              \\\n",
       "Algorithm                binmf        bmf       bmf+      mpbmf      nimfa   \n",
       "Dataset          k                                                           \n",
       "full             2   73.344298  75.750915  72.333028  71.256986  71.321495   \n",
       "                 3   71.831318  74.280728  69.928525  69.385181  68.674021   \n",
       "                 5   69.252822  72.157767  65.764912  66.563674  64.856944   \n",
       "                 10  62.785281  68.657704  57.353965  61.535130  58.478444   \n",
       "                 15  56.163514  66.404657  50.373358  57.918306  53.723584   \n",
       "full0.1          2   43.009379  36.000430  35.010907  34.946703  35.164001   \n",
       "                 3   42.409356  35.899464  34.884510  34.948634  34.976351   \n",
       "                 5   39.331131  35.637114  34.608827  35.530870  34.223749   \n",
       "                 10  34.073479  35.023489  33.868040  35.812739  31.749037   \n",
       "                 15  29.300266  34.317619  33.025709  38.451906  28.995963   \n",
       "lr10             2   73.169735  75.817642  72.161664  71.090447  71.680565   \n",
       "                 3   71.561317  74.320028  69.554721  69.135761  68.961825   \n",
       "                 5   68.815887  72.048301  64.746181  66.119482  64.841498   \n",
       "                 10  61.768702  68.193327  28.368406  60.222202  57.948659   \n",
       "                 15  55.343812  65.645340   0.799573  56.017076  52.942195   \n",
       "lr10-0.1         2   32.765260  30.820627  30.521675  27.625313  28.510833   \n",
       "                 3   28.609959  28.506134  28.131885  25.238997  25.479182   \n",
       "                 5   17.199439  24.734379  23.198115  20.365842  19.927415   \n",
       "                 10   2.605244  18.313160  10.201085   7.566958   8.757867   \n",
       "                 15   0.196752  15.221658   2.504529   4.691869   5.410569   \n",
       "lr15             2   73.461105  75.708405  72.273592  71.187829  71.268859   \n",
       "                 3   71.885052  74.246647  69.898775  69.338224  68.712767   \n",
       "                 5   69.421449  72.067391  65.710864  66.565762  64.809208   \n",
       "                 10  62.643136  68.609598  56.540031  61.474079  58.391770   \n",
       "                 15  56.199033  66.368334  29.212435  57.732194  53.589677   \n",
       "lr15-0.1         2   39.467855  38.697035  38.229198  35.638083  36.530253   \n",
       "                 3   37.376478  37.087185  36.190913  33.650332  34.211802   \n",
       "                 5   30.334947  33.716537  32.177006  29.832138  29.483310   \n",
       "                 10  13.518119  28.122054  22.340419  20.330422  19.781748   \n",
       "                 15   3.752210  25.274851  14.232960  11.597783  13.381887   \n",
       "lr5              2   66.111364  72.472089  67.098743  66.013343  67.823084   \n",
       "                 3   61.581214  69.161153  60.017709  62.280223  64.038011   \n",
       "                 5   53.020314  63.956862  26.933413  55.245308  56.724761   \n",
       "                 10  34.338310  52.869364   0.693289  41.015698  42.546584   \n",
       "                 15  19.072401  43.320731   0.000000  32.752151  31.133041   \n",
       "lr5-0.1          2   20.671033  20.506771  20.369701  16.458187  15.809840   \n",
       "                 3   12.877655  16.982355  16.581775  13.068700  11.961674   \n",
       "                 5    2.529595  11.121688   8.431304   4.618262   5.122947   \n",
       "                 10   0.000000   5.149004   0.000000   0.723558   2.347018   \n",
       "                 15   0.000000   1.519957   0.000000   0.383233   1.447927   \n",
       "noisy10-0001     2   73.371909  75.830112  72.314566  71.212894  71.573618   \n",
       "                 3   71.633068  74.332280  69.618142  69.270222  69.007748   \n",
       "                 5   68.985594  72.054578  64.695129  66.218066  64.964312   \n",
       "                 10  62.120176  68.194114  33.776000  60.342012  58.077464   \n",
       "                 15  55.412943  65.566467   4.821331  56.164721  53.212566   \n",
       "noisy10-0001-0.1 2   33.303616  32.482432  32.142283  29.307728  29.963531   \n",
       "                 3   29.460065  30.046449  29.523761  26.942610  27.099691   \n",
       "                 5   19.396051  26.152327  24.632310  21.993109  21.320073   \n",
       "                 10   5.687233  19.784124  12.015600   9.252733  10.449424   \n",
       "                 15   2.168419  16.698047   4.913025   6.835038   7.201189   \n",
       "noisy10-001      2   73.081826  75.795304  72.079907  70.980806  71.675296   \n",
       "                 3   71.388300  74.325448  69.534284  69.028929  69.070412   \n",
       "                 5   68.799062  72.038974  64.659731  66.010443  64.777670   \n",
       "                 10  61.690641  68.305561  38.203974  60.187646  57.926486   \n",
       "                 15  55.107302  65.704424  16.733824  56.072349  52.782413   \n",
       "noisy10-001-0.1  2   39.271263  33.260074  33.025713  30.274989  30.929522   \n",
       "                 3   36.258272  31.264094  30.769495  28.162254  28.001292   \n",
       "                 5   28.124579  27.813954  26.165476  23.634714  23.350200   \n",
       "                 10  13.429582  22.281945  16.344174  14.032479  15.068175   \n",
       "                 15   5.958691  19.904945  12.452179  12.507805  12.005887   \n",
       "\n",
       "                         Time                                          \n",
       "Algorithm               binmf       bmf      bmf+     mpbmf     nimfa  \n",
       "Dataset          k                                                     \n",
       "full             2   0.177331  0.011210  0.008610  0.280658  0.011552  \n",
       "                 3   0.140231  0.014863  0.012492  0.309760  0.011651  \n",
       "                 5   0.139583  0.010872  0.011492  0.347684  0.013350  \n",
       "                 10  0.203146  0.015410  0.053407  0.486640  0.017212  \n",
       "                 15  0.232967  0.016217  0.272142  0.667299  0.021675  \n",
       "full0.1          2   0.098257  0.010760  0.011347  0.277318  0.009876  \n",
       "                 3   0.094788  0.007534  0.013918  0.302109  0.010645  \n",
       "                 5   0.088861  0.012673  0.018454  0.336946  0.012633  \n",
       "                 10  0.094921  0.017044  0.064458  0.459616  0.015913  \n",
       "                 15  0.102995  0.020859  0.269500  0.628404  0.019576  \n",
       "lr10             2   0.171184  0.013379  0.015495  0.281237  0.011453  \n",
       "                 3   0.174765  0.015792  0.020046  0.308018  0.011711  \n",
       "                 5   0.223248  0.020858  0.019687  0.345483  0.013624  \n",
       "                 10  0.289431  0.016190  0.051420  0.477845  0.017268  \n",
       "                 15  0.264179  0.019311  0.245181  0.659640  0.021258  \n",
       "lr10-0.1         2   0.073599  0.010030  0.014258  0.213402  0.005664  \n",
       "                 3   0.074419  0.011076  0.013308  0.248525  0.011488  \n",
       "                 5   0.068856  0.013058  0.018687  0.291977  0.013395  \n",
       "                 10  0.072697  0.016362  0.076154  0.434597  0.016920  \n",
       "                 15  0.065885  0.014753  0.261326  0.638779  0.022075  \n",
       "lr15             2   0.279565  0.014452  0.018608  0.277588  0.011339  \n",
       "                 3   0.232276  0.012746  0.011133  0.306455  0.011698  \n",
       "                 5   0.225033  0.014997  0.019006  0.339678  0.013028  \n",
       "                 10  0.140653  0.018659  0.051422  0.478283  0.017195  \n",
       "                 15  0.144722  0.013021  0.239873  0.652809  0.021137  \n",
       "lr15-0.1         2   0.090266  0.012055  0.010404  0.242158  0.009670  \n",
       "                 3   0.094768  0.009987  0.013022  0.274059  0.012790  \n",
       "                 5   0.090495  0.013158  0.017917  0.313237  0.014645  \n",
       "                 10  0.069222  0.020178  0.056258  0.457335  0.017878  \n",
       "                 15  0.085105  0.021152  0.247893  0.643755  0.021234  \n",
       "lr5              2   0.195308  0.004060  0.007883  0.274857  0.011892  \n",
       "                 3   0.168244  0.012764  0.012004  0.301523  0.013537  \n",
       "                 5   0.152431  0.010394  0.011867  0.339839  0.015420  \n",
       "                 10  0.136435  0.014717  0.072737  0.472532  0.019469  \n",
       "                 15  0.127316  0.018001  0.295959  0.658014  0.023838  \n",
       "lr5-0.1          2   0.072242  0.009361  0.006258  0.185606  0.004770  \n",
       "                 3   0.064584  0.005006  0.005821  0.209091  0.012251  \n",
       "                 5   0.075819  0.007038  0.008039  0.275875  0.014790  \n",
       "                 10  0.076249  0.019299  0.074956  0.460467  0.018124  \n",
       "                 15  0.066698  0.020186  0.297033  0.630887  0.022105  \n",
       "noisy10-0001     2   0.154078  0.013934  0.012840  0.290358  0.011308  \n",
       "                 3   0.156375  0.013779  0.015563  0.309285  0.011601  \n",
       "                 5   0.144317  0.017590  0.023805  0.345791  0.013636  \n",
       "                 10  0.141350  0.016828  0.053969  0.481068  0.017556  \n",
       "                 15  0.151302  0.018362  0.247057  0.661778  0.021622  \n",
       "noisy10-0001-0.1 2   0.081998  0.006312  0.009583  0.223646  0.007564  \n",
       "                 3   0.077983  0.006387  0.010063  0.255379  0.011568  \n",
       "                 5   0.072059  0.006637  0.009697  0.291923  0.013541  \n",
       "                 10  0.071803  0.016357  0.067387  0.441153  0.018231  \n",
       "                 15  0.073849  0.013914  0.254960  0.641788  0.022376  \n",
       "noisy10-001      2   0.139399  0.009654  0.011388  0.276129  0.011360  \n",
       "                 3   0.139142  0.012133  0.013341  0.302450  0.011976  \n",
       "                 5   0.146974  0.012433  0.012517  0.338912  0.013408  \n",
       "                 10  0.149543  0.015029  0.050654  0.474954  0.017228  \n",
       "                 15  0.149078  0.018006  0.254025  0.672944  0.021290  \n",
       "noisy10-001-0.1  2   0.071764  0.009901  0.011524  0.225325  0.009243  \n",
       "                 3   0.086274  0.010768  0.010503  0.257513  0.012461  \n",
       "                 5   0.085855  0.009358  0.018329  0.292094  0.014269  \n",
       "                 10  0.077576  0.021040  0.058539  0.448510  0.017439  \n",
       "                 15  0.081003  0.020513  0.260330  0.645429  0.021742  "
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = synth_df.groupby(['Dataset', 'k', 'Algorithm']).mean()\n",
    "grouped_df.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a84fc7",
   "metadata": {},
   "source": [
    "# Results for $L_p$ Norms and Standard Matrix Product\n",
    "\n",
    "We now showcase the results of $L_p^p$ loss for the approximations produced by different heuristics.\n",
    "\n",
    "Runtimes have been omitted, as they are the same as in the case of the above experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "6aaec88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load real data\n",
    "real_df_bmf = pd.read_pickle('./real_df_bmf_int.pkl')\n",
    "real_df_binmf = pd.read_pickle('./real_df_binmf_int.pkl')\n",
    "real_df_mpf = pd.read_pickle('./real_df_mpf_int.pkl')\n",
    "real_df_nimfa = pd.read_pickle('./real_df_nimfa_int.pkl')\n",
    "\n",
    "real_df = pd.concat([real_df_bmf, real_df_mpf, real_df_nimfa, real_df_binmf], ignore_index=True)\n",
    "real_l1 = real_df.loc[real_df['Algorithm'].isin(['binmf l1', 'bmf', 'bmf+ (int, l1)', 'mpbmf l1', 'nimfa l1'])]\n",
    "real_l2 = real_df.loc[real_df['Algorithm'].isin(['binmf l2', 'bmf', 'bmf+ (int, l2)', 'mpbmf l2', 'nimfa l2'])]\n",
    "real_l5 = real_df.loc[real_df['Algorithm'].isin(['binmf l5', 'bmf', 'bmf+ (int, l5)', 'mpbmf l5', 'nimfa l5'])]\n",
    "\n",
    "\n",
    "# load synthetic data\n",
    "synth_df_bmf = pd.read_pickle('./synth_df_bmf_int.pkl')\n",
    "synth_df_binmf = pd.read_pickle('./synth_df_binmf_int.pkl')\n",
    "synth_df_mpf = pd.read_pickle('./synth_df_mpf_int.pkl')\n",
    "synth_df_nimfa = pd.read_pickle('./synth_df_nimfa_int.pkl')\n",
    "\n",
    "synth_df = pd.concat([synth_df_bmf, synth_df_binmf, synth_df_mpf, synth_df_nimfa])\n",
    "\n",
    "synth_l1 = synth_df.loc[synth_df['Algorithm'].isin(['binmf l1', 'bmf', 'bmf+ (int, l1)', 'mpbmf l1', 'nimfa l1'])]\n",
    "synth_l2 = synth_df.loc[synth_df['Algorithm'].isin(['binmf l2', 'bmf', 'bmf+ (int, l2)', 'mpbmf l2', 'nimfa l2'])]\n",
    "synth_l5 = synth_df.loc[synth_df['Algorithm'].isin(['binmf l5', 'bmf', 'bmf+ (int, l5)', 'mpbmf l5', 'nimfa l5'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "c7d54c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>binmf l1</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+ (int, l1)</th>\n",
       "      <th>mpbmf l1</th>\n",
       "      <th>nimfa l1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">congress</th>\n",
       "      <th>2</th>\n",
       "      <td>2535.40000</td>\n",
       "      <td>1603.00000</td>\n",
       "      <td>1522.00000</td>\n",
       "      <td>1522.70000</td>\n",
       "      <td>2011.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2723.50000</td>\n",
       "      <td>1466.60000</td>\n",
       "      <td>1378.90000</td>\n",
       "      <td>1538.40000</td>\n",
       "      <td>2045.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2614.10000</td>\n",
       "      <td>1267.00000</td>\n",
       "      <td>1167.80000</td>\n",
       "      <td>1763.70000</td>\n",
       "      <td>2264.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3005.40000</td>\n",
       "      <td>1049.20000</td>\n",
       "      <td>969.90000</td>\n",
       "      <td>1876.80000</td>\n",
       "      <td>1102.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2711.40000</td>\n",
       "      <td>920.40000</td>\n",
       "      <td>872.30000</td>\n",
       "      <td>1677.20000</td>\n",
       "      <td>380.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">orl</th>\n",
       "      <th>2</th>\n",
       "      <td>4525.91425</td>\n",
       "      <td>1585.28850</td>\n",
       "      <td>1473.15475</td>\n",
       "      <td>3487.70375</td>\n",
       "      <td>2072.6775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4608.26300</td>\n",
       "      <td>1311.40900</td>\n",
       "      <td>1250.40375</td>\n",
       "      <td>4514.47350</td>\n",
       "      <td>3286.6725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4586.95800</td>\n",
       "      <td>1032.48625</td>\n",
       "      <td>997.73050</td>\n",
       "      <td>5925.21800</td>\n",
       "      <td>4545.2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5081.62300</td>\n",
       "      <td>722.43050</td>\n",
       "      <td>704.79500</td>\n",
       "      <td>8377.60575</td>\n",
       "      <td>3898.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5351.15800</td>\n",
       "      <td>568.44675</td>\n",
       "      <td>556.85200</td>\n",
       "      <td>10488.95875</td>\n",
       "      <td>3813.2350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">thyroid</th>\n",
       "      <th>2</th>\n",
       "      <td>32295.60000</td>\n",
       "      <td>12094.60000</td>\n",
       "      <td>10187.90000</td>\n",
       "      <td>19573.60000</td>\n",
       "      <td>8225.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48312.90000</td>\n",
       "      <td>9302.70000</td>\n",
       "      <td>9032.90000</td>\n",
       "      <td>26269.90000</td>\n",
       "      <td>17151.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47199.10000</td>\n",
       "      <td>6931.10000</td>\n",
       "      <td>6987.60000</td>\n",
       "      <td>18783.50000</td>\n",
       "      <td>46439.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>42135.60000</td>\n",
       "      <td>4298.70000</td>\n",
       "      <td>4343.30000</td>\n",
       "      <td>24350.70000</td>\n",
       "      <td>19392.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>43816.30000</td>\n",
       "      <td>3422.30000</td>\n",
       "      <td>3237.00000</td>\n",
       "      <td>27547.90000</td>\n",
       "      <td>11561.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithm       binmf l1          bmf  bmf+ (int, l1)     mpbmf l1    nimfa l1\n",
       "Dataset  k                                                                    \n",
       "congress 2    2535.40000   1603.00000      1522.00000   1522.70000   2011.0000\n",
       "         3    2723.50000   1466.60000      1378.90000   1538.40000   2045.0000\n",
       "         5    2614.10000   1267.00000      1167.80000   1763.70000   2264.0000\n",
       "         10   3005.40000   1049.20000       969.90000   1876.80000   1102.0000\n",
       "         15   2711.40000    920.40000       872.30000   1677.20000    380.0000\n",
       "orl      2    4525.91425   1585.28850      1473.15475   3487.70375   2072.6775\n",
       "         3    4608.26300   1311.40900      1250.40375   4514.47350   3286.6725\n",
       "         5    4586.95800   1032.48625       997.73050   5925.21800   4545.2375\n",
       "         10   5081.62300    722.43050       704.79500   8377.60575   3898.6275\n",
       "         15   5351.15800    568.44675       556.85200  10488.95875   3813.2350\n",
       "thyroid  2   32295.60000  12094.60000     10187.90000  19573.60000   8225.0000\n",
       "         3   48312.90000   9302.70000      9032.90000  26269.90000  17151.0000\n",
       "         5   47199.10000   6931.10000      6987.60000  18783.50000  46439.0000\n",
       "         10  42135.60000   4298.70000      4343.30000  24350.70000  19392.0000\n",
       "         15  43816.30000   3422.30000      3237.00000  27547.90000  11561.0000"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = real_l1.groupby(['Dataset', 'k', 'Algorithm']).mean()\n",
    "grouped_df['Error'].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "b805519b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>binmf l2</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+ (int, l2)</th>\n",
       "      <th>mpbmf l2</th>\n",
       "      <th>nimfa l2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">congress</th>\n",
       "      <th>2</th>\n",
       "      <td>2537.60000</td>\n",
       "      <td>1603.00000</td>\n",
       "      <td>1526.00000</td>\n",
       "      <td>1529.70000</td>\n",
       "      <td>2011.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2738.70000</td>\n",
       "      <td>1466.60000</td>\n",
       "      <td>1384.00000</td>\n",
       "      <td>1610.40000</td>\n",
       "      <td>2277.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2663.90000</td>\n",
       "      <td>1267.00000</td>\n",
       "      <td>1187.60000</td>\n",
       "      <td>2075.10000</td>\n",
       "      <td>2470.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3359.00000</td>\n",
       "      <td>1049.20000</td>\n",
       "      <td>968.20000</td>\n",
       "      <td>2583.00000</td>\n",
       "      <td>1114.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2748.80000</td>\n",
       "      <td>920.40000</td>\n",
       "      <td>860.70000</td>\n",
       "      <td>2589.60000</td>\n",
       "      <td>416.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">orl</th>\n",
       "      <th>2</th>\n",
       "      <td>4533.46325</td>\n",
       "      <td>1585.28850</td>\n",
       "      <td>1477.12950</td>\n",
       "      <td>3771.28125</td>\n",
       "      <td>2133.6425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4638.30650</td>\n",
       "      <td>1311.40900</td>\n",
       "      <td>1249.60175</td>\n",
       "      <td>6169.16050</td>\n",
       "      <td>3504.8775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4724.91800</td>\n",
       "      <td>1032.48625</td>\n",
       "      <td>999.17850</td>\n",
       "      <td>10291.12300</td>\n",
       "      <td>5188.6025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5766.27150</td>\n",
       "      <td>722.43050</td>\n",
       "      <td>705.67025</td>\n",
       "      <td>21385.84375</td>\n",
       "      <td>4380.5675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6329.65800</td>\n",
       "      <td>568.44675</td>\n",
       "      <td>557.59900</td>\n",
       "      <td>34831.16475</td>\n",
       "      <td>4025.1450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">thyroid</th>\n",
       "      <th>2</th>\n",
       "      <td>32297.80000</td>\n",
       "      <td>12094.60000</td>\n",
       "      <td>10082.10000</td>\n",
       "      <td>20439.80000</td>\n",
       "      <td>8225.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48447.30000</td>\n",
       "      <td>9302.70000</td>\n",
       "      <td>8215.20000</td>\n",
       "      <td>31674.30000</td>\n",
       "      <td>17433.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48401.70000</td>\n",
       "      <td>6931.10000</td>\n",
       "      <td>6700.40000</td>\n",
       "      <td>22305.90000</td>\n",
       "      <td>61997.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>42791.20000</td>\n",
       "      <td>4298.70000</td>\n",
       "      <td>4243.10000</td>\n",
       "      <td>31445.10000</td>\n",
       "      <td>19392.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>43980.10000</td>\n",
       "      <td>3422.30000</td>\n",
       "      <td>3313.40000</td>\n",
       "      <td>38870.30000</td>\n",
       "      <td>11561.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithm       binmf l2          bmf  bmf+ (int, l2)     mpbmf l2    nimfa l2\n",
       "Dataset  k                                                                    \n",
       "congress 2    2537.60000   1603.00000      1526.00000   1529.70000   2011.0000\n",
       "         3    2738.70000   1466.60000      1384.00000   1610.40000   2277.0000\n",
       "         5    2663.90000   1267.00000      1187.60000   2075.10000   2470.0000\n",
       "         10   3359.00000   1049.20000       968.20000   2583.00000   1114.0000\n",
       "         15   2748.80000    920.40000       860.70000   2589.60000    416.0000\n",
       "orl      2    4533.46325   1585.28850      1477.12950   3771.28125   2133.6425\n",
       "         3    4638.30650   1311.40900      1249.60175   6169.16050   3504.8775\n",
       "         5    4724.91800   1032.48625       999.17850  10291.12300   5188.6025\n",
       "         10   5766.27150    722.43050       705.67025  21385.84375   4380.5675\n",
       "         15   6329.65800    568.44675       557.59900  34831.16475   4025.1450\n",
       "thyroid  2   32297.80000  12094.60000     10082.10000  20439.80000   8225.0000\n",
       "         3   48447.30000   9302.70000      8215.20000  31674.30000  17433.0000\n",
       "         5   48401.70000   6931.10000      6700.40000  22305.90000  61997.0000\n",
       "         10  42791.20000   4298.70000      4243.10000  31445.10000  19392.0000\n",
       "         15  43980.10000   3422.30000      3313.40000  38870.30000  11561.0000"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = real_l2.groupby(['Dataset', 'k', 'Algorithm']).mean()\n",
    "grouped_df['Error'].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "0a2b0c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>binmf l5</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+ (int, l5)</th>\n",
       "      <th>mpbmf l5</th>\n",
       "      <th>nimfa l5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">congress</th>\n",
       "      <th>2</th>\n",
       "      <td>2568.40000</td>\n",
       "      <td>1603.00000</td>\n",
       "      <td>1526.00000</td>\n",
       "      <td>1.627700e+03</td>\n",
       "      <td>2011.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2951.50000</td>\n",
       "      <td>1466.60000</td>\n",
       "      <td>1386.70000</td>\n",
       "      <td>2.618400e+03</td>\n",
       "      <td>5525.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3451.10000</td>\n",
       "      <td>1267.00000</td>\n",
       "      <td>1181.70000</td>\n",
       "      <td>7.289700e+03</td>\n",
       "      <td>5354.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10790.40000</td>\n",
       "      <td>1049.20000</td>\n",
       "      <td>955.10000</td>\n",
       "      <td>1.663380e+04</td>\n",
       "      <td>1282.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3347.40000</td>\n",
       "      <td>920.40000</td>\n",
       "      <td>858.70000</td>\n",
       "      <td>2.538620e+04</td>\n",
       "      <td>920.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">orl</th>\n",
       "      <th>2</th>\n",
       "      <td>4639.14925</td>\n",
       "      <td>1585.28850</td>\n",
       "      <td>1476.51400</td>\n",
       "      <td>7.741366e+03</td>\n",
       "      <td>2987.1525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5062.89050</td>\n",
       "      <td>1311.40900</td>\n",
       "      <td>1250.10325</td>\n",
       "      <td>3.357022e+04</td>\n",
       "      <td>6633.9975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6936.35550</td>\n",
       "      <td>1032.48625</td>\n",
       "      <td>999.84225</td>\n",
       "      <td>1.787981e+05</td>\n",
       "      <td>15003.7625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19957.50550</td>\n",
       "      <td>722.43050</td>\n",
       "      <td>706.14275</td>\n",
       "      <td>2.394899e+06</td>\n",
       "      <td>11909.4525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28394.91550</td>\n",
       "      <td>568.44675</td>\n",
       "      <td>557.22975</td>\n",
       "      <td>1.411953e+07</td>\n",
       "      <td>7266.2350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">thyroid</th>\n",
       "      <th>2</th>\n",
       "      <td>32328.60000</td>\n",
       "      <td>12094.60000</td>\n",
       "      <td>10011.90000</td>\n",
       "      <td>3.256660e+04</td>\n",
       "      <td>8225.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50328.90000</td>\n",
       "      <td>9302.70000</td>\n",
       "      <td>8853.70000</td>\n",
       "      <td>1.139359e+05</td>\n",
       "      <td>21381.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73122.10000</td>\n",
       "      <td>6931.10000</td>\n",
       "      <td>6980.50000</td>\n",
       "      <td>8.525750e+04</td>\n",
       "      <td>279809.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>52824.60000</td>\n",
       "      <td>4298.70000</td>\n",
       "      <td>4403.00000</td>\n",
       "      <td>1.566597e+05</td>\n",
       "      <td>19392.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>46363.30000</td>\n",
       "      <td>3422.30000</td>\n",
       "      <td>3312.80000</td>\n",
       "      <td>2.731459e+05</td>\n",
       "      <td>11561.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithm       binmf l5          bmf  bmf+ (int, l5)      mpbmf l5  \\\n",
       "Dataset  k                                                            \n",
       "congress 2    2568.40000   1603.00000      1526.00000  1.627700e+03   \n",
       "         3    2951.50000   1466.60000      1386.70000  2.618400e+03   \n",
       "         5    3451.10000   1267.00000      1181.70000  7.289700e+03   \n",
       "         10  10790.40000   1049.20000       955.10000  1.663380e+04   \n",
       "         15   3347.40000    920.40000       858.70000  2.538620e+04   \n",
       "orl      2    4639.14925   1585.28850      1476.51400  7.741366e+03   \n",
       "         3    5062.89050   1311.40900      1250.10325  3.357022e+04   \n",
       "         5    6936.35550   1032.48625       999.84225  1.787981e+05   \n",
       "         10  19957.50550    722.43050       706.14275  2.394899e+06   \n",
       "         15  28394.91550    568.44675       557.22975  1.411953e+07   \n",
       "thyroid  2   32328.60000  12094.60000     10011.90000  3.256660e+04   \n",
       "         3   50328.90000   9302.70000      8853.70000  1.139359e+05   \n",
       "         5   73122.10000   6931.10000      6980.50000  8.525750e+04   \n",
       "         10  52824.60000   4298.70000      4403.00000  1.566597e+05   \n",
       "         15  46363.30000   3422.30000      3312.80000  2.731459e+05   \n",
       "\n",
       "Algorithm       nimfa l5  \n",
       "Dataset  k                \n",
       "congress 2     2011.0000  \n",
       "         3     5525.0000  \n",
       "         5     5354.0000  \n",
       "         10    1282.0000  \n",
       "         15     920.0000  \n",
       "orl      2     2987.1525  \n",
       "         3     6633.9975  \n",
       "         5    15003.7625  \n",
       "         10   11909.4525  \n",
       "         15    7266.2350  \n",
       "thyroid  2     8225.0000  \n",
       "         3    21381.0000  \n",
       "         5   279809.0000  \n",
       "         10   19392.0000  \n",
       "         15   11561.0000  "
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = real_l5.groupby(['Dataset', 'k', 'Algorithm']).mean()\n",
    "grouped_df['Error'].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ae3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "e08d34ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>binmf l1</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+ (int, l1)</th>\n",
       "      <th>mpbmf l1</th>\n",
       "      <th>nimfa l1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">full</th>\n",
       "      <th>2</th>\n",
       "      <td>5894.808</td>\n",
       "      <td>5736.392</td>\n",
       "      <td>5383.992</td>\n",
       "      <td>5590.284</td>\n",
       "      <td>6056.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5841.592</td>\n",
       "      <td>5516.160</td>\n",
       "      <td>5204.740</td>\n",
       "      <td>5719.600</td>\n",
       "      <td>6183.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5799.004</td>\n",
       "      <td>5205.024</td>\n",
       "      <td>4959.436</td>\n",
       "      <td>5779.136</td>\n",
       "      <td>6418.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5637.484</td>\n",
       "      <td>4712.456</td>\n",
       "      <td>4578.772</td>\n",
       "      <td>5550.372</td>\n",
       "      <td>6107.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5516.280</td>\n",
       "      <td>4406.472</td>\n",
       "      <td>4323.488</td>\n",
       "      <td>5314.516</td>\n",
       "      <td>5569.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">full0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1934.784</td>\n",
       "      <td>1289.460</td>\n",
       "      <td>1227.364</td>\n",
       "      <td>1225.932</td>\n",
       "      <td>1499.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2135.224</td>\n",
       "      <td>1282.024</td>\n",
       "      <td>1221.808</td>\n",
       "      <td>1230.428</td>\n",
       "      <td>1744.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2228.592</td>\n",
       "      <td>1265.340</td>\n",
       "      <td>1202.316</td>\n",
       "      <td>1266.888</td>\n",
       "      <td>1869.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1738.056</td>\n",
       "      <td>1221.160</td>\n",
       "      <td>1153.768</td>\n",
       "      <td>1353.024</td>\n",
       "      <td>1535.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1804.804</td>\n",
       "      <td>1176.524</td>\n",
       "      <td>1100.732</td>\n",
       "      <td>1646.632</td>\n",
       "      <td>1234.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr10</th>\n",
       "      <th>2</th>\n",
       "      <td>5869.036</td>\n",
       "      <td>5741.388</td>\n",
       "      <td>5357.288</td>\n",
       "      <td>5590.468</td>\n",
       "      <td>5964.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5825.476</td>\n",
       "      <td>5517.924</td>\n",
       "      <td>5166.236</td>\n",
       "      <td>5748.572</td>\n",
       "      <td>6182.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5782.580</td>\n",
       "      <td>5197.728</td>\n",
       "      <td>4898.900</td>\n",
       "      <td>5782.228</td>\n",
       "      <td>5966.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5620.568</td>\n",
       "      <td>4647.344</td>\n",
       "      <td>4476.280</td>\n",
       "      <td>5617.380</td>\n",
       "      <td>5957.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5504.988</td>\n",
       "      <td>4295.128</td>\n",
       "      <td>4179.220</td>\n",
       "      <td>5388.244</td>\n",
       "      <td>5641.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr10-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1371.160</td>\n",
       "      <td>1029.800</td>\n",
       "      <td>1004.948</td>\n",
       "      <td>837.400</td>\n",
       "      <td>1235.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1526.156</td>\n",
       "      <td>890.364</td>\n",
       "      <td>856.028</td>\n",
       "      <td>715.292</td>\n",
       "      <td>1145.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1794.068</td>\n",
       "      <td>667.928</td>\n",
       "      <td>613.124</td>\n",
       "      <td>488.084</td>\n",
       "      <td>695.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1738.072</td>\n",
       "      <td>372.532</td>\n",
       "      <td>227.932</td>\n",
       "      <td>130.588</td>\n",
       "      <td>186.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1180.384</td>\n",
       "      <td>257.132</td>\n",
       "      <td>108.320</td>\n",
       "      <td>99.376</td>\n",
       "      <td>139.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr15</th>\n",
       "      <th>2</th>\n",
       "      <td>5868.216</td>\n",
       "      <td>5732.744</td>\n",
       "      <td>5375.496</td>\n",
       "      <td>5563.124</td>\n",
       "      <td>6036.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5823.016</td>\n",
       "      <td>5515.080</td>\n",
       "      <td>5197.868</td>\n",
       "      <td>5688.616</td>\n",
       "      <td>6248.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5784.820</td>\n",
       "      <td>5207.972</td>\n",
       "      <td>4952.756</td>\n",
       "      <td>5732.756</td>\n",
       "      <td>6429.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5633.284</td>\n",
       "      <td>4710.444</td>\n",
       "      <td>4569.272</td>\n",
       "      <td>5526.260</td>\n",
       "      <td>6235.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5502.188</td>\n",
       "      <td>4401.692</td>\n",
       "      <td>4318.540</td>\n",
       "      <td>5283.496</td>\n",
       "      <td>5712.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr15-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1753.676</td>\n",
       "      <td>1550.032</td>\n",
       "      <td>1506.412</td>\n",
       "      <td>1322.612</td>\n",
       "      <td>1937.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1827.800</td>\n",
       "      <td>1418.796</td>\n",
       "      <td>1360.876</td>\n",
       "      <td>1202.004</td>\n",
       "      <td>1936.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2082.312</td>\n",
       "      <td>1196.932</td>\n",
       "      <td>1121.884</td>\n",
       "      <td>982.676</td>\n",
       "      <td>1518.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2586.232</td>\n",
       "      <td>851.384</td>\n",
       "      <td>681.652</td>\n",
       "      <td>552.988</td>\n",
       "      <td>788.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2535.924</td>\n",
       "      <td>694.268</td>\n",
       "      <td>458.224</td>\n",
       "      <td>277.400</td>\n",
       "      <td>379.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr5</th>\n",
       "      <th>2</th>\n",
       "      <td>5401.548</td>\n",
       "      <td>5222.544</td>\n",
       "      <td>4775.464</td>\n",
       "      <td>4971.432</td>\n",
       "      <td>5158.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5315.208</td>\n",
       "      <td>4752.412</td>\n",
       "      <td>4401.440</td>\n",
       "      <td>5007.588</td>\n",
       "      <td>5853.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5243.020</td>\n",
       "      <td>4069.268</td>\n",
       "      <td>3772.132</td>\n",
       "      <td>4801.188</td>\n",
       "      <td>4812.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5488.900</td>\n",
       "      <td>2773.692</td>\n",
       "      <td>2561.648</td>\n",
       "      <td>3413.412</td>\n",
       "      <td>3162.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6221.272</td>\n",
       "      <td>1854.956</td>\n",
       "      <td>1670.116</td>\n",
       "      <td>2503.704</td>\n",
       "      <td>1936.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr5-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>881.416</td>\n",
       "      <td>485.096</td>\n",
       "      <td>480.432</td>\n",
       "      <td>338.836</td>\n",
       "      <td>526.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>907.088</td>\n",
       "      <td>338.632</td>\n",
       "      <td>331.076</td>\n",
       "      <td>225.828</td>\n",
       "      <td>264.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>780.300</td>\n",
       "      <td>158.824</td>\n",
       "      <td>117.388</td>\n",
       "      <td>48.220</td>\n",
       "      <td>44.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>492.636</td>\n",
       "      <td>36.216</td>\n",
       "      <td>11.104</td>\n",
       "      <td>71.872</td>\n",
       "      <td>142.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>488.580</td>\n",
       "      <td>6.548</td>\n",
       "      <td>2.016</td>\n",
       "      <td>166.268</td>\n",
       "      <td>170.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-0001</th>\n",
       "      <th>2</th>\n",
       "      <td>5855.764</td>\n",
       "      <td>5751.324</td>\n",
       "      <td>5354.672</td>\n",
       "      <td>5564.184</td>\n",
       "      <td>5991.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5805.412</td>\n",
       "      <td>5527.984</td>\n",
       "      <td>5167.532</td>\n",
       "      <td>5672.544</td>\n",
       "      <td>6207.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5758.980</td>\n",
       "      <td>5202.720</td>\n",
       "      <td>4897.220</td>\n",
       "      <td>5738.064</td>\n",
       "      <td>6078.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5596.988</td>\n",
       "      <td>4659.872</td>\n",
       "      <td>4473.416</td>\n",
       "      <td>5537.756</td>\n",
       "      <td>5948.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5484.512</td>\n",
       "      <td>4302.984</td>\n",
       "      <td>4172.204</td>\n",
       "      <td>5327.052</td>\n",
       "      <td>5467.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-0001-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1385.300</td>\n",
       "      <td>1048.852</td>\n",
       "      <td>1036.328</td>\n",
       "      <td>862.316</td>\n",
       "      <td>1320.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1496.448</td>\n",
       "      <td>912.300</td>\n",
       "      <td>877.020</td>\n",
       "      <td>736.556</td>\n",
       "      <td>1181.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1739.756</td>\n",
       "      <td>693.500</td>\n",
       "      <td>633.368</td>\n",
       "      <td>511.584</td>\n",
       "      <td>723.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1843.624</td>\n",
       "      <td>410.768</td>\n",
       "      <td>268.860</td>\n",
       "      <td>154.936</td>\n",
       "      <td>205.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1333.096</td>\n",
       "      <td>291.420</td>\n",
       "      <td>135.440</td>\n",
       "      <td>109.836</td>\n",
       "      <td>158.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-001</th>\n",
       "      <th>2</th>\n",
       "      <td>5845.100</td>\n",
       "      <td>5738.904</td>\n",
       "      <td>5341.192</td>\n",
       "      <td>5556.680</td>\n",
       "      <td>5991.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5801.880</td>\n",
       "      <td>5520.908</td>\n",
       "      <td>5150.836</td>\n",
       "      <td>5664.904</td>\n",
       "      <td>6221.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5760.008</td>\n",
       "      <td>5183.712</td>\n",
       "      <td>4885.804</td>\n",
       "      <td>5736.676</td>\n",
       "      <td>5939.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5601.580</td>\n",
       "      <td>4648.680</td>\n",
       "      <td>4459.152</td>\n",
       "      <td>5534.416</td>\n",
       "      <td>5811.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5489.404</td>\n",
       "      <td>4294.824</td>\n",
       "      <td>4165.028</td>\n",
       "      <td>5323.868</td>\n",
       "      <td>5357.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-001-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1491.660</td>\n",
       "      <td>1148.512</td>\n",
       "      <td>1124.300</td>\n",
       "      <td>944.544</td>\n",
       "      <td>1408.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1614.108</td>\n",
       "      <td>1012.868</td>\n",
       "      <td>975.472</td>\n",
       "      <td>822.304</td>\n",
       "      <td>1220.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1911.028</td>\n",
       "      <td>792.140</td>\n",
       "      <td>732.984</td>\n",
       "      <td>601.204</td>\n",
       "      <td>851.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2287.164</td>\n",
       "      <td>509.608</td>\n",
       "      <td>375.380</td>\n",
       "      <td>265.560</td>\n",
       "      <td>338.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2224.844</td>\n",
       "      <td>397.808</td>\n",
       "      <td>256.916</td>\n",
       "      <td>223.420</td>\n",
       "      <td>218.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithm            binmf l1       bmf  bmf+ (int, l1)  mpbmf l1  nimfa l1\n",
       "Dataset          k                                                         \n",
       "full             2   5894.808  5736.392        5383.992  5590.284   6056.24\n",
       "                 3   5841.592  5516.160        5204.740  5719.600   6183.36\n",
       "                 5   5799.004  5205.024        4959.436  5779.136   6418.88\n",
       "                 10  5637.484  4712.456        4578.772  5550.372   6107.28\n",
       "                 15  5516.280  4406.472        4323.488  5314.516   5569.40\n",
       "full0.1          2   1934.784  1289.460        1227.364  1225.932   1499.20\n",
       "                 3   2135.224  1282.024        1221.808  1230.428   1744.28\n",
       "                 5   2228.592  1265.340        1202.316  1266.888   1869.32\n",
       "                 10  1738.056  1221.160        1153.768  1353.024   1535.76\n",
       "                 15  1804.804  1176.524        1100.732  1646.632   1234.60\n",
       "lr10             2   5869.036  5741.388        5357.288  5590.468   5964.96\n",
       "                 3   5825.476  5517.924        5166.236  5748.572   6182.28\n",
       "                 5   5782.580  5197.728        4898.900  5782.228   5966.28\n",
       "                 10  5620.568  4647.344        4476.280  5617.380   5957.00\n",
       "                 15  5504.988  4295.128        4179.220  5388.244   5641.16\n",
       "lr10-0.1         2   1371.160  1029.800        1004.948   837.400   1235.84\n",
       "                 3   1526.156   890.364         856.028   715.292   1145.28\n",
       "                 5   1794.068   667.928         613.124   488.084    695.64\n",
       "                 10  1738.072   372.532         227.932   130.588    186.96\n",
       "                 15  1180.384   257.132         108.320    99.376    139.64\n",
       "lr15             2   5868.216  5732.744        5375.496  5563.124   6036.00\n",
       "                 3   5823.016  5515.080        5197.868  5688.616   6248.72\n",
       "                 5   5784.820  5207.972        4952.756  5732.756   6429.76\n",
       "                 10  5633.284  4710.444        4569.272  5526.260   6235.68\n",
       "                 15  5502.188  4401.692        4318.540  5283.496   5712.28\n",
       "lr15-0.1         2   1753.676  1550.032        1506.412  1322.612   1937.32\n",
       "                 3   1827.800  1418.796        1360.876  1202.004   1936.80\n",
       "                 5   2082.312  1196.932        1121.884   982.676   1518.40\n",
       "                 10  2586.232   851.384         681.652   552.988    788.68\n",
       "                 15  2535.924   694.268         458.224   277.400    379.80\n",
       "lr5              2   5401.548  5222.544        4775.464  4971.432   5158.32\n",
       "                 3   5315.208  4752.412        4401.440  5007.588   5853.20\n",
       "                 5   5243.020  4069.268        3772.132  4801.188   4812.52\n",
       "                 10  5488.900  2773.692        2561.648  3413.412   3162.64\n",
       "                 15  6221.272  1854.956        1670.116  2503.704   1936.76\n",
       "lr5-0.1          2    881.416   485.096         480.432   338.836    526.12\n",
       "                 3    907.088   338.632         331.076   225.828    264.32\n",
       "                 5    780.300   158.824         117.388    48.220     44.96\n",
       "                 10   492.636    36.216          11.104    71.872    142.32\n",
       "                 15   488.580     6.548           2.016   166.268    170.32\n",
       "noisy10-0001     2   5855.764  5751.324        5354.672  5564.184   5991.20\n",
       "                 3   5805.412  5527.984        5167.532  5672.544   6207.48\n",
       "                 5   5758.980  5202.720        4897.220  5738.064   6078.12\n",
       "                 10  5596.988  4659.872        4473.416  5537.756   5948.60\n",
       "                 15  5484.512  4302.984        4172.204  5327.052   5467.52\n",
       "noisy10-0001-0.1 2   1385.300  1048.852        1036.328   862.316   1320.36\n",
       "                 3   1496.448   912.300         877.020   736.556   1181.76\n",
       "                 5   1739.756   693.500         633.368   511.584    723.36\n",
       "                 10  1843.624   410.768         268.860   154.936    205.32\n",
       "                 15  1333.096   291.420         135.440   109.836    158.24\n",
       "noisy10-001      2   5845.100  5738.904        5341.192  5556.680   5991.76\n",
       "                 3   5801.880  5520.908        5150.836  5664.904   6221.68\n",
       "                 5   5760.008  5183.712        4885.804  5736.676   5939.36\n",
       "                 10  5601.580  4648.680        4459.152  5534.416   5811.92\n",
       "                 15  5489.404  4294.824        4165.028  5323.868   5357.44\n",
       "noisy10-001-0.1  2   1491.660  1148.512        1124.300   944.544   1408.24\n",
       "                 3   1614.108  1012.868         975.472   822.304   1220.72\n",
       "                 5   1911.028   792.140         732.984   601.204    851.16\n",
       "                 10  2287.164   509.608         375.380   265.560    338.72\n",
       "                 15  2224.844   397.808         256.916   223.420    218.32"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = synth_l1.groupby(['Dataset', 'k', 'Algorithm']).mean()\n",
    "grouped_df['Error'].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "cbf2c4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>binmf l2</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+ (int, l2)</th>\n",
       "      <th>mpbmf l2</th>\n",
       "      <th>nimfa l2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">full</th>\n",
       "      <th>2</th>\n",
       "      <td>5906.360</td>\n",
       "      <td>5736.392</td>\n",
       "      <td>5383.372</td>\n",
       "      <td>6067.508</td>\n",
       "      <td>6135.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5849.688</td>\n",
       "      <td>5516.160</td>\n",
       "      <td>5199.296</td>\n",
       "      <td>6562.712</td>\n",
       "      <td>6599.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5806.548</td>\n",
       "      <td>5205.024</td>\n",
       "      <td>4964.404</td>\n",
       "      <td>7019.016</td>\n",
       "      <td>7315.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5649.324</td>\n",
       "      <td>4712.456</td>\n",
       "      <td>4573.492</td>\n",
       "      <td>7113.300</td>\n",
       "      <td>7028.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5533.712</td>\n",
       "      <td>4406.472</td>\n",
       "      <td>4323.616</td>\n",
       "      <td>6990.012</td>\n",
       "      <td>6361.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">full0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1934.784</td>\n",
       "      <td>1289.460</td>\n",
       "      <td>1225.984</td>\n",
       "      <td>1226.148</td>\n",
       "      <td>1499.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2166.792</td>\n",
       "      <td>1282.024</td>\n",
       "      <td>1218.220</td>\n",
       "      <td>1230.716</td>\n",
       "      <td>1745.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2299.440</td>\n",
       "      <td>1265.340</td>\n",
       "      <td>1201.068</td>\n",
       "      <td>1268.576</td>\n",
       "      <td>1869.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1787.600</td>\n",
       "      <td>1221.160</td>\n",
       "      <td>1150.996</td>\n",
       "      <td>1371.016</td>\n",
       "      <td>1536.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1875.996</td>\n",
       "      <td>1176.524</td>\n",
       "      <td>1104.048</td>\n",
       "      <td>1741.120</td>\n",
       "      <td>1235.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr10</th>\n",
       "      <th>2</th>\n",
       "      <td>5878.548</td>\n",
       "      <td>5741.388</td>\n",
       "      <td>5360.032</td>\n",
       "      <td>6110.340</td>\n",
       "      <td>5980.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5833.596</td>\n",
       "      <td>5517.924</td>\n",
       "      <td>5165.092</td>\n",
       "      <td>6694.652</td>\n",
       "      <td>6648.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5789.804</td>\n",
       "      <td>5197.728</td>\n",
       "      <td>4905.644</td>\n",
       "      <td>7181.860</td>\n",
       "      <td>6638.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5634.096</td>\n",
       "      <td>4647.344</td>\n",
       "      <td>4482.092</td>\n",
       "      <td>7662.300</td>\n",
       "      <td>6882.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5527.820</td>\n",
       "      <td>4295.128</td>\n",
       "      <td>4185.060</td>\n",
       "      <td>7726.788</td>\n",
       "      <td>6506.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr10-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1377.256</td>\n",
       "      <td>1029.800</td>\n",
       "      <td>1003.600</td>\n",
       "      <td>842.208</td>\n",
       "      <td>1241.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1551.964</td>\n",
       "      <td>890.364</td>\n",
       "      <td>862.664</td>\n",
       "      <td>728.468</td>\n",
       "      <td>1170.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1882.980</td>\n",
       "      <td>667.928</td>\n",
       "      <td>625.520</td>\n",
       "      <td>523.196</td>\n",
       "      <td>737.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1892.120</td>\n",
       "      <td>372.532</td>\n",
       "      <td>261.576</td>\n",
       "      <td>217.084</td>\n",
       "      <td>232.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1224.104</td>\n",
       "      <td>257.132</td>\n",
       "      <td>143.664</td>\n",
       "      <td>153.984</td>\n",
       "      <td>159.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr15</th>\n",
       "      <th>2</th>\n",
       "      <td>5879.048</td>\n",
       "      <td>5732.744</td>\n",
       "      <td>5371.456</td>\n",
       "      <td>6022.196</td>\n",
       "      <td>6087.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5831.064</td>\n",
       "      <td>5515.080</td>\n",
       "      <td>5202.184</td>\n",
       "      <td>6500.664</td>\n",
       "      <td>6742.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5792.228</td>\n",
       "      <td>5207.972</td>\n",
       "      <td>4957.184</td>\n",
       "      <td>6945.428</td>\n",
       "      <td>7320.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5644.980</td>\n",
       "      <td>4710.444</td>\n",
       "      <td>4570.092</td>\n",
       "      <td>7099.660</td>\n",
       "      <td>7246.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5520.284</td>\n",
       "      <td>4401.692</td>\n",
       "      <td>4318.236</td>\n",
       "      <td>6972.864</td>\n",
       "      <td>6573.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr15-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1753.780</td>\n",
       "      <td>1550.032</td>\n",
       "      <td>1514.172</td>\n",
       "      <td>1330.540</td>\n",
       "      <td>1950.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1838.536</td>\n",
       "      <td>1418.796</td>\n",
       "      <td>1365.288</td>\n",
       "      <td>1220.308</td>\n",
       "      <td>2000.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2140.392</td>\n",
       "      <td>1196.932</td>\n",
       "      <td>1128.200</td>\n",
       "      <td>1027.468</td>\n",
       "      <td>1608.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2830.328</td>\n",
       "      <td>851.384</td>\n",
       "      <td>722.380</td>\n",
       "      <td>692.292</td>\n",
       "      <td>895.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2845.444</td>\n",
       "      <td>694.268</td>\n",
       "      <td>516.060</td>\n",
       "      <td>491.040</td>\n",
       "      <td>466.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr5</th>\n",
       "      <th>2</th>\n",
       "      <td>5408.044</td>\n",
       "      <td>5222.544</td>\n",
       "      <td>4777.660</td>\n",
       "      <td>5662.264</td>\n",
       "      <td>5188.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5336.680</td>\n",
       "      <td>4752.412</td>\n",
       "      <td>4415.240</td>\n",
       "      <td>6402.436</td>\n",
       "      <td>7000.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5312.716</td>\n",
       "      <td>4069.268</td>\n",
       "      <td>3823.264</td>\n",
       "      <td>7356.228</td>\n",
       "      <td>5706.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6027.068</td>\n",
       "      <td>2773.692</td>\n",
       "      <td>2647.636</td>\n",
       "      <td>6066.084</td>\n",
       "      <td>3532.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7652.712</td>\n",
       "      <td>1854.956</td>\n",
       "      <td>1779.184</td>\n",
       "      <td>4610.184</td>\n",
       "      <td>2062.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr5-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>888.624</td>\n",
       "      <td>485.096</td>\n",
       "      <td>471.348</td>\n",
       "      <td>342.380</td>\n",
       "      <td>527.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>927.048</td>\n",
       "      <td>338.632</td>\n",
       "      <td>329.824</td>\n",
       "      <td>237.436</td>\n",
       "      <td>274.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>804.924</td>\n",
       "      <td>158.824</td>\n",
       "      <td>128.024</td>\n",
       "      <td>72.372</td>\n",
       "      <td>62.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>495.516</td>\n",
       "      <td>36.216</td>\n",
       "      <td>16.368</td>\n",
       "      <td>79.176</td>\n",
       "      <td>179.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>489.252</td>\n",
       "      <td>6.548</td>\n",
       "      <td>3.012</td>\n",
       "      <td>229.476</td>\n",
       "      <td>184.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-0001</th>\n",
       "      <th>2</th>\n",
       "      <td>5865.700</td>\n",
       "      <td>5751.324</td>\n",
       "      <td>5355.728</td>\n",
       "      <td>6058.504</td>\n",
       "      <td>6004.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5813.508</td>\n",
       "      <td>5527.984</td>\n",
       "      <td>5165.684</td>\n",
       "      <td>6541.240</td>\n",
       "      <td>6677.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5766.460</td>\n",
       "      <td>5202.720</td>\n",
       "      <td>4902.180</td>\n",
       "      <td>7087.664</td>\n",
       "      <td>6831.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5610.772</td>\n",
       "      <td>4659.872</td>\n",
       "      <td>4476.664</td>\n",
       "      <td>7494.636</td>\n",
       "      <td>6889.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5508.064</td>\n",
       "      <td>4302.984</td>\n",
       "      <td>4187.572</td>\n",
       "      <td>7586.396</td>\n",
       "      <td>6279.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-0001-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1391.220</td>\n",
       "      <td>1048.852</td>\n",
       "      <td>1029.068</td>\n",
       "      <td>868.116</td>\n",
       "      <td>1329.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1523.784</td>\n",
       "      <td>912.300</td>\n",
       "      <td>890.296</td>\n",
       "      <td>750.884</td>\n",
       "      <td>1202.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1821.380</td>\n",
       "      <td>693.500</td>\n",
       "      <td>646.300</td>\n",
       "      <td>552.472</td>\n",
       "      <td>766.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2036.864</td>\n",
       "      <td>410.768</td>\n",
       "      <td>294.620</td>\n",
       "      <td>252.160</td>\n",
       "      <td>259.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1403.688</td>\n",
       "      <td>291.420</td>\n",
       "      <td>168.808</td>\n",
       "      <td>181.812</td>\n",
       "      <td>181.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-001</th>\n",
       "      <th>2</th>\n",
       "      <td>5851.388</td>\n",
       "      <td>5738.904</td>\n",
       "      <td>5344.164</td>\n",
       "      <td>6058.088</td>\n",
       "      <td>6012.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5809.176</td>\n",
       "      <td>5520.908</td>\n",
       "      <td>5150.284</td>\n",
       "      <td>6547.656</td>\n",
       "      <td>6747.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5768.104</td>\n",
       "      <td>5183.712</td>\n",
       "      <td>4890.728</td>\n",
       "      <td>7097.708</td>\n",
       "      <td>6616.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5615.708</td>\n",
       "      <td>4648.680</td>\n",
       "      <td>4471.032</td>\n",
       "      <td>7469.336</td>\n",
       "      <td>6676.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5514.556</td>\n",
       "      <td>4294.824</td>\n",
       "      <td>4167.852</td>\n",
       "      <td>7554.004</td>\n",
       "      <td>6143.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-001-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1497.060</td>\n",
       "      <td>1148.512</td>\n",
       "      <td>1119.664</td>\n",
       "      <td>950.648</td>\n",
       "      <td>1412.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1637.220</td>\n",
       "      <td>1012.868</td>\n",
       "      <td>981.296</td>\n",
       "      <td>838.592</td>\n",
       "      <td>1245.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1993.908</td>\n",
       "      <td>792.140</td>\n",
       "      <td>743.068</td>\n",
       "      <td>641.516</td>\n",
       "      <td>898.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2529.116</td>\n",
       "      <td>509.608</td>\n",
       "      <td>409.068</td>\n",
       "      <td>366.096</td>\n",
       "      <td>386.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2498.684</td>\n",
       "      <td>397.808</td>\n",
       "      <td>291.004</td>\n",
       "      <td>306.132</td>\n",
       "      <td>238.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithm            binmf l2       bmf  bmf+ (int, l2)  mpbmf l2  nimfa l2\n",
       "Dataset          k                                                         \n",
       "full             2   5906.360  5736.392        5383.372  6067.508   6135.92\n",
       "                 3   5849.688  5516.160        5199.296  6562.712   6599.60\n",
       "                 5   5806.548  5205.024        4964.404  7019.016   7315.20\n",
       "                 10  5649.324  4712.456        4573.492  7113.300   7028.00\n",
       "                 15  5533.712  4406.472        4323.616  6990.012   6361.08\n",
       "full0.1          2   1934.784  1289.460        1225.984  1226.148   1499.20\n",
       "                 3   2166.792  1282.024        1218.220  1230.716   1745.24\n",
       "                 5   2299.440  1265.340        1201.068  1268.576   1869.32\n",
       "                 10  1787.600  1221.160        1150.996  1371.016   1536.80\n",
       "                 15  1875.996  1176.524        1104.048  1741.120   1235.08\n",
       "lr10             2   5878.548  5741.388        5360.032  6110.340   5980.00\n",
       "                 3   5833.596  5517.924        5165.092  6694.652   6648.44\n",
       "                 5   5789.804  5197.728        4905.644  7181.860   6638.20\n",
       "                 10  5634.096  4647.344        4482.092  7662.300   6882.20\n",
       "                 15  5527.820  4295.128        4185.060  7726.788   6506.04\n",
       "lr10-0.1         2   1377.256  1029.800        1003.600   842.208   1241.68\n",
       "                 3   1551.964   890.364         862.664   728.468   1170.96\n",
       "                 5   1882.980   667.928         625.520   523.196    737.72\n",
       "                 10  1892.120   372.532         261.576   217.084    232.16\n",
       "                 15  1224.104   257.132         143.664   153.984    159.08\n",
       "lr15             2   5879.048  5732.744        5371.456  6022.196   6087.84\n",
       "                 3   5831.064  5515.080        5202.184  6500.664   6742.96\n",
       "                 5   5792.228  5207.972        4957.184  6945.428   7320.08\n",
       "                 10  5644.980  4710.444        4570.092  7099.660   7246.48\n",
       "                 15  5520.284  4401.692        4318.236  6972.864   6573.72\n",
       "lr15-0.1         2   1753.780  1550.032        1514.172  1330.540   1950.36\n",
       "                 3   1838.536  1418.796        1365.288  1220.308   2000.64\n",
       "                 5   2140.392  1196.932        1128.200  1027.468   1608.24\n",
       "                 10  2830.328   851.384         722.380   692.292    895.40\n",
       "                 15  2845.444   694.268         516.060   491.040    466.92\n",
       "lr5              2   5408.044  5222.544        4777.660  5662.264   5188.00\n",
       "                 3   5336.680  4752.412        4415.240  6402.436   7000.80\n",
       "                 5   5312.716  4069.268        3823.264  7356.228   5706.04\n",
       "                 10  6027.068  2773.692        2647.636  6066.084   3532.96\n",
       "                 15  7652.712  1854.956        1779.184  4610.184   2062.52\n",
       "lr5-0.1          2    888.624   485.096         471.348   342.380    527.40\n",
       "                 3    927.048   338.632         329.824   237.436    274.80\n",
       "                 5    804.924   158.824         128.024    72.372     62.08\n",
       "                 10   495.516    36.216          16.368    79.176    179.36\n",
       "                 15   489.252     6.548           3.012   229.476    184.00\n",
       "noisy10-0001     2   5865.700  5751.324        5355.728  6058.504   6004.48\n",
       "                 3   5813.508  5527.984        5165.684  6541.240   6677.08\n",
       "                 5   5766.460  5202.720        4902.180  7087.664   6831.80\n",
       "                 10  5610.772  4659.872        4476.664  7494.636   6889.88\n",
       "                 15  5508.064  4302.984        4187.572  7586.396   6279.44\n",
       "noisy10-0001-0.1 2   1391.220  1048.852        1029.068   868.116   1329.80\n",
       "                 3   1523.784   912.300         890.296   750.884   1202.96\n",
       "                 5   1821.380   693.500         646.300   552.472    766.88\n",
       "                 10  2036.864   410.768         294.620   252.160    259.80\n",
       "                 15  1403.688   291.420         168.808   181.812    181.20\n",
       "noisy10-001      2   5851.388  5738.904        5344.164  6058.088   6012.56\n",
       "                 3   5809.176  5520.908        5150.284  6547.656   6747.20\n",
       "                 5   5768.104  5183.712        4890.728  7097.708   6616.80\n",
       "                 10  5615.708  4648.680        4471.032  7469.336   6676.16\n",
       "                 15  5514.556  4294.824        4167.852  7554.004   6143.84\n",
       "noisy10-001-0.1  2   1497.060  1148.512        1119.664   950.648   1412.56\n",
       "                 3   1637.220  1012.868         981.296   838.592   1245.68\n",
       "                 5   1993.908   792.140         743.068   641.516    898.12\n",
       "                 10  2529.116   509.608         409.068   366.096    386.64\n",
       "                 15  2498.684   397.808         291.004   306.132    238.24"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = synth_l2.groupby(['Dataset', 'k', 'Algorithm']).mean()\n",
    "grouped_df['Error'].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "88b0cc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>binmf l5</th>\n",
       "      <th>bmf</th>\n",
       "      <th>bmf+ (int, l5)</th>\n",
       "      <th>mpbmf l5</th>\n",
       "      <th>nimfa l5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">full</th>\n",
       "      <th>2</th>\n",
       "      <td>6068.088</td>\n",
       "      <td>5736.392</td>\n",
       "      <td>5377.000</td>\n",
       "      <td>12748.644</td>\n",
       "      <td>7251.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5963.032</td>\n",
       "      <td>5516.160</td>\n",
       "      <td>5202.324</td>\n",
       "      <td>19217.080</td>\n",
       "      <td>12426.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5912.164</td>\n",
       "      <td>5205.024</td>\n",
       "      <td>4960.328</td>\n",
       "      <td>27414.176</td>\n",
       "      <td>19863.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5818.084</td>\n",
       "      <td>4712.456</td>\n",
       "      <td>4576.740</td>\n",
       "      <td>36911.772</td>\n",
       "      <td>21235.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5786.160</td>\n",
       "      <td>4406.472</td>\n",
       "      <td>4326.308</td>\n",
       "      <td>41413.996</td>\n",
       "      <td>18632.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">full0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1934.784</td>\n",
       "      <td>1289.460</td>\n",
       "      <td>1228.680</td>\n",
       "      <td>1229.172</td>\n",
       "      <td>1499.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2608.744</td>\n",
       "      <td>1282.024</td>\n",
       "      <td>1218.212</td>\n",
       "      <td>1234.748</td>\n",
       "      <td>1758.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3327.312</td>\n",
       "      <td>1265.340</td>\n",
       "      <td>1200.484</td>\n",
       "      <td>1295.208</td>\n",
       "      <td>1869.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2553.936</td>\n",
       "      <td>1221.160</td>\n",
       "      <td>1152.596</td>\n",
       "      <td>1669.104</td>\n",
       "      <td>1551.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3004.804</td>\n",
       "      <td>1176.524</td>\n",
       "      <td>1100.280</td>\n",
       "      <td>3527.392</td>\n",
       "      <td>1241.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr10</th>\n",
       "      <th>2</th>\n",
       "      <td>6011.716</td>\n",
       "      <td>5741.388</td>\n",
       "      <td>5357.988</td>\n",
       "      <td>13388.548</td>\n",
       "      <td>6190.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5947.276</td>\n",
       "      <td>5517.924</td>\n",
       "      <td>5164.796</td>\n",
       "      <td>21364.172</td>\n",
       "      <td>13174.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5890.940</td>\n",
       "      <td>5197.728</td>\n",
       "      <td>4904.776</td>\n",
       "      <td>31344.508</td>\n",
       "      <td>16045.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5825.888</td>\n",
       "      <td>4647.344</td>\n",
       "      <td>4488.128</td>\n",
       "      <td>49994.940</td>\n",
       "      <td>21125.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5859.468</td>\n",
       "      <td>4295.128</td>\n",
       "      <td>4190.416</td>\n",
       "      <td>61031.404</td>\n",
       "      <td>20222.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr10-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1462.600</td>\n",
       "      <td>1029.800</td>\n",
       "      <td>1007.236</td>\n",
       "      <td>909.520</td>\n",
       "      <td>1323.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1922.876</td>\n",
       "      <td>890.364</td>\n",
       "      <td>858.276</td>\n",
       "      <td>917.732</td>\n",
       "      <td>1530.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3179.348</td>\n",
       "      <td>667.928</td>\n",
       "      <td>622.196</td>\n",
       "      <td>1035.764</td>\n",
       "      <td>1356.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4518.712</td>\n",
       "      <td>372.532</td>\n",
       "      <td>268.424</td>\n",
       "      <td>1479.028</td>\n",
       "      <td>882.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1911.184</td>\n",
       "      <td>257.132</td>\n",
       "      <td>149.416</td>\n",
       "      <td>1142.776</td>\n",
       "      <td>437.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr15</th>\n",
       "      <th>2</th>\n",
       "      <td>6030.696</td>\n",
       "      <td>5732.744</td>\n",
       "      <td>5374.872</td>\n",
       "      <td>12449.204</td>\n",
       "      <td>6813.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5943.736</td>\n",
       "      <td>5515.080</td>\n",
       "      <td>5205.588</td>\n",
       "      <td>18752.536</td>\n",
       "      <td>13662.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5895.940</td>\n",
       "      <td>5207.972</td>\n",
       "      <td>4958.088</td>\n",
       "      <td>26807.876</td>\n",
       "      <td>19874.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5814.724</td>\n",
       "      <td>4710.444</td>\n",
       "      <td>4572.316</td>\n",
       "      <td>37296.140</td>\n",
       "      <td>22777.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5786.228</td>\n",
       "      <td>4401.692</td>\n",
       "      <td>4319.204</td>\n",
       "      <td>41610.256</td>\n",
       "      <td>20270.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr15-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1755.236</td>\n",
       "      <td>1550.032</td>\n",
       "      <td>1509.952</td>\n",
       "      <td>1441.532</td>\n",
       "      <td>2132.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988.840</td>\n",
       "      <td>1418.796</td>\n",
       "      <td>1360.732</td>\n",
       "      <td>1487.364</td>\n",
       "      <td>2948.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3027.792</td>\n",
       "      <td>1196.932</td>\n",
       "      <td>1130.692</td>\n",
       "      <td>1686.356</td>\n",
       "      <td>2914.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6802.312</td>\n",
       "      <td>851.384</td>\n",
       "      <td>743.552</td>\n",
       "      <td>2862.508</td>\n",
       "      <td>2449.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8285.724</td>\n",
       "      <td>694.268</td>\n",
       "      <td>539.196</td>\n",
       "      <td>3848.120</td>\n",
       "      <td>1698.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr5</th>\n",
       "      <th>2</th>\n",
       "      <td>5498.988</td>\n",
       "      <td>5222.544</td>\n",
       "      <td>4784.400</td>\n",
       "      <td>15333.912</td>\n",
       "      <td>5603.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5643.288</td>\n",
       "      <td>4752.412</td>\n",
       "      <td>4427.076</td>\n",
       "      <td>30772.308</td>\n",
       "      <td>23067.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6610.060</td>\n",
       "      <td>4069.268</td>\n",
       "      <td>3814.204</td>\n",
       "      <td>58454.388</td>\n",
       "      <td>19163.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19036.060</td>\n",
       "      <td>2773.692</td>\n",
       "      <td>2650.100</td>\n",
       "      <td>56142.372</td>\n",
       "      <td>9435.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>47961.232</td>\n",
       "      <td>1854.956</td>\n",
       "      <td>1789.584</td>\n",
       "      <td>47348.184</td>\n",
       "      <td>4039.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lr5-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>989.536</td>\n",
       "      <td>485.096</td>\n",
       "      <td>477.236</td>\n",
       "      <td>391.996</td>\n",
       "      <td>545.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1206.488</td>\n",
       "      <td>338.632</td>\n",
       "      <td>331.960</td>\n",
       "      <td>405.348</td>\n",
       "      <td>421.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1225.260</td>\n",
       "      <td>158.824</td>\n",
       "      <td>131.252</td>\n",
       "      <td>410.500</td>\n",
       "      <td>301.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>538.236</td>\n",
       "      <td>36.216</td>\n",
       "      <td>18.588</td>\n",
       "      <td>219.232</td>\n",
       "      <td>697.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>498.660</td>\n",
       "      <td>6.548</td>\n",
       "      <td>3.692</td>\n",
       "      <td>2581.628</td>\n",
       "      <td>375.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-0001</th>\n",
       "      <th>2</th>\n",
       "      <td>6004.804</td>\n",
       "      <td>5751.324</td>\n",
       "      <td>5356.424</td>\n",
       "      <td>12978.984</td>\n",
       "      <td>6190.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5927.452</td>\n",
       "      <td>5527.984</td>\n",
       "      <td>5168.080</td>\n",
       "      <td>19834.584</td>\n",
       "      <td>13251.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5871.180</td>\n",
       "      <td>5202.720</td>\n",
       "      <td>4906.412</td>\n",
       "      <td>30192.144</td>\n",
       "      <td>17383.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5808.548</td>\n",
       "      <td>4659.872</td>\n",
       "      <td>4485.536</td>\n",
       "      <td>47430.956</td>\n",
       "      <td>21375.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5870.792</td>\n",
       "      <td>4302.984</td>\n",
       "      <td>4184.660</td>\n",
       "      <td>58515.372</td>\n",
       "      <td>19074.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-0001-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1474.100</td>\n",
       "      <td>1048.852</td>\n",
       "      <td>1030.796</td>\n",
       "      <td>949.316</td>\n",
       "      <td>1461.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1906.488</td>\n",
       "      <td>912.300</td>\n",
       "      <td>881.140</td>\n",
       "      <td>953.876</td>\n",
       "      <td>1499.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3019.916</td>\n",
       "      <td>693.500</td>\n",
       "      <td>649.848</td>\n",
       "      <td>1152.504</td>\n",
       "      <td>1382.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5298.784</td>\n",
       "      <td>410.768</td>\n",
       "      <td>309.184</td>\n",
       "      <td>1695.496</td>\n",
       "      <td>1046.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2569.456</td>\n",
       "      <td>291.420</td>\n",
       "      <td>181.552</td>\n",
       "      <td>1334.076</td>\n",
       "      <td>520.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-001</th>\n",
       "      <th>2</th>\n",
       "      <td>5939.420</td>\n",
       "      <td>5738.904</td>\n",
       "      <td>5341.880</td>\n",
       "      <td>13077.800</td>\n",
       "      <td>6303.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5911.320</td>\n",
       "      <td>5520.908</td>\n",
       "      <td>5150.336</td>\n",
       "      <td>20150.584</td>\n",
       "      <td>14104.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5881.448</td>\n",
       "      <td>5183.712</td>\n",
       "      <td>4887.224</td>\n",
       "      <td>30528.556</td>\n",
       "      <td>16100.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5823.100</td>\n",
       "      <td>4648.680</td>\n",
       "      <td>4465.160</td>\n",
       "      <td>46728.016</td>\n",
       "      <td>19819.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5902.444</td>\n",
       "      <td>4294.824</td>\n",
       "      <td>4169.940</td>\n",
       "      <td>57342.788</td>\n",
       "      <td>18449.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">noisy10-001-0.1</th>\n",
       "      <th>2</th>\n",
       "      <td>1572.660</td>\n",
       "      <td>1148.512</td>\n",
       "      <td>1122.480</td>\n",
       "      <td>1036.104</td>\n",
       "      <td>1473.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1966.188</td>\n",
       "      <td>1012.868</td>\n",
       "      <td>979.936</td>\n",
       "      <td>1082.224</td>\n",
       "      <td>1595.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3255.148</td>\n",
       "      <td>792.140</td>\n",
       "      <td>753.084</td>\n",
       "      <td>1232.044</td>\n",
       "      <td>1579.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6572.004</td>\n",
       "      <td>509.608</td>\n",
       "      <td>417.192</td>\n",
       "      <td>1925.280</td>\n",
       "      <td>1093.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7272.764</td>\n",
       "      <td>397.808</td>\n",
       "      <td>300.848</td>\n",
       "      <td>1676.020</td>\n",
       "      <td>541.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithm             binmf l5       bmf  bmf+ (int, l5)   mpbmf l5  nimfa l5\n",
       "Dataset          k                                                           \n",
       "full             2    6068.088  5736.392        5377.000  12748.644   7251.44\n",
       "                 3    5963.032  5516.160        5202.324  19217.080  12426.96\n",
       "                 5    5912.164  5205.024        4960.328  27414.176  19863.68\n",
       "                 10   5818.084  4712.456        4576.740  36911.772  21235.68\n",
       "                 15   5786.160  4406.472        4326.308  41413.996  18632.60\n",
       "full0.1          2    1934.784  1289.460        1228.680   1229.172   1499.20\n",
       "                 3    2608.744  1282.024        1218.212   1234.748   1758.68\n",
       "                 5    3327.312  1265.340        1200.484   1295.208   1869.32\n",
       "                 10   2553.936  1221.160        1152.596   1669.104   1551.36\n",
       "                 15   3004.804  1176.524        1100.280   3527.392   1241.80\n",
       "lr10             2    6011.716  5741.388        5357.988  13388.548   6190.56\n",
       "                 3    5947.276  5517.924        5164.796  21364.172  13174.68\n",
       "                 5    5890.940  5197.728        4904.776  31344.508  16045.08\n",
       "                 10   5825.888  4647.344        4488.128  49994.940  21125.00\n",
       "                 15   5859.468  4295.128        4190.416  61031.404  20222.36\n",
       "lr10-0.1         2    1462.600  1029.800        1007.236    909.520   1323.44\n",
       "                 3    1922.876   890.364         858.276    917.732   1530.48\n",
       "                 5    3179.348   667.928         622.196   1035.764   1356.84\n",
       "                 10   4518.712   372.532         268.424   1479.028    882.96\n",
       "                 15   1911.184   257.132         149.416   1142.776    437.24\n",
       "lr15             2    6030.696  5732.744        5374.872  12449.204   6813.60\n",
       "                 3    5943.736  5515.080        5205.588  18752.536  13662.32\n",
       "                 5    5895.940  5207.972        4958.088  26807.876  19874.56\n",
       "                 10   5814.724  4710.444        4572.316  37296.140  22777.68\n",
       "                 15   5786.228  4401.692        4319.204  41610.256  20270.68\n",
       "lr15-0.1         2    1755.236  1550.032        1509.952   1441.532   2132.92\n",
       "                 3    1988.840  1418.796        1360.732   1487.364   2948.40\n",
       "                 5    3027.792  1196.932        1130.692   1686.356   2914.00\n",
       "                 10   6802.312   851.384         743.552   2862.508   2449.48\n",
       "                 15   8285.724   694.268         539.196   3848.120   1698.60\n",
       "lr5              2    5498.988  5222.544        4784.400  15333.912   5603.52\n",
       "                 3    5643.288  4752.412        4427.076  30772.308  23067.20\n",
       "                 5    6610.060  4069.268        3814.204  58454.388  19163.32\n",
       "                 10  19036.060  2773.692        2650.100  56142.372   9435.04\n",
       "                 15  47961.232  1854.956        1789.584  47348.184   4039.16\n",
       "lr5-0.1          2     989.536   485.096         477.236    391.996    545.32\n",
       "                 3    1206.488   338.632         331.960    405.348    421.52\n",
       "                 5    1225.260   158.824         131.252    410.500    301.76\n",
       "                 10    538.236    36.216          18.588    219.232    697.92\n",
       "                 15    498.660     6.548           3.692   2581.628    375.52\n",
       "noisy10-0001     2    6004.804  5751.324        5356.424  12978.984   6190.40\n",
       "                 3    5927.452  5527.984        5168.080  19834.584  13251.48\n",
       "                 5    5871.180  5202.720        4906.412  30192.144  17383.32\n",
       "                 10   5808.548  4659.872        4485.536  47430.956  21375.80\n",
       "                 15   5870.792  4302.984        4184.660  58515.372  19074.32\n",
       "noisy10-0001-0.1 2    1474.100  1048.852        1030.796    949.316   1461.96\n",
       "                 3    1906.488   912.300         881.140    953.876   1499.76\n",
       "                 5    3019.916   693.500         649.848   1152.504   1382.16\n",
       "                 10   5298.784   410.768         309.184   1695.496   1046.52\n",
       "                 15   2569.456   291.420         181.552   1334.076    520.64\n",
       "noisy10-001      2    5939.420  5738.904        5341.880  13077.800   6303.76\n",
       "                 3    5911.320  5520.908        5150.336  20150.584  14104.48\n",
       "                 5    5881.448  5183.712        4887.224  30528.556  16100.96\n",
       "                 10   5823.100  4648.680        4465.160  46728.016  19819.52\n",
       "                 15   5902.444  4294.824        4169.940  57342.788  18449.44\n",
       "noisy10-001-0.1  2    1572.660  1148.512        1122.480   1036.104   1473.04\n",
       "                 3    1966.188  1012.868         979.936   1082.224   1595.12\n",
       "                 5    3255.148   792.140         753.084   1232.044   1579.56\n",
       "                 10   6572.004   509.608         417.192   1925.280   1093.52\n",
       "                 15   7272.764   397.808         300.848   1676.020    541.12"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = synth_l5.groupby(['Dataset', 'k', 'Algorithm']).mean()\n",
    "grouped_df['Error'].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf0b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c51f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
